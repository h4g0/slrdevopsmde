@inproceedings{10.1145/3652620.3687799,
author1 = {Morais, Gabriel and Adda, Mehdi and Bork, Dominik},
title = {Breaking Down Barriers: Building Sustainable Microservices Architectures with Model-Driven Engineering},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687799},
doi = {10.1145/3652620.3687799},
abstract = {Despite their promise of circularity and optimized resource consumption, the concrete achievement of sustainability through Microservices Architecture (MSA) faces challenges. Numerous intricate factors can negatively influence MSAs' design and implementation, compromising their economic and environmental effectiveness. We advocate for adopting standard and shared modeling practices to address these challenges. In this paper, we initiate an open discussion on the root causes of these challenges, relating them to the foundational microservices tenets of independence and autonomy. We also propose directions for researchers and practitioners to expand theoretical and practical knowledge of achieving sustainable microservices architectures through model-driven engineering (MDE).},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {528–532},
numpages = {5},
keywords = {software sustainability, microservices architecture, model-driven engineering},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3550356.3561609,
author1 = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial requirements for supporting AI-enhanced model-driven engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {artificial intelligence, cyber-physical systems, model-driven engineering, requirements},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3528228.3528405,
author1 = {Ponsard, Christophe and Ramon, Valery},
title = {Survey of automation practices in model-driven development and operations},
year = {2022},
isbn = {9781450393331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528228.3528405},
doi = {10.1145/3528228.3528405},
abstract = {Model-driven methods are gaining momentum in the industry to develop software intensive systems. To be effective in quality and efficient in productivity, they require a strong toolchain with seamless automation. The DevOps approach can help reach this by unifying software development and operations with a strong focus on automation and monitoring. The aim of this short paper is to review automation tasks that are specific to a model-driven context and to classify them according to a typical DevOps lifecycle covering design, code, testing, deployment and runtime activities. Tasks are identified based on different industry use cases experienced in our research centre or reported in the literature. Some challenges are identified and discussed, especially related to the use of bots in a model-driven context.},
booktitle = {Proceedings of the Fourth International Workshop on Bots in Software Engineering},
pages = {14–17},
numpages = {4},
keywords = {DevOps, certification, continuous integration, generation, model-based system development, testing, toolchain, verification},
location = {Pittsburgh, Pennsylvania},
series = {BotSE '22}
}

@inproceedings{10.1145/3555776.3577761,
author1 = {Basso, Fabio and Soares Ferreira, Bruno Marcelo and Torres, Rafael and Frantz, Rafael Z. and Kreutz, Diego and Bernardino, Maicon and de Macedo Rodrigues, Elder},
title = {Model-Driven Integration and the OSLC Standard: a Mapping of Applied Studies},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577761},
doi = {10.1145/3555776.3577761},
abstract = {Open Services for Lifecycle Collaboration (OSLC) is an open standard for tool interoperability, which allows data federation throughout Software Engineering (SE) application lifecycles. The OSLC community has been active since 2008, and there is still an open question: "What is the state-of-the-art and practice of OSLC for tool integration in Application Lifecycle Management (ALM) for Software Engineering environments?". Objective: To answer this question, our main goal is to map the state-of-the-art and practice on the adoption of OSLC in SE lifecycles. Method: This paper presents a Systematic Mapping Study (SMS) by analyzing 59 primary studies and addressing integration issues such as building SE toolchains. Results: Our findings show that OSLC has been mostly implemented with the development of adapters and MDE. Conclusions: The main advantages of OSLC are related to linked data, involving not only tool adapters for point-to-point integrations, but also proposing solutions for tool replacement in the toolchain, as well as including modifications of OSLC domain specifications and solutions for automated activities for tool integration.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {763–770},
numpages = {8},
keywords = {open services for lifecycle collaboration, tool integration, tool adapters, model-driven engineering, systematic mapping study},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3550356.3552395,
author1 = {Pulgar, Corinne},
title = {Eat your own DevOps: a model driven approach to justify continuous integration pipelines},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3552395},
doi = {10.1145/3550356.3552395},
abstract = {Many aspiring DevOps projects have introduced continuous development or continuous integration pipelines to their workflow as proof of their trustworthiness. However, a quality control protocol for pipelines has yet to be researched. This contribution suggests a model-driven approach using justification diagrams as a means to evaluate a pipeline's coherency with its project. The approach is partly automated and tested on three open-source projects with promising results.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {225–228},
numpages = {4},
keywords = {quality, pipeline, justification diagram, continuous integration, continuous development, DevOps},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/2945408.2945417,
author1 = {Arta\v{c}, Matej and Borov\v{s}ak, Tadej and Di Nitto, Elisabetta and Guerriero, Michele and Tamburri, Damian A.},
title = {Model-driven continuous deployment for quality DevOps},
year = {2016},
isbn = {9781450344111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2945408.2945417},
doi = {10.1145/2945408.2945417},
abstract = {DevOps entails a series of software engineering strategies and tools that promise to deliver quality and speed at the same time with little or no additional expense. In our work we strived to enable a DevOps way of working, combining Model-Driven Engineering tenets with the challenges of delivering a model-driven continuous deployment tool that allows quick (re-)deployment of cloud applications for the purpose of continuous improvement. This paper illustrates the DICER tool and elaborates on how it can bring about the DevOps promise and enable the quality-awareness.},
booktitle = {Proceedings of the 2nd International Workshop on Quality-Aware DevOps},
pages = {40–41},
numpages = {2},
keywords = {Continuous Deployment, Model-Driven Engineering, Quality-Aware DevOps},
location = {Saarbr\"{u}cken, Germany},
series = {QUDOS 2016}
}

@inproceedings{10.1145/3297280.3300182,
author1 = {Rademacher, Florian and Sorgalla, Jonas and Sachweh, Sabine and Z\"{u}ndorf, Albert},
title = {A model-driven workflow for distributed microservice development},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3300182},
doi = {10.1145/3297280.3300182},
abstract = {Model-driven Development (MDD) is a software engineering approach that abstracts a software's design leveraging models. In particular, the development of complex, service-based architectures is considered to benefit from MDD techniques like model validation, transformation, and code generation. This paper presents an MDD-based workflow for distributed, DevOps-based microservice development and identifies the involved model types. They provide the foundation for the subsequent development of modeling languages to employ MDD for MSA engineering.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1260–1262},
numpages = {3},
keywords = {distributed microservice development, microservice architecture, model-driven microservice development, modeling languages, viewpoint modeling},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3234152.3234193,
author1 = {Rademacher, Florian and Sorgalla, Jonas and Wizenty, Philip Nils and Sachweh, Sabine and Z\"{u}ndorf, Albert},
title = {Microservice architecture and model-driven development: yet singles, soon married (?)},
year = {2018},
isbn = {9781450364225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234152.3234193},
doi = {10.1145/3234152.3234193},
abstract = {Microservice Architecture (MSA) is a comparatively novel service-based architectural style with a strong focus on high cohesion, loose coupling, and independence of services and their development teams. In this position paper we argue that Microservice Architecture (MSA) can benefit from the application of Model-driven Development (MDD). Therefore, we elucidate how typical MSA concerns may be addressed by means of MDD such as abstraction, model transformation, and modeling viewpoints. Because this contemplation is driven from a conceptual perspective on MSA, we conversely present an overview of existing methodologies and tools for applying MDD holistically in MSA development to further substantiate our position.},
booktitle = {Proceedings of the 19th International Conference on Agile Software Development: Companion},
articleno = {23},
numpages = {5},
keywords = {domain-driven design, microservice architecture, model transformation, model-driven development, model-driven microservice development, modeling languages},
location = {Porto, Portugal},
series = {XP '18}
}

@inproceedings{10.1145/3234152.3234194,
author1 = {Sorgalla, Jonas and Rademacher, Florian and Sachweh, Sabine and Z\"{u}ndorf, Albert},
title = {Collaborative model-driven software engineering and microservice architecture: a perfect match?},
year = {2018},
isbn = {9781450364225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234152.3234194},
doi = {10.1145/3234152.3234194},
abstract = {The emerging microservice architectural style (MSA) provides means predestined to cope with the essential complexity of distributed software systems. However, this gives rise to accidental complexity which can be reduced with the application of Model-Driven Development (MDD). Although there are first MDD approaches for microservices, we take the position that for a holistic modeling approach the organizational characteristics of MSA need more attention.},
booktitle = {Proceedings of the 19th International Conference on Agile Software Development: Companion},
articleno = {24},
numpages = {2},
keywords = {collaborative model-driven software engineering, microservice architecture, model-driven development},
location = {Porto, Portugal},
series = {XP '18}
}

@inproceedings{10.1109/MODELS-C.2019.00094,
author1 = {Meyers, Bart and Gadeyne, Klaas and Oakes, Bentley James and Bernaerts, Matthias and Vangheluwe, Hans and Denil, Joachim},
title = {A model-driven engineering framework to support the functional safety process},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00094},
doi = {10.1109/MODELS-C.2019.00094},
abstract = {The design of safety-related systems traditionally has long and costly development cycles due to the highly manual safety engineering process, which is guided by industry standards. In this paper, we present a modelling framework that supports DevOps principles of continuous testing and fast development iterations for the design of safety-critical systems. We show how modelling can help introducing DevOps in the context of functional safety analysis, and we also report how DevOps was used during the development of the framework.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {619–623},
numpages = {5},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1109/MODELS-C.2019.00114,
author1 = {Sandobalin, Julio and Insfran, Emilio and Abiah\~{a}o, Silvia},
title = {ARGON: a model-driven infrastructure provisioning tool},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00114},
doi = {10.1109/MODELS-C.2019.00114},
abstract = {Infrastructure as Code (IaC) is an approach to infrastructure automation based on practices from software development. IaC tools use scripts to specify the creation, update, and execution of cloud infrastructures. As each cloud provider offers a different type of infrastructure, the definition of an infrastructure element implies to write several lines of code that strongly depend on the target cloud provider. As a result, managing IaC scripts has become a time-consuming and error-prone activity. In previous work, we have presented ARGON, which is a model-driven infrastructure provisioning tool. ARGON implements a domain-specific language (DSL) for modeling the characteristics of the cloud infrastructure and provides transformation engines to automate the infrastructure provisioning for different cloud providers. In this demonstration, we show the use of ARGON for modeling and provisioning a load balancer in Amazon Web Services and Microsoft Azure. The load balancer distributes incoming application traffic across multiple virtual machines.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {738–742},
numpages = {5},
keywords = {DevOps, cloud infrastructure provisioning, infrastructure as code, model-driven engineering},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3652620.3686248,
author1 = {Bonetti, Federico and Bucchiarone, Antonio and Michael, Judith and Cicchetti, Antonio and Marconi, Annapaola and Rumpe, Bernhard},
title = {Digital Twins of Socio-Technical Ecosystems to Drive Societal Change},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3686248},
doi = {10.1145/3652620.3686248},
abstract = {While the engineering of digital twins (DTs) of cyber-physical systems already faces a number of challenges, DTs of socio-technical systems are made even more complex by human and social factors, and a comprehensive representation of their internal relations is currently lacking. DTs for socio-technical systems could open up new ways of achieving common societal goals by i) providing an understanding of complex interactions and processes, and by ii) facilitating the design of and participation in collective actions. In this context, dynamic adaptation and motivational strategies would be required to swiftly address sub-optimal system behavior. To enable the model-driven engineering of DTs responding to such requirements, we propose a conceptual model of socio-technical systems and discuss it with use-case scenarios. The presented approach supports our vision of future DT-based model-driven interventions, empowering citizens and stakeholders in driving societal change and increasing community resilience.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {275–286},
numpages = {12},
keywords = {digital twin, modeling, socio-technical system, model-driven engineering, system engineering},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/2993274.3011285,
author1 = {Alipour, Hanieh and Liu, Yan},
title = {A model driven method to deploy auto-scaling configuration for cloud services},
year = {2016},
isbn = {9781450343992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993274.3011285},
doi = {10.1145/2993274.3011285},
abstract = {Vendor lock-in is the issues in auto-scaling configuration; scaling configuration of a service cannot automatically transfer when the service is migrated from one cloud to another cloud. To facilitate fast service deployment, there is a need to automate the operations of auto-scaling configuration and deployment.},
booktitle = {Proceedings of the 4th International Workshop on Release Engineering},
pages = {23},
numpages = {1},
keywords = {Auto-scaling, Cloud Computing, DevOps, Model-driven},
location = {Seattle, WA, USA},
series = {RELENG 2016}
}

@inproceedings{10.1145/3652620.3688556,
author1 = {Hahner, Sebastian and Niehues, Nils and Boltz, Nicolas and Fuksa, Mario and Heinrich, Robert},
title = {ARC3N: A Collaborative Uncertainty Catalog to Address the Awareness Problem of Model-Based Confidentiality Analysis},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688556},
doi = {10.1145/3652620.3688556},
abstract = {Identifying confidentiality violations is challenging as modern software-intensive systems exchange and store large amounts of data, and system deployment and context vary. Although modelbased analyses can identify such violations already at design time, uncertainty within a software system or its environment can void analysis results. Existing approaches to raising awareness of uncertainty sources are limited in usability and extendability and require expert knowledge for interpretation and analysis. This paper presents our collaborative tooling ARC3N for collecting, modeling, and analyzing uncertainty sources regarding confidentiality. Using an open web-based platform, we simplify both identifying and assessing uncertainty without requiring expert knowledge. We evaluate our approach with a user study with students, researchers, and practitioners (n = 17) and demonstrate its feasibility.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {640–644},
numpages = {5},
keywords = {model-driven security, software architecture, confidentiality, uncertainty, unknown unknowns, uncertainty awareness problem},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.5555/3400397.3400521,
author1 = {Benaben, Frederick and Lauras, Matthieu and Fertier, Audrey and Salatg\'{e}, Nicolas},
title = {Integrating model-driven engineering as the next challenge for artificial intelligence: application to risk and crisis management},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {Artificial Intelligence (AI) is currently on top of the hype regarding simultaneously research publications and industrial development. However, the current status of AI makes it quite far and different from the current understanding of Human intelligence. One suggestion that is made in this article is that Model-Driven approaches could be considered as an interesting avenue to complement classical visions of AI and to provide some missing features. Specifically, the use of Model-Driven Engineering tools (such as metamodel and model transformation) could benefit to the domain of AI by introducing a way to extend the apprehension of unknown situations. To support that proposal, an illustrative example is provided regarding the domain of risk and crisis management.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {1549–1563},
numpages = {15},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@article{10.1145/2897356.2897363,
author1 = {Nambiar, Manoj and Kattepur, Ajay and Bhaskaran, Gopal and Singhal, Rekha and Duttagupta, Subhasri},
title = {Model Driven Software Performance Engineering: Current Challenges and Way Ahead},
year = {2016},
issue_date = {March 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/2897356.2897363},
doi = {10.1145/2897356.2897363},
abstract = {Performance model solvers and simulation engines have been around for more than two decades. Yet, performance modeling has not received wide acceptance in the software industry, unlike pervasion of modeling and simulation tools in other industries. This paper explores underlying causes and looks at challenges that need to be overcome to increase utility of performance modeling, in order to make critical decisions on software based products and services. Multiple real-world case studies and examples are included to highlight our viewpoints on performance engineering. Finally, we conclude with some possible directions the performance modeling community could take, for better predictive capabilities required for industrial use.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = feb,
pages = {53–62},
numpages = {10},
keywords = {Shift Left Development, Performance Modeling, Model Driven Software Performance Engineering, Industry Adoption}
}

@article{10.1145/3125621,
author1 = {Ferry, Nicolas and Chauvel, Franck and Song, Hui and Rossini, Alessandro and Lushpenko, Maksym and Solberg, Arnor},
title = {CloudMF: Model-Driven Management of Multi-Cloud Applications},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3125621},
doi = {10.1145/3125621},
abstract = {While the number of cloud solutions is continuously increasing, the development and operation of large-scale and distributed cloud applications are still challenging. A major challenge is the lack of interoperability between the existing cloud solutions, which increases the complexity of maintaining and evolving complex applications potentially deployed across multiple cloud infrastructures and platforms. In this article, we show how the Cloud Modelling Framework leverages model-driven engineering and supports the DevOps ideas to tame this complexity by providing: (i) a domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for their continuous provisioning, deployment, and adaptation.},
journal = {ACM Trans. Internet Technol.},
month = jan,
articleno = {16},
numpages = {24},
keywords = {multi-cloud, models@run-time, model-driven engineering, DevOps, Cloud computing}
}

@inproceedings{10.1145/3053600.3053627,
author1 = {D\"{u}llmann, Thomas F. and van Hoorn, Andr\'{e}},
title = {Model-driven Generation of Microservice Architectures for Benchmarking Performance and Resilience Engineering Approaches},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053627},
doi = {10.1145/3053600.3053627},
abstract = {Microservice architectures are steadily gaining adoption in industrial practice. At the same time, performance and resilience are important properties that need to be ensured. Even though approaches for performance and resilience have been developed (e.g., for anomaly detection and fault tolerance), there are no benchmarking environments for their evaluation under controlled conditions. In this paper, we propose a generative platform for benchmarking performance and resilience engineering approaches in microservice architectures, comprising an underlying metamodel, a generation platform, and supporting services for workload generation, problem injection, and monitoring.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {171–172},
numpages = {2},
keywords = {software resilience, software performance, model-driven generation, microservice architecture, benchmarking},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/3652620.3686247,
author1 = {Bedekar, Manas Manoj and Mussbacher, Gunter},
title = {A Multi-Platform Specification Language and Dataset for the Analysis of DevOps Pipelines},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3686247},
doi = {10.1145/3652620.3686247},
abstract = {To meet market demand for products that are delivered faster, while also delivering high-quality products, businesses are seeking to streamline and accelerate the design, development, and delivery process. The DevOps methodology addresses automation and faster delivery processes. Platforms such as GitHub, GitLab, Bitbucket, Azure DevOps, and Jenkins are commonly used to specify automation pipelines. With the proliferation of these platforms, it has become more difficult to analyze pipelines across individual platforms. An analysis environment that abstracts from individual platforms and can understand several pipeline dialects could address these issues. In this paper, we present a language and an Xtext-based editor for the analysis of multi-platform pipeline specifications that covers dialects from the GitHub Actions, GitLab, BitBucket, Bamboo, Circle CI, and Azure DevOps platforms. Furthermore, we present a heterogeneous dataset of automation pipelines from different platforms. We conducted a systematic analysis of existing pipeline specifications before defining the multi-platform language, and we mined and preprocessed 42,106 pipelines from open-source projects such as GitHub and Software Heritage for validation. According to our results, the proposed editor successfully parsed 40,160 pipelines after applying minor pre-processing. Based on a random sample of the remaining 1,946 pipelines, these pipelines were not parsed successfully due a malformed pipeline specification, or the files being intended for other purposes. The proposed analysis environment including language, editor, and dataset paves the way for further cross-platform analysis of automation pipelines. To demonstrate a use case for the analysis environment, we identify five distinct pipeline specification patterns from the successfully parsed pipelines to better understand common pipeline usage.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {264–274},
numpages = {11},
keywords = {DevOps, multi-platform language editor, software heritage, GitHub, pipeline dataset, pipeline specification patterns},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3217197.3217207,
author1 = {Yang, Xi and Lehman, Tom and Kettimuthu, Raj and Winkler, Linda and Jung, Eun-Sung},
title = {A Model Driven Intelligent Orchestration Approach to Service Automation in Large Distributed Infrastructures},
year = {2018},
isbn = {9781450358620},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3217197.3217207},
doi = {10.1145/3217197.3217207},
abstract = {Today's scientific computing applications and workflows operate on heterogeneous and vastly distributed infrastructures. Traditional human-in-the-loop service engineering approach met its insurmountable challenge in dealing with these very complex and diverse networked systems, including conventional and software defined networks, compute, storage, clouds and instruments. Orchestration is the key to integrate and coordinate the networked multi-services and automate end-to-end workflows. In this work, we present a model driven intelligent orchestration approach to this end-to-end automation, which is built upon a semantic modeling solution that supports the full stack of service integration, orchestration, abstraction, and intent and policy representation. We also present the design of a real-world orchestrator called StackV that is able to accommodate highly complex application scenarios such as Software Defined ScienceDMZ (SD-SDMZ) and Hybrid Cloud Inter-Networking (HCIN) by implementing this approach.},
booktitle = {Proceedings of the 1st International Workshop on Autonomous Infrastructure for Science},
articleno = {5},
numpages = {8},
keywords = {Distributed Infrastructure, Intelligent Orchestration, Modeling, Service Automation},
location = {Tempe, AZ, USA},
series = {AI-Science'18}
}

@inproceedings{10.1145/3652620.3688266,
author1 = {Aissat, Sara and Beaulieu, Jonathan and Bordeleau, Francis and Gascon-Samson, Julien and Poirier, Erik A. and Motamedi, Ali},
title = {JuNo-OPS: A DevOps Framework for the Engineering of Digital Twins for Built Assets},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688266},
doi = {10.1145/3652620.3688266},
abstract = {Digital Twins (DT) constitute complex software systems that need to be continuously modified/updated to meet evolving user requirements and priorities, and support continual improvement. Because they aim at monitoring and improving different system aspects, their development requires the collaboration of people from different domains of expertise, e.g. the development of a DT for built assets may involve the collaboration of experts in software engineering, thermal comfort, air quality, and energy consumption, etc. Consequently, DTs need to be engineered to enable the fast and secure integration and deployment of new code, the systematic and iterative evolution of their components, and the independent development of different system aspects by those experts.In this paper, we present JuNo-OPS, a DevOps framework for the engineering of DTs for built assets. The framework is being developed, tested and validated in the the context of a multi-function room at \'{E}cole de Technologie Sup\'{e}rieure (ETS). We focus on two main facets of the DT software: the microservices architecture; and the DevOps infrastructure used to support the development, continuous integration, continuous delivery and the automation thereof. We also discuss challenges and next steps related to the development and evolution of the framework.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {496–506},
numpages = {11},
keywords = {DevOps, digital twins, CI/CD pipelines, microservices, IoT},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.5555/3018100.3018105,
author1 = {Yang, Xi and Lehman, Tom},
title = {Model driven advanced hybrid cloud services for big data: paradigm and practice},
year = {2016},
isbn = {9781509061587},
publisher = {IEEE Press},
abstract = {Advanced hybrid cloud services aim to serve big data applications by bridging multi-provider high performance cloud resources including direct connects, hypervisor bypassing VM interfaces, on premise clusters, parallel storage and high speed inter-cloud networks. We present a new "full-stack model driven orchestration" paradigm to integrate these diverse resources through semantic modeling and provide complex high-end services through dynamic orchestrated workflows. We also present architectural design of a real-world orchestration system, VersaStack, that implements the paradigm as well as a case study for providing full-scale advanced hybrid cloud services in practice.},
booktitle = {Proceedings of the 7th International Workshop on Data-Intensive Computing in the Cloud},
pages = {32–36},
numpages = {5},
keywords = {service orchestration, semantic modeling, big data, advanced hybrid cloud},
location = {Salt Lake City, Utah},
series = {DataCloud '16}
}

@inproceedings{10.1145/3550356.3561597,
author1 = {Colantoni, Alessandro and Berardinelli, Luca and Garmendia, Antonio and Br\"{a}uer, Johannes},
title = {Towards blended modeling and simulation of DevOps processes: the Keptn case study},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561597},
doi = {10.1145/3550356.3561597},
abstract = {DevOps and Model Driven Engineering (MDE) provide differently skilled IT stakeholders with methodologies and tools for organizing and automating continuous software engineering activities and using models as key engineering artifacts. JSON is a popular data format, and JSON Schema provides a general-purpose schema language for JSON. This paper presents our work in progress on blended modeling and scenario simulation of continuous delivery pipelines as executable JSON-based models. For this purpose, we show a case study based on Keptn, an open source tool for DevOps automation of cloud-native applications, and its language, Shipyard, a JSON-based process language for continuous delivery pipeline specification.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {784–792},
numpages = {9},
keywords = {simulation, blended modeling, MDE, DevOps},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1109/MODELS-C.2019.00089,
author1 = {Bordeleau, Francis and Bruel, Jean-Michel and Cabot, Jordi and Dingel, Juergen and Mosser, S\'{e}bastien},
title = {1st workshop on DevOps@MODELS},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00089},
doi = {10.1109/MODELS-C.2019.00089},
abstract = {The first edition of the International Workshop DevOps@MODELS, specifically devoted to DevOps and Model Driven Engineering, was held on September 17, 2019 in Munich, Germany, as part of the satellite events of the ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems (MODELS 2019). The motivation, objectives, organization, and program of the workshop are summarized.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {587–588},
numpages = {2},
keywords = {modeling, model-driven engineering, development process, DevOps},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3550356.3561582,
author1 = {Bergelin, Johan and Cicchetti, Antonio},
title = {Towards continuous modelling to enable DevOps: a preliminary study with practitioners},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561582},
doi = {10.1145/3550356.3561582},
abstract = {Model-based methods and techniques continuously evolve to meet the increasing challenges of modern-day technical landscapes. Parallel to Model-based methods, other paradigms are similarly maturing and being integrated, and one such paradigm is DevOps. Model-based methods and DevOps are perceived to provide benefits when viewed in isolation. Recently, there has been an increased interest in matching the two paradigms, with various proposals and early adoption results. However, little focus is put on the practitioners' view.In this paper, we propose a methodology that aims to utilise Model-driven engineering and DevOps practices in conjunction. Together with the methodology, we present an early evaluation of it from a practitioner's perspective. In particular, we study a large and long-running student project aiming to build a solar vehicle, by presenting the current integration and potential future directions. In this paper we limit the observation to the development phase. Early feedback from the case study indicates significant benefits for several identified project pain points, and it's expected that more benefits will emerge when more advanced DevOps aspects are integrated with model-based methods, and the project matures.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {774–783},
numpages = {10},
keywords = {simulink, practitioners, model-based engineering, DevOps},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3550356.3561568,
author1 = {Baumann, Nils and Kusmenko, Evgeny and Ritz, Jonas and Rumpe, Bernhard and Weber, Moritz Benedikt},
title = {Dynamic data management for continuous retraining},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561568},
doi = {10.1145/3550356.3561568},
abstract = {Managing dynamic datasets intended to serve as training data for a Machine Learning (ML) model often emerges as very challenging, especially when data is often altered iteratively and already existing ML models should pertain to the data. For example, this applies when new data versions arise from either a generated or aggregated extension of an existing dataset a model has already been trained on. In this work, it is investigated on how a model-based approach for these training data concerns can be provided as well as how the complete process, including the resulting training and retraining process of the ML model, can therein be integrated. Hence, model-based concepts and the implementation are devised to cope with the complexity of iterative data management as an enabler for the integration of continuous retraining routines. With Deep Learning techniques becoming technically feasible and massively being developed further over the last decade, MLOps, aiming to establish DevOps tailored to ML projects, gained crucial relevance. Unfortunately, data-management concepts for iteratively growing datasets with retraining capabilities embedded in a model-driven ML development methodology are unexplored to the best of our knowledge. To fill in this gap, this contribution provides such agile data management concepts and integrates them and continuous retraining into the model-driven ML Framework MontiAnna [18]. The new functionality is evaluated in the context of a research project where ML is exploited for the optimal design of lattice structures for crash applications.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {359–366},
numpages = {8},
keywords = {retraining, model-driven engineering, data management, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3241403.3241406,
author1 = {Sorgalla, Jonas and Wizenty, Philip and Rademacher, Florian and Sachweh, Sabine and Z\"{u}ndorf, Albert},
title = {AjiL: enabling model-driven microservice development},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241406},
doi = {10.1145/3241403.3241406},
abstract = {The development of microservice-based architectures typically involves tedious development tasks, e.g., to configure the necessary infrastructural components or to establish the interface-based communication between services. Therefore, this paper presents AjiL, a tool which aims to ease the necessary development effort with the means of graphical modeling and code generation. It comprises three major components: based on the lightweight Aji Modeling Language, the Aji Editor can create microservice system diagrams, which can be used by the Aji Spring Cloud Generator to generate system foundations.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {1},
numpages = {4},
keywords = {model-driven engineering, microservice architecture, graphical domain-specific modeling language, development tool},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3652620.3688335,
author1 = {Sedrakyan, Gayane and Iacob, Maria-Eugenia and Van Hillegersberg, Jos},
title = {Towards LowDevSecOps Framework for Low-Code Development: Integrating Process-Oriented Recommendations for Security Risk Management},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688335},
doi = {10.1145/3652620.3688335},
abstract = {The increasing demand for software solutions in the coming years will surpass the availability of IT talent, driving interest in citizen development and low-code approaches. However, the lack of technical insight among citizen developers poses potential security risks. This research aims to support businesses adopting citizen development by providing a framework that helps to proactively identify security risks by also linking them to specific actors and tools needed during the system design and development process to mitigate those risks. Additionally, this framework helps to address knowledge gaps by outlining actionable steps to ensure secure low-code development practices. The research aims to answer the question: "How can contextual information be modeled in low-code platforms to proactively identify and address security-related issues, acting as a virtual mentor for citizen / low-code developers?". To answer this question, our research conceptualizes security risks from established frameworks and operational security methodologies into a practical framework that allows mapping security risks to the context of low-code development. This framework serves as a foundational platform for designing and integrating active process-oriented guidance within low-code platforms using model-based automated prompts. This approach additionally aligns with DevSecOps principles that allows enhancing the capacity for low-code approach and citizen development in areas that currently may include manual coding and integrations.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {886–894},
numpages = {9},
keywords = {low code development, modeling, recommenders, security, devops, devsecops},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3417990.3420203,
author1 = {Colantoni, Alessandro and Berardinelli, Luca and Wimmer, Manuel},
title = {DevOpsML: towards modeling DevOps processes and platforms},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420203},
doi = {10.1145/3417990.3420203},
abstract = {DevOps and Model Driven Engineering (MDE) provide differently skilled IT stakeholders with methodologies and tools for organizing and automating continuous software engineering activities-from development to operations, and using models as key engineering artifacts, respectively. Both DevOps and MDE aim at shortening the development life-cycle, dealing with complexity, and improve software process and product quality.The integration of DevOps and MDE principles and practices in low-code engineering platforms (LCEP) are gaining attention by the research community. However, at the same time, new requirements are upcoming for DevOps and MDE as LCEPs are often used by non-technical users, to deliver fully functional software. This is in particular challenging for current DevOps processes, which are mostly considered on the technological level, and thus, excluding most of the current LCEP users. The systematic use of models and modeling to lowering the learning curve of DevOps processes and platforms seems beneficial to make them also accessible for non-technical users.In this paper, we introduce DevOpsML, a conceptual framework for modeling and combining DevOps processes and platforms. Tools along with their interfaces and capabilities are the building blocks of DevOps platform configurations, which can be mapped to software engineering processes of arbitrary complexity. We show our initial endeavors on DevOpsML and present a research roadmap how to employ the resulting DevOpsML framework for different use cases.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {69},
numpages = {10},
keywords = {modeling languages, model-driven engineering, DevOps},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3652620.3688219,
author1 = {Predoaia, Ionut and Kolovos, Dimitris and Garcia-Dominguez, Antonio and Lenk, Matthias and Ebel, Wolfram and Burkl, Jan},
title = {Towards Processing YAML Documents with Model Management Languages},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688219},
doi = {10.1145/3652620.3688219},
abstract = {YAML is a widely used textual format for capturing structured data. Despite its widespread use by software engineering practitioners, there is little support for YAML in model management (e.g. model-to-text, model-to-model) languages. This paper proposes an approach for bridging the conceptual gap between contemporary model management languages and YAML. A technical solution is presented for enabling the use of model management tasks over models captured in YAML. Our solution is evaluated in an industrial case study on cloud infrastructure automation, involving the use of model transformations that transform EMF models into YAML models, with the goal of producing Infrastructure as Code through Ansible Playbooks.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {970–979},
numpages = {10},
keywords = {model management, YAML, MDE, EMF, infrastructure as code, ansible, eclipse epsilon, EMC driver, cloud automation},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3688259,
author1 = {Beaumont, Gwendal and Beugnard, Antoine and Mart\'{\i}nez, Salvador and Urtado, Christelle and Vauttier, Sylvain},
title = {Towards Re-Engineering Digital Twins: Preliminary Experiments on Three Use Cases},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688259},
doi = {10.1145/3652620.3688259},
abstract = {Digital Twins (DTs) are everywhere, but they often have been developed before consensual definitions, reference models or adapted tools were proposed. Thus, these ad hoc DTs cannot be easily manipulated as actual entities, hampering both their sustainability and their life cycle management (e.g., their redeployment). In order to deal with this issue, this paper chooses to learn from practice by re-engineering existing DTs. Starting from a generic a priori metamodel that tries to clearly separate concerns (so that DTs can be seen as first class software entities), this paper implements experiments in three steps: (i) reverse engineering an existing Digital Twin, seen as a prototypical instance, (ii) generalization of the DT architecture descriptor into a DT model, (iii) alignment between this reverse engineered DT model and the a priori DT metamodel. First experiments, run on three use cases, show that our proposal can relevantly analyze and document DTs to support their re-engineering as first class entities.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {453–458},
numpages = {6},
keywords = {digital twin, metamodel, model-driven engineering, digital twin architecture, reverse engineering digital twins, re-engineering digital twins},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3107091.3107093,
author1 = {Truong, Hong-Linh and Berardinelli, Luca},
title = {Testing uncertainty of cyber-physical systems in IoT cloud infrastructures: combining model-driven engineering and elastic execution},
year = {2017},
isbn = {9781450351126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3107091.3107093},
doi = {10.1145/3107091.3107093},
abstract = {Today's cyber-physical systems (CPS) span IoT and cloud-based datacenter infrastructures, which are highly heterogeneous with various types of uncertainty. Thus, testing uncertainties in these CPS is a challenging and multidisciplinary activity. We need several tools for modeling, deployment, control, and analytics to test and evaluate uncertainties for different configurations of the same CPS. In this paper, we explain why using state-of-the art model-driven engineering (MDE) and model-based testing (MBT) tools is not adequate for testing uncertainties of CPS in IoT Cloud infrastructures. We discus how to combine them with techniques for elastic execution to dynamically provision both CPS under test and testing utilities to perform tests in various IoT Cloud infrastructures.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Testing Embedded and Cyber-Physical Systems},
pages = {5–8},
numpages = {4},
keywords = {uncertainty, testing, elasticity, MDE, MBT, IoT, Cloud},
location = {Santa Barbara, CA, USA},
series = {TECPS 2017}
}

@inproceedings{10.1145/3652620.3686250,
author1 = {Cederbladh, Johan and Eisenberg, Martin and Berardinelli, Luca and Bilic, Damir},
title = {Automation Support for System Simulation and Architecture Layout Design in Cyber-Physical Systems Engineering},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3686250},
doi = {10.1145/3652620.3686250},
abstract = {Simulations have long been part of hardware-centric system domains. Similarly, architecture design is a common practice for complex industrial systems, which comprise many components that can be arranged in different layouts according to given requirements. Configuring simulation models and choosing the architecture design can be time-consuming activities. This paper presents a model-driven approach to automate the simulation configuration and architecture layouting engineering activities by leveraging model-driven optimisation techniques. The approach leverages a research solution, MOMoT (Marrying Optimisation and Model Transformations), an academic tool that combines search-based algorithms and model transformations. MOMoT is extended with two software modules, leveraging the Functional Mock-up Interface standard for simulation configuration and an architectural description language to design architecture layouts. Our solution is presented in the context of Volvo Construction Equipment's industrial use case, which is part of the European-funded project AIDOaRt. Our approach contributes to automated decision support to simulation and architecture design through model-driven optimisation while preserving the organisation's engineering practices.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {299–310},
numpages = {12},
keywords = {simulation, models, optimisation, architecture, layout},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3550356.3556504,
author1 = {Zam, Michel},
title = {Teaching modeling to anyone the aristotelian way: anyone can cook a sound model},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3556504},
doi = {10.1145/3550356.3556504},
abstract = {Could model-driven engineering --- inspired by classical drama, modern agile practices, and recent findings from neurosciences--- be a way to address gaps and mismatches in designing and modeling better software, empower and engage both students and professionals of any level to learn and share knowledge? In this paper we report on our experiences with teaching and practicing model-driven engineering during 25+ years, we share three original socio-technical strategies we called Aristotelians and invite the reader to join a collaborative open-source gamified initiative for a greater social impact.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {107–114},
numpages = {8},
keywords = {tool support, socio-technical, social impact, model-driven engineering, mix theory and practice, informal and formal models, engaging students, education, domain modeling},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3550356.3563134,
author1 = {Fend, Andreas and Bork, Dominik},
title = {CPSAML: a language and code generation framework for digital twin based monitoring of mobile cyber-physical systems},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3563134},
doi = {10.1145/3550356.3563134},
abstract = {Cyber-physical systems (CPS) are finding increasing use, whether in factories, autonomous vehicles, or smart buildings. Monitoring the execution of CPSs is crucial since CPSs directly influence their physical environment. Like the actual system, the monitoring application must be designed, developed, and tested. Mobile CPSs, in contrast to stationary CPSs, bring the additional requirement that instances can dynamically join, leave, or fail during execution time. This dynamic behavior must also be considered in the monitoring application. This paper presents CPSAML, a language and code generation framework for the model-driven development of mobile CPS systems, including a cockpit application for monitoring and interacting with such a system. The pipeline starts with the formulation of the system and the CPSs it contains at an abstract level by the system architect using a domain-specific modeling language. Next, this model is transformed into SysML 2 for further extension and richer specificity by system engineers on a more technical level. In the last step of the pipeline, the SysML 2 model is used to generate code for the CPS devices, a system-wide digital twin, and the cockpit application mentioned above. This cockpit enables the operator to configure and apply the monitoring and interaction with the system during runtime. We evaluate our CPSAML language and code generation framework on an Indoor Transport System case study with Roomba vacuum cleaner robots.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {649–658},
numpages = {10},
keywords = {multi-paradigm modeling, model-driven engineering, digital twin, cyber-physical systems},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3652620.3676876,
author1 = {Chaudhari, Nirmal},
title = {Pipelines Have Feelings Too: A Structured Way To Design CI/CD Pipelines},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3676876},
doi = {10.1145/3652620.3676876},
abstract = {Despite the increased use of continuous integration or continuous development (CI/CD) pipelines as a means to ensure code quality, its effectiveness is limited due to the lack of justification in its structure. Since CI/CD pipelines are written as code, they ideally should be treated as such. This means, they should be fully integrated into the DevOps process. The proposed solution is an extension to the Justification Diagram (JD) model that would enable developers to seamlessly develop such pipelines iterative and incrementally, through the use of patterns and merging syntax. This tool will help better integrate CI/CD pipelines into the DevOps process, ultimately creating more maintainable and justified pipelines.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {184–187},
numpages = {4},
keywords = {DevOps, justification diagrams, CI/CD, CSD},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3550356.3561576,
author1 = {Kirchhof, J\"{o}rg Christian and Kusmenko, Evgeny and Ritz, Jonas and Rumpe, Bernhard and Moin, Armin and Badii, Atta and G\"{u}nnemann, Stephan and Challenger, Moharram},
title = {MDE for machine learning-enabled software systems: a case study and comparison of MontiAnna &amp; ML-Quadrat},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561576},
doi = {10.1145/3550356.3561576},
abstract = {In this paper, we propose to adopt the MDE paradigm for the development of Machine Learning (ML)-enabled software systems with a focus on the Internet of Things (IoT) domain. We illustrate how two state-of-the-art open-source modeling tools, namely MontiAnna and ML-Quadrat can be used for this purpose as demonstrated through a case study. The case study illustrates using ML, in particular deep Artificial Neural Networks (ANNs), for automated image recognition of handwritten digits using the MNIST reference dataset, and integrating the machine learning components into an IoT-system. Subsequently, we conduct a functional comparison of the two frameworks, setting out an analysis base to include a broad range of design considerations, such as the problem domain, methods for the ML integration into larger systems, and supported ML methods, as well as topics of recent intense interest to the ML community, such as AutoML and MLOps. Accordingly, this paper is focused on elucidating the potential of the MDE approach in the ML domain. This supports the ML-engineer in developing the (ML/software) model rather than implementing the code, and additionally enforces reusability and modularity of the design through enabling the out-of-the-box integration of ML functionality as a component of the IoT or cyber-physical systems.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {380–387},
numpages = {8},
keywords = {tools, model-driven engineering, machine learning, domain specific modeling, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3550356.3561567,
author1 = {Nicacio, Jalves and Petrillo, Fabio},
title = {An approach to build consistent software architecture diagrams using devops system descriptors},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561567},
doi = {10.1145/3550356.3561567},
abstract = {System architecture diagrams play an essential role in understanding system architecture. They encourage more active discussion among participants and make it easier to recall system details. However, system architecture diagrams often diverge from the software. As a result, they can interfere with the understanding and maintenance of the software. We propose an approach to build system architecture diagrams using DevOps system descriptors to improve the consistency of architecture diagrams. To produce our approach, we survey problems with architecture diagrams in the software industry, developing guidelines for creating architecture diagrams. Next, we produce a taxonomy for system descriptor concepts and a process to convert system descriptors into architecture diagrams. We evaluate our approach through a case study. In this case study, we defined a Docker Compose descriptor for a newsfeed system and transformed it into a system architectural diagram using the proposed approach. Our results indicate that, currently, system descriptors generally lead to consistent diagrams only to a limited extent. However, the case study's observations indicate that the proposed approach is promising and demonstrates that system descriptors have the potential to create more consistent architectural diagrams. Further evaluation in controlled and empirical experiments is necessary to test our hypothesis in more detail.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {312–321},
numpages = {10},
keywords = {system descriptors, system architecture, software systems, software engineering, software architecture, modelling process, architectural diagram consistency},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3417990.3420206,
author1 = {Philippe, Jolan and Coullon, H\'{e}l\'{e}ne and Tisi, Massimo and Suny\'{e}, Gerson},
title = {Towards transparent combination of model management execution strategies for low-code development platforms},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420206},
doi = {10.1145/3417990.3420206},
abstract = {Low-code development platforms are taking an important place in the model-driven engineering ecosystem, raising new challenges, among which transparent efficiency or scalability. Indeed, the increasing size of models leads to difficulties in interacting with them efficiently. To tackle this scalability issue, some tools are built upon specific computational strategies exploiting reactivity, or parallelism. However, their performances may vary depending on the specific nature of their usage. Choosing the most suitable computational strategy for a given usage is a difficult task which should be automated. Besides, the most efficient solutions may be obtained by the use of several strategies at the same time. This paper motivates the need for a transparent multi-strategy execution mode for model-management operations. We present an overview of the different computational strategies used in the model-driven engineering ecosystem, and use a running example to introduce the benefits of mixing strategies for performing a single computation. This example helps us present our design ideas for a multi-strategy model-management system. The code-related and DevOps challenges that emerged from this analysis are also presented.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {72},
numpages = {10},
keywords = {spark, multi-strategy, model-driven engineering, low-code development, OCL},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1109/MODELS-C.2019.00093,
author1 = {Ferry, Nicolas and Nguyen, Phu H.},
title = {Towards model-based continuous deployment of secure IoT systems},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00093},
doi = {10.1109/MODELS-C.2019.00093},
abstract = {Software development and delivery of IoT systems would greatly benefit from DevOps as their requirements for reliability, quality, security and privacy are paramount. The ability to continuously evolve these systems to adapt to their environment is decisive to ensure and increase their trustworthiness (including security and privacy) and quality. In particular, there is a need for supporting the continuous deployment of secure IoT systems over IoT, Edge, and Cloud infrastructures. However, our recent survey shows a lack of specific support for deploying security and privacy mechanisms as part of the system. This position paper reports on an on-going extension of the modelling language and models@runtime implementation of the Generation and Deployment of Smart IoT Systems (GeneSIS) tool for supporting continuous deployment of IoT security and privacy mechanisms on the Edge. In particular, we present our early design of the extended version of GeneSIS with the new concepts of port, security capability, and privacy capability.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {613–618},
numpages = {6},
keywords = {model@runtime, model-driven engineering, deployment, IoT, DevOps},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3652620.3687780,
author1 = {Zschaler, Steffen and Barnett, Will and Boronat, Artur and Garcia-Dominguez, Antonio and Kolovos, Dimitris},
title = {Move your MDE teaching online: The MDENet Education Platform},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687780},
doi = {10.1145/3652620.3687780},
abstract = {Teaching MDE is challenging, not least because the tools developed by the community can be difficult to install and configure as well as complex to master and use. To reduce the complexity for learners of MDE, enabling them to focus on the core MDE concepts, we present the MDENet Education Platform - an online, playground-based platform for learning MDE without the need for tool installation. Teachers declaratively describe learning activities, carefully controlling the complexity of the user interface learners are exposed to. We give an overview of the platform and highlight some current applications. The demonstration will show the use of the platform from the perspective of learners and teachers.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {6–10},
numpages = {5},
keywords = {MDE, education, online, no installation, playground},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3688343,
author1 = {Michael, Judith and David, Istvan and Bork, Dominik},
title = {Digital Twin Evolution for Sustainable Smart Ecosystems},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688343},
doi = {10.1145/3652620.3688343},
abstract = {Smart ecosystems are the drivers of modern society. They control infrastructures of socio-techno-economic importance, ensuring their stable and sustainable operation. Smart ecosystems are governed by digital twins---real-time virtual representations of physical infrastructure. To support the open-ended and reactive traits of smart ecosystems, digital twins need to be able to evolve in reaction to changing conditions. However, digital twin evolution is challenged by the intertwined nature of physical and software components, and their individual evolution. As a consequence, software practitioners find a substantial body of knowledge on software evolution hard to apply in digital twin evolution scenarios and a lack of knowledge on the digital twin evolution itself. The aim of this paper, consequently, is to provide software practitioners with tangible leads toward understanding and managing the evolutionary concerns of digital twins. We use four distinct digital twin evolution scenarios, contextualized in a citizen energy community case to illustrate the usage of the 7R taxonomy of digital twin evolution. By that, we aim to bridge a significant gap in leveraging software engineering practices to develop robust smart ecosystems.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {1061–1065},
numpages = {5},
keywords = {cyber-physical systems, digital twins, evolution, sustainability},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3687795,
author1 = {Sch\"{o}berl, Stefan and Banse, Christian and Geist, Verena and Kunz, Immanuel and Pinzger, Martin},
title = {CertGraph: Towards a Comprehensive Knowledge Graph for Cloud Security Certifications},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687795},
doi = {10.1145/3652620.3687795},
abstract = {This paper introduces CertGraph, a knowledge graph-based approach designed to streamline security certification which integrates evidence from multiple sources. Unlike existing approaches, we consider the complete stack from software to policies, and enable the fusion of evidence from different views and sources. Its extensible ontology is designed to accommodate multiple domains, including cloud security, AI models, and source code. By providing an automated and systematic approach to build an ontology, CertGraph aims to facilitate more effective security certification and compliance verification.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {76–77},
numpages = {2},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3688252,
author1 = {Honcak, Rene and Wooley, Ana},
title = {An MBSE approach for Virtual Verification &amp; Validation of Systems with Digital Twins},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688252},
doi = {10.1145/3652620.3688252},
abstract = {The automotive industry is embracing digital transformation, with trends like electric mobility leading the way. However, how will we efficiently and sustainably develop our electrified vehicles in the future? Agile customer demands, which require shorter product development cycles, pose a challenge for the automotive supplier industry. One approach to address this challenge is the adoption of Model Based Systems Engineering (MBSE) and Digital Twins (DT) for product digitalization and virtualization. MBSE supports product development from inception to the entire product lifecycle by continuously describing the system based on a system model. DTs, which are virtual representations of physical products/systems, capture both behavior and lifespan through simulation models and workflows. The complexity of DTs will highly increase due to multi-physical interactions, requiring consistency and traceability for the cross-domain development as well as application of simulation models and workflows in virtual testing and product approvals. The foundation lies in calibrated, verified, and validated simulation models, as well as reproducible simulation workflows, with capabilities that include uncertainty assessments. Processes and methods are necessary to manage complexity, ensure systematic validation, and efficiently develop DTs. Current approaches often overlook how DTs should be specified, designed, tested, and standardized. This research highlights the advantages of introducing a V-model and MBSE for DT development within the context of digital engineering. These measures can enhance the efficiency, reusability, quality, and automation of DTs.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {390–400},
numpages = {11},
keywords = {digital twin, model based systems engineering, verification, validation, simulation, virtual verification, virtual validation},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1109/MODELS-C.2019.00091,
author1 = {Nehls, Holger and Ratiu, Daniel},
title = {Towards continuous delivery for domain experts: using MDE to integrate non-programmers into a software delivery pipeline},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00091},
doi = {10.1109/MODELS-C.2019.00091},
abstract = {Modern computed tomography (CT) scanners are complex, software-intensive systems whose correct functioning is governed by over 100 parameters which depend on the concrete hardware configurations and on the addressed clinical use-cases. To tame the intrinsic complexity of the parameters configurations, over the last four years, Siemens Healthineers (SHS) have been developing and deploying a set of domain specific languages and tooling based on Jetbrains' Meta-Programming System.In this paper, we report on the challenges and experiences we made while building two delivery pipelines. At meta-level, we built a continuous delivery pipeline such that new versions of our domain specific modeling tool can be deployed continuously based on the feedback of domain experts. At model-level we have integrated the developed domain-specific tool in the continuous delivery pipeline for the computed tomography software and thereby bring the Continuous Delivery mind-set with advantages and challenges to domain experts who are working traditionally "outside" of the software development.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {598–604},
numpages = {7},
keywords = {model-driven engineering, continuous delivery},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3550355.3552417,
author1 = {Baresi, Luciano and Quattrocchi, Giovanni and Tamburri, Damian Andrew and Terracciano, Luca},
title = {A declarative modelling framework for the deployment and management of blockchain applications},
year = {2022},
isbn = {9781450394666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550355.3552417},
doi = {10.1145/3550355.3552417},
abstract = {The deployment and management of Blockchain applications require non-trivial efforts given the unique characteristics of their infrastructure (i.e., immutability) and the complexity of the software systems being executed. The operation of Blockchain applications is still based on ad-hoc solutions that are error-prone, difficult to maintain and evolve, and do not manage their interactions with other infrastructures (e.g., a Cloud backend).This paper proposes KATENA, a framework for the deployment and management of Blockchain applications. In particular, it focuses on applications that are compatible with Ethereum, a popular general-purpose Blockchain technology. KATENA provides i) a metamodel for defining Blockchain applications, ii) a set of processes to automate the deployment and management of defined models, and iii) an implementation of the approach based on TOSCA, a standard language for Infrastructure-as-Code, and xOpera, a TOSCA-compatible orchestrator. To evaluate the approach, we applied KATENA to model and deploy three real-world Blockchain applications, and showed that our solution reduces the amount of code required for their operations up to 82.7%.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
pages = {311–321},
numpages = {11},
keywords = {smart contract, orchestration, infrastructure-as-code, iac, ethereum, devops, deployment, decentralized applications, dApp, blockchain, TOSCA},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3417990.3421446,
author1 = {Hugues, Jerome and Hristosov, Anton and Hudak, John J. and Yankel, Joe},
title = {TwinOps - DevOps meets model-based engineering and digital twins for the engineering of CPS},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3421446},
doi = {10.1145/3417990.3421446},
abstract = {The engineering of Cyber-Physical Systems (CPS) requires a large set of expertise to capture the system requirements and to derive a correct solution. Model-based Engineering and DevOps aim to efficiently deliver software with increased quality. Model-based Engineering relies on models as first-class artifacts to analyze, simulate, and ultimately generate parts of a system. DevOps focuses on software engineering activities, from early development to integration, and then improvement through the monitoring of the system at run-time. We claim these can be efficiently combined to improve the engineering process of CPS.In this paper, we present TwinOps, a process that unifies Model-based Engineering, Digital Twins, and DevOps practice in a uniform workflow. TwinOps illustrates how to leverage several best practices in MBE and DevOps for the engineering Cyber-Physical systems. We illustrate our contribution using a Digital Twins case study to illustrate TwinOps benefits, combining AADL and Modelica models, and an IoT platform.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {94},
numpages = {5},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1109/MODELS-C.2019.00092,
author1 = {Benni, Benjamin and Blay-Fornarino, Mireille and Mosser, S\'{e}bastien and Pr\'{e}cioso, Fr\'{e}d\'{e}ric and Jungbluth, G\"{u}nther},
title = {When DevOps meets meta-learning: a portfolio to rule them all},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00092},
doi = {10.1109/MODELS-C.2019.00092},
abstract = {The Machine Learning (ML) world is in constant evolution, as the amount of different algorithms in this context is evolving quickly. Until now, it is the responsibility of data scientists to create ad-hoc ML pipelines for each situation they encounter, gaining knowledge about the adequacy between their context and the chosen pipeline. Considering that it is not possible at a human scale to analyze the exponential number of potential pipelines, picking the right pipeline that combines the proper preprocessing and algorithms is a hard task that requires knowledge and experience. In front of the complexity of building a right ML pipeline, algorithm portfolios aim to drive algorithm selection, learning from the past in a continuous process. However, building a portfolio requires that (i) data scientists develop and test pipelines and (ii) portfolio maintainers ensure the quality of the portfolio and enrich it. The firsts are the developers, while the seconds are the operators. In this paper, we present a set of criteria to be respected, and propose a pipeline-based meta-model, to support a DevOps approach in the context of Machine Learning Pipelines. The exploitation of this meta-model, both as a graph and as a logical expression, serves to ensure continuity between Dev and Ops. We depict our proposition through the simplified study of two primary use cases, one with developer's point-of-view, the other with ops'.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {605–612},
numpages = {8},
keywords = {portfolio, meta-learning, machine learning pipeline, generation, composition},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3417990.3420194,
author1 = {Piedade, Bruno and Dias, Jo\~{a}o Pedro and Correia, Filipe F.},
title = {An empirical study on visual programming docker compose configurations},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420194},
doi = {10.1145/3417990.3420194},
abstract = {Infrastructure-as-Code tools, such as Docker and Docker Compose, play a crucial role in the development and orchestration of cloud-native and at-scale software. However, as IaC relies mostly on the development of text-only specifications, these are prone to misconfigurations and hard to debug. Several works suggest the use of models as a way to abstract their complexity, and some point to the use of visual metaphors. Yet, few empirical studies exist in this domain. We propose a visual programming notation and environment for specifying Docker Compose configurations and proceed to empirically validate its merits when compared with the standard text-only specification. The goal of this work is to produce evidence of the impact that visual approaches may have on the development of IaC. We observe that the use of our solution reduced the development time and error proneness, primarily for configurations definition activities. We also observed a preference for the approach in terms of ease of use, a positive sentiment of its usefulness and intention to use.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {60},
numpages = {10},
keywords = {visual programming, orchestration, docker compose, docker},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/2804371.2804378,
author1 = {Guerriero, Michele and Ciavotta, Michele and Gibilisco, Giovanni Paolo and Ardagna, Danilo},
title = {SPACE4Cloud: a DevOps environment for multi-cloud applications},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804378},
doi = {10.1145/2804371.2804378},
abstract = {Cloud computing has been a game changer in the design, development and management of modern applications, which have grown in scope and size becoming distributed and service oriented. New methodologies have emerged to deal with this paradigm shift in software engineering. Consequently, new tools, devoted to ease the convergence between developers and other IT professional, are required. Here, we present SPACE4Cloud, a DevOps integrated environment for model-driven design-time QoS assessment and optimization, and runtime capacity allocation for Cloud applications.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {29–30},
numpages = {2},
keywords = {runtime, design-time, QoS, Model-Driven, DevOps, Cloud},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}

@inproceedings{10.1145/3687997.3695650,
author1 = {Pontes Miranda, James William and Bruneliere, Hugo and Tisi, Massimo and Suny\'{e}, Gerson},
title = {Towards an In-Context LLM-Based Approach for Automating the Definition of Model Views},
year = {2024},
isbn = {9798400711800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687997.3695650},
doi = {10.1145/3687997.3695650},
abstract = {In the Model-Driven Engineering (MDE) of complex systems, multiple models represent various systems' aspects. In practice, these models are often unconnected and specified using different modeling languages. Model view solutions can be employed to automatically combine such models. However, writing model view definitions is not trivial. When modeling languages are semantically distant and/or have a large number of concepts, it can quickly become difficult to manually identify the language elements to be selected, associated, or queried to build a model view. As a solution, this paper proposes an in-context Large Language Model (LLM)-based approach to assist engineers in writing model-view definitions. Notably, we rely on LLMs and Prompt Engineering techniques to automatically generate drafts of model-view definitions by providing as input only minimal information on the modeling languages to be combined. We implemented our approach by integrating the EMF Views solution for model views with the LangChain framework for LLM-based applications. To this end, we tailored LangChain to handle EMF metamodels. We validated our approach and implementation on a set of model views originally specified either in VPDL, the ViewPoint Definition Language of EMF Views, or as ATL model-to-model transformations. We compared these original model view definitions with the ones we automatically generated. The obtained results show the feasibility and applicability of our approach.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {29–42},
numpages = {14},
keywords = {Large language models, Model views, Model-driven engineering, Modeling languages, Prompt engineering},
location = {Pasadena, CA, USA},
series = {SLE '24}
}

@inproceedings{10.1145/3639474.3640071,
author1 = {Sarmiento-Calisaya, Edgar and Mamani-Aliaga, Alvaro and Leite, Julio Cesar Sampaio Do Prado},
title = {Introducing Computer Science Undergraduate Students to DevOps Technologies from Software Engineering Fundamentals},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640071},
doi = {10.1145/3639474.3640071},
abstract = {The fast adoption of collaborative software development by the industry allied with the demand for a short time to market has led to a dramatic change in IT roles. New practices, tools, and environments are available to support professionals in their day-to-day activities. In this context, the demand for software engineers with these skills continues to increase, specifically those related to Extreme Programming, Agile frameworks, CI/CD, and DevOps. To match Computer Science undergraduate students' skills with existing job offers, some universities have begun to include DevOps topics in their curriculums. However, due to the wide range of courses covered in Computer Science majors, it is particularly challenging to introduce DevOps within the context of Software Engineering fundamentals, i.e., connect abstract concepts to skills needed for software engineers in the industry. This paper investigates ways of introducing Computer Science students to industry-relevant practices and technologies early from two Software Engineering fundamentals courses. Student outcomes were extremely positive, providing insights into ways to introduce students to DevOps-related practices and technologies and bridge the gap between academia and industry.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {348–358},
numpages = {11},
keywords = {DevOps, CI/CD, industry, academy, software engineering, education, tools, environment},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3550356.3561549,
author1 = {Cleophas, Loek and Godfrey, Thomas and Khelladi, Djamel Eddine and Lehner, Daniel and Combemale, Benoit and van den Brand, Mark and Vierhauser, Michael and Wimmer, Manuel and Zschaler, Steffen},
title = {A community-sourced view on engineering digital twins: a report from the EDT.Community},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561549},
doi = {10.1145/3550356.3561549},
abstract = {Digital Twins are an important concept, enabling what-if scenario exploration, predictive maintenance, and other approaches. They help in saving time and physical resources when developing and evolving systems, whether natural or engineered. However, constructing and maintaining digital twins is a challenging engineering task - and, to date, there is a lack of understanding of the engineering techniques and methodologies required. To address these challenges, we created EDT.Community, a programme of seminars on the engineering of digital twins hosting digital twins experts from academia and industry. In this paper, we report on the main topics of discussion from the first year of the programme. We contribute by providing (1) a common understanding of open challenges in research and practice of the engineering of digital twins, and (2) an entry point to researchers who aim to close gaps in the current state of the art.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {481–485},
numpages = {5},
keywords = {systems engineering, digital twin, digital engineering},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3365438.3410951,
author1 = {Song, Hui and Dautov, Rustem and Ferry, Nicolas and Solberg, Arnor and Fleurey, Franck},
title = {Model-based fleet deployment of edge computing applications},
year = {2020},
isbn = {9781450370196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365438.3410951},
doi = {10.1145/3365438.3410951},
abstract = {Edge computing brings software in close proximity to end users and IoT devices. Given the increasing number of distributed Edge devices with various contexts, as well as the widely adopted continuous delivery practices, software developers need to maintain multiple application versions and frequently (re-)deploy them to a fleet of many devices with respect to their contexts. Doing this correctly and efficiently goes beyond manual capabilities and requires employing an intelligent and reliable automated approach. Accordingly this paper describes a joint research with a Smart Healthcare application provider on a model-based approach to automatically assigning multiple software deployments to hundreds of Edge gateways. From a Platform-Specific Model obtained from the existing Edge computing platform, we extract a Platform-Independent Model that describes a list of target devices and a pool of available deployments. Next, we use constraint solving to automatically assign deployments to devices at once, given their specific contexts. The resulting solution is transformed back to the PSM as to proceed with software deployment accordingly. We validate the approach with a Fleet Deployment prototype integrated into the DevOps toolchain currently used by the application provider. Initial experiments demonstrate the viability of the approach and its usefulness in supporting DevOps in Edge computing applications.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {132–142},
numpages = {11},
keywords = {software deployment, model-based software engineering, device fleet, IoT, DevOps},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3550356.3561550,
author1 = {Christofi, Nikolena and Pucel, Xavier},
title = {A novel methodology to construct digital twin models for spacecraft operations using fault and behaviour trees},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561550},
doi = {10.1145/3550356.3561550},
abstract = {Successful satellite data reception requires the nominal operation of the ground stations in charge of their health monitoring as much as the spacecrafts themselves. Although the concept of Model-Based Diagnosis (MBD) in the field of autonomous systems -such as satellites, has long been researched and developed, that is not the case for their ground systems. Both satellites and ground stations operate autonomously. The latter however, are not equipped with the advanced Fault Detection, Isolation and Recovery (FDIR) capabilities one finds today on-board all orbiting spacecrafts. The aim of the study presented in this paper is the improvement of ground stations' operational diagnostics by providing the operators with ad-hock, Operations-Dedicated Models (ODMs). The latter serve as a basis for the construction of the system's Digital Twin (DT) models. These models allow the operators react more quickly and more precisely to alarms raised by the station. By helping the operators identify the malfunction and correct it in the quickest delays, they can avoid loosing the next satellite telemetry (TM) data, thus saving precious time and costs. This would increase both the availability and maintainability of the system. In a larger framework, ODMs are ideally concurrently built and connected with the engineering and safety models of the system, in a sort of virtual continuous improvement loop. While the utter purpose of ODMs is their usage as the system's DTs during operations, they also contribute to the stations' architecture and robustness continuous improvement, through increasing its fault detection and mitigation capabilities.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {473–480},
numpages = {8},
keywords = {operational diagnosis, model-based operations (MBO), model-based diagnosis (MBD), ground systems operations, fault trees (FTs), digital twins (DTs), behaviour trees (BTs), MBSE, MBSA},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3375555.3384936,
author1 = {Avritzer, Alberto},
title = {Automated Scalability Assessment in DevOps Environments},
year = {2020},
isbn = {9781450371094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375555.3384936},
doi = {10.1145/3375555.3384936},
abstract = {In this extended abstract, we provide an outline of the presentation planned for WOSP-C 2020. The goal of the presentation is to provide an overview of the challenges and approaches for automated scalability assessment in the context of DevOps and microservices. The focus of this presentation is on approaches that employ automated identification of performance problems because these approaches can leverage performance anti-pattern[5] detection technology. In addition, we envision extending the approach to recommend component refactoring. In our previous work[1,2] we have designed a methodology and associated tool support for the automated scalability assessment of micro-service architectures, which included the automation of all the steps required for scalability assessment. The presentation starts with an introduction to dependability, operational Profile Data, and DevOps. Specifically, we provide an overview of the state of the art in continuous performance monitoring technologies[4] that are used for obtaining operational profile data using APM tools. We then present an overview of selected approaches for production and performance testing based on the application monitoring tool (PPTAM) as introduced in [1,2]. The presentation concludes by outlining a vision for automated performance anti-pattern[5] detection. Specifically, we present the approach introduced for automated anti-pattern detection based on load testing results and profiling introduced in[6] and provide recommendations for future research.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {10},
numpages = {1},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@inproceedings{10.1109/MODELS-C.2019.00073,
author1 = {Mezei, Gergely and Theisz, Zolt\'{a}n and B\'{a}csi, S\'{a}ndor and Somogyi, Ferenc A. and Palatinszky, D\'{a}niel},
title = {Towards flexible, rigorous refinement in metamodeling},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00073},
doi = {10.1109/MODELS-C.2019.00073},
abstract = {One of the main motivations behind modeling has always been to use a higher level of abstraction than usual programming languages. Metamodeling added the ability to create models of models, and thus the creation of efficient, domain-specific workbenches became simple and fast. However, the rising popularity of model-driven development revealed an important limitation: in the case of classical metamodeling, the definition and the usage of the domain are separated in time and are not to be mixed. Moreover, in the age of Industry 4.0, there is a real need for solutions that support the fine-graded, stepwise refinement of concepts instead of having a rigid, two (or four) level modeling structure. In our research group, we are working on a new metamodeling approach that supports stepwise refinement and gradual constraining of concepts. Although we originally aimed to create a multi-level solution, we realized that the result is worth discussing from the flexibility's point of view as well. In this paper, we elaborate features related to flexible modeling that we have identified, and show how these features were realized in our approach.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {455–459},
numpages = {5},
keywords = {multi-layer modeling, meta-modeling, gradual refinement, flexible modeling, dynamic modeling, DMLA},
location = {Munich, Germany},
series = {MODELS '19}
}

@article{10.1145/3699839.3699841,
author1 = {Awad, Hiba and Alidra, Abdelghani and Bruneliere, Hugo and Ledoux, Thomas and Rivalan, Jonathan},
title = {VeriFog: A Generic Model-based Approach for Verifying Fog Systems at Design Time and Generating Deployment Configurations},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {1559-6915},
url = {https://doi.org/10.1145/3699839.3699841},
doi = {10.1145/3699839.3699841},
abstract = {Fog Computing is a paradigm decentralizing the Cloud by geographically distributing computation, storage, network resources and related services. It provides benefits such as reducing the number of bottlenecks, limiting unwanted data movements, etc. However, managing the size, complexity and heterogeneity of the Fog systems to be engineered is challenging and can quickly become costly. According to best practices in software engineering, verification tasks could be performed on a system design prior to its implementation and deployment. We propose a generic model-based approach for verifying Fog systems at design time, also enabling the automatic generation of corresponding deployment configuration files. Named VeriFog, this approach is notably based on a customizable Fog Modeling Language (FML). We experimented in practice by modeling three use cases, from three different application domains, and by considering three main types of non-functional properties to be verified. From this modeling and verification effort, we show that we are able to automatically generate usable deployment configuration files for different deployment tools. In direct collaboration with our industrial partner Smile, the approach and underlying language presented in this paper are necessary steps towards a more global model-based support for the complete life cycle of Fog systems.},
journal = {SIGAPP Appl. Comput. Rev.},
month = oct,
pages = {18–36},
numpages = {19},
keywords = {deployment configuration, design time, fog computing, generation, model-based engineering, modeling language, non-functional properties, verification}
}

@inproceedings{10.5555/3291291.3291317,
author1 = {Rivera, Luis F. and Villegas, Norha M. and Tamura, Gabriel and Jim\'{e}nez, Miguel and M\"{u}ller, Hausi A.},
title = {UML-driven automated software deployment},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software companies face the challenge of ensuring customer satisfaction through the continuous delivery of functionalities and rapid response to quality issues. However, achieving frequent software delivery is not a trivial task. It requires agile---and continuous---design, development and deployment of existing and new software features. Over time, managing these systems becomes increasingly complex. This complexity stems, in part, from the deployment pipelines and the myriad possible configurations of the software components. Furthermore, software deployment is a time-consuming and error-prone process, which, even when automated, can lead to configuration errors and cost overruns. In this paper, we address deployment challenges that developers face during continuous delivery and DevOps. Our proposal consists of Urano, a mechanism for automating the deployment process, which uses UML, an interoperable and de facto modeling standard, as a means of specifying a software architecture and its associated deployment. Our approach is based on the model-driven architecture principles to generate executable deployment specifications from user-defined UML deployment diagrams. We extend this kind of diagrams by defining and applying a UML profile that captures the semantics and requirements of the installation, configuration, and update of software components. Thus, enabling more expressive deployment specifications and their automatic realization. To evaluate Urano, we conducted three case studies that demonstrate its potential to effectively automate software deployment processes in industry.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {257–268},
numpages = {12},
keywords = {model-driven engineering, model-driven architecture, deployment, continuous delivery, UML, DevOps},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inproceedings{10.1145/2945408.2945411,
author1 = {Di Nitto, Elisabetta and Jamshidi, Pooyan and Guerriero, Michele and Spais, Ilias and Tamburri, Damian A.},
title = {A software architecture framework for quality-aware DevOps},
year = {2016},
isbn = {9781450344111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2945408.2945411},
doi = {10.1145/2945408.2945411},
abstract = {DevOps is an emerging software engineering strategy entailing the joined efforts of development and operations people, their concerns and best practices with the purpose of realising a coherent working group for increased software development and operations speed. To allow software architecture practitioners to enrich and properly elaborate their architecture specifications in a manner which is consistent with DevOps, we surveyed a number of DevOps stakeholders. We studied concerns and challenges to be tackled with respect to preparing a software architecture which is DevOps-ready, i.e., described in all details needed to enact DevOps scenarios. Subsequently, we introduce SQUID, that stands for Specification Quality In DevOps. SQUID is a software architecture framework that supports the model-based documentation of software architectures and their quality properties in DevOps scenarios with the goal of providing DevOps-ready software architecture descriptions. We illustrate our framework in a case-study in the Big Data domain.},
booktitle = {Proceedings of the 2nd International Workshop on Quality-Aware DevOps},
pages = {12–17},
numpages = {6},
keywords = {QoS, QoD, Model-Driven Design, Architecture Frameworks},
location = {Saarbr\"{u}cken, Germany},
series = {QUDOS 2016}
}

@article{10.1145/3651620,
author1 = {Vitharana, Padmal and Daya, Shahir A.},
title = {Adopting and Sustaining Microservice-Based Software Development},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3651620},
doi = {10.1145/3651620},
abstract = {Organizational challenges can be more difficult than technical ones.},
journal = {Commun. ACM},
month = jul,
pages = {34–41},
numpages = {8}
}

@article{10.1145/3587691,
author1 = {Hirzel, Martin},
title = {Low-Code Programming Models},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3587691},
doi = {10.1145/3587691},
abstract = {Low-code has the potential to empower more people to automate tasks by creating computer programs.},
journal = {Commun. ACM},
month = sep,
pages = {76–85},
numpages = {10}
}

@inproceedings{10.1145/3417990.3422004,
author1 = {Khalajzadeh, Hourieh and Verma, Tarun and Simmons, Andrew J. and Grundy, John and Abdelrazek, Mohamed and Hosking, John},
title = {User-centred tooling for modelling of big data applications},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3422004},
doi = {10.1145/3417990.3422004},
abstract = {We outline the key requirements for a Big Data modelling recommender tool. Our web-based tool is suitable for capturing system requirements in big data analytics applications involving diverse stakeholders. It promotes awareness of the datasets and algorithm implementations that are available to leverage in the design of the solution. We implement these ideas in BiDaML-web, a proof of concept recommender system for Big Data applications, and evaluate the tool using an empirical study with a group of 16 target end-users. Participants found the integrated recommender and technique suggestion tools helpful and highly rated the overall BiDaML web-based modelling experience. BiDaML-web is available at https://bidaml.web.app/ and the source code can be accessed at https://github.com/tarunverma23/bidaml.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {7},
numpages = {5},
keywords = {recommender, big data applications, BiDaML},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3624486.3624507,
author1 = {Villanueva, Eliseo and Torres, Ismael and Osaba, Eneko and Canzoneri, Sergio and Franchini, Andrea and Blasi, Lorenzo},
title = {PIACERE Integrated Development Environment},
year = {2023},
isbn = {9798400708350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624486.3624507},
doi = {10.1145/3624486.3624507},
abstract = {This article presents a model-driven engineering (MDE) integrated development environment (IDE) to assist the DevSecOps (Development Security and Operations) process. This tool has been developed within the PIACERE H2020 project, which proposes a framework composed of a set of tools developed to support all phases of the DevSecOps life cycle including modeling, test/validation, build/generate, deployment, operate and modeling. PIACERE IDE is an Eclipse based tool, that acts as the front-end for this framework, and plays a key role in integrating other PIACERE tools. The IDE allows developers to access the different tools in a simple and unified way.},
booktitle = {Proceedings of the 3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum},
pages = {62–66},
numpages = {5},
keywords = {DevSecOps, Eclipse, IDE (integrated development environment), IaC (Infrastructure as Code)},
location = {Ludwigsburg, Germany},
series = {eSAAM '23}
}

@inproceedings{10.1145/3510457.3513054,
author1 = {Zhou, Xin and Huang, Huang and Zhang, He and Huang, Xin and Shao, Dong and Zhong, Chenxin},
title = {A cross-company ethnographic study on software teams for DevOps and microservices: organization, benefits, and issues},
year = {2022},
isbn = {9781450392266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510457.3513054},
doi = {10.1145/3510457.3513054},
abstract = {Context: DevOps and microservices are acknowledged to be important new paradigms to tackle contemporary software demands and provide capabilities for rapid and reliable software development. Industrial reports show that they are quickly adopted together in massive software companies. However, because of the technical and organizational requirements, many difficulties against efficient implementation of the both emerge in real software teams. Objectives: This study aims to discover the organization, benefits and issues of software teams using DevOps &amp; microservices from an immersive perspective. Method: An ethnographic study was carried out in three companies with different business, size, products, customers, and degree of globalization. All the three companies claimed their adoption of DevOps and microservices. Seven months (cumulative) of participant observations and nine interviews with practitioners were conducted to collect the data of software teams related to DevOps and microservices. A cross-company empirical investigation using grounded theory was done by analyzing the archive data. Results: The virtual software teams were organized for adopting DevOps and microservices under the stubborn organizational structure. The adoption of DevOps and microservices brings benefits to rapid delivery, ability improvements and burden reduction, whilst the high cost and lack of practical guidance were emerged. Two major issues of adopting DevOps and microservices in software teams (i.e. fragmentary DevOps and abuse of microservices) were found common in the companies. Moreover, our observations and interviews reflect that in software teams, the relationship between DevOps and microservices is not significant, which differs from the relationship described in the previous studies. Four lessons for practitioners and four implications for researchers were discussed based on our findings. Conclusion: Our findings contribute to the understanding of the organization, benefits and issues of adopting DevOps and microservices from an immersive perspective of software teams.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
pages = {1–10},
numpages = {10},
keywords = {DevOps, ethnographic study, interview, microservices, participant observation},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIP '22}
}

@inproceedings{10.1145/3422392.3422447,
author1 = {Medeiros, Carlos Alberto and Bandeira, Alan and Maia, Paulo Henrique M. and Paixao, Matheus},
title = {MDE in the Wild: An Exploratory Analysis on What Developers are Discussing from Q&amp;A Platforms},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422447},
doi = {10.1145/3422392.3422447},
abstract = {Model-Driven Engineering (MDE) is an approach that considers models as first-class entities used in the software analysis, design and implementation. Although MDE has become popular in both academia and industry as an alternative for tackling the growing complexity of modern software, MDE has not been largely adopted in the software development process. A possible way to mitigate those problems consists of understanding how MDE has been applied in practice and what are the main barriers found by developers. Hence, this paper presents an exploratory study to analyse the discussions about MDE from two Q&amp;A platforms: Stack Overflow and Software Engineering Stack Exchange. One hundred fourteen discussions have been analysed under four perspectives: discussion type, application domain, tools, and developer interest. As a result, we identified that 69, 30% of the discussions regard technical aspects, from which metamodelling is the most discussed topic, and Xtext is the most discussed tool. In addition, we observed that discussions in which developers suggest MDE-related tools tend to attract more views and answers.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {157–166},
numpages = {10},
keywords = {Mining Software Repositories, Model-Driven Engineering},
location = {Natal, Brazil},
series = {SBES '20}
}

@inproceedings{10.1109/ICSE-NIER52604.2021.00028,
author1 = {Vierhauser, Michael and Marah, Hussein and Garmendia, Antonio and Cleland-Huang, Jane and Wimmer, Manuel},
title = {Towards a model-integrated runtime monitoring infrastructure for cyber-physical systems},
year = {2021},
isbn = {9780738133249},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER52604.2021.00028},
doi = {10.1109/ICSE-NIER52604.2021.00028},
abstract = {Runtime monitoring is essential for ensuring the safe operation and enabling self-adaptive behavior of Cyber-Physical Systems (CPS). It requires the creation of system monitors, instrumentation for data collection, and the definition of constraints. All of these aspects need to evolve to accommodate changes in the system. However, most existing approaches lack support for the automated generation and setup of monitors and constraints for diverse technologies and do not provide adequate support for evolving the monitoring infrastructure. Without this support, constraints and monitors can become stale and become less effective in long-running, rapidly changing CPS. In this "new and emerging results" paper we propose a novel framework for model-integrated runtime monitoring. We combine model-driven techniques and runtime monitoring to automatically generate large parts of the monitoring framework and to reduce the maintenance effort necessary when parts of the monitored system change. We build a prototype and evaluate our approach against a system for controlling the flights of unmanned aerial vehicles.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {96–100},
numpages = {5},
keywords = {runtime monitoring, model-driven engineering, evolution, cyber-physical systems},
location = {Virtual Event, Spain},
series = {ICSE-NIER '21}
}

@inproceedings{10.1145/3417990.3420204,
author1 = {Khorram, Faezeh and Mottu, Jean-Marie and Suny\'{e}, Gerson},
title = {Challenges &amp; opportunities in low-code testing},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420204},
doi = {10.1145/3417990.3420204},
abstract = {Low-code is a growing development approach supported by many platforms. It fills the gap between business and IT by supporting the active involvement of non-technical domain experts, named Citizen Developer, in the application development lifecycle.Low-code introduces new concepts and characteristics. However, it is not investigated yet in academic research to point out the existing challenges and opportunities when testing low-code software. This shortage of resources motivates this research to provide an explicit definition to this area that we call it Low-Code Testing.In this paper, we initially conduct an analysis of the testing components of five commercial Low-Code Development Platforms (LCDP) to present low-code testing advancements from a business point of view. Based on the low-code principles as well as the result of our analysis, we propose a feature list for low-code testing along with possible values for them. This feature list can be used as a baseline for comparing low-code testing components and as a guideline for building new ones. Accordingly, we specify the status of the testing components of investigated LCDPs based on the proposed features. Finally, the challenges of low-code testing are introduced considering three concerns: the role of citizen developer in testing, the need for high-level test automation, and cloud testing. We provide references to the state-of-the-art to specify the difficulties and opportunities from an academic perspective. The results of this research can be used as a starting point for future research in low-code testing area.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {70},
numpages = {10},
keywords = {testing, low-code development platform, low-code, citizen developer},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3417990.3421264,
author1 = {Wiecher, Carsten and Japs, Sergej and Kaiser, Lydia and Greenyer, Joel and Dumitrescu, Roman and Wolff, Carsten},
title = {Scenarios in the loop: integrated requirements analysis and automotive system validation},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3421264},
doi = {10.1145/3417990.3421264},
abstract = {The development of safety-relevant systems in the automotive industry requires the definition of high-quality requirements and tests for the coordination and monitoring of development activities in an agile development environment. In this paper we describe a Scenarios in the Loop (SCIL) approach. SCIL combines (1) natural language requirements specification based on Behavior-Driven Development (BDD) with (2) formal and test-driven requirements modeling and analysis, and (3) integrates discipline-specific tools for software and system validation during development. A central element of SCIL is a flexible and executable scenario-based modeling language, the Scenario Modeling Language for Kotlin (SMLK). SMLK allows for an intuitive requirements formalization, and supports engineers to move iteratively, and continuously aided by automated checks, from stakeholder requirements to the validation of the implemented system. We evaluated the approach using a real example from the field of e-mobility.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {35},
numpages = {10},
keywords = {system validation, requirements analysis, automotive systems engineering, BizDevOps},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3605098.3635973,
author1 = {Awad, Hiba and Alidra, Abdelghani and Bruneliere, Hugo and Ledoux, Thomas and Leclercq, Etienne and Rivalan, Jonathan},
title = {VeriFog: A Generic Model-based Approach for Verifying Fog Systems at Design Time},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635973},
doi = {10.1145/3605098.3635973},
abstract = {Fog Computing is a paradigm aiming to decentralize the Cloud by geographically distributing away computation, storage, network resources and related services. It provides several benefits such as reducing the number of bottlenecks, limiting unwanted data movements, etc. However, managing the size, complexity and heterogeneity of Fog systems to be designed, developed, tested, deployed, and maintained, is challenging and can quickly become costly. According to best practices in software engineering, verification tasks could be performed on system design prior to its actual implementation and deployment. Thus, we propose a generic model-based approach for verifying Fog systems at design time. Named VeriFog, this approach is notably based on a customizable Fog Modeling Language (FML). We experimented with our approach in practice by modeling three use cases, from three different application domains, and by considering three main types of non-functional properties to be verified. In direct collaboration with our industrial partner Smile, the approach and underlying language presented in this paper are necessary steps towards a more global model-based support for the complete life cycle of Fog systems.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1252–1261},
numpages = {10},
keywords = {model-based engineering, modeling language, fog computing, verification, non-functional properties, design time},
location = {Avila, Spain},
series = {SAC '24}
}

@article{10.1145/3637228,
author1 = {Ca\~{n}izares, Pablo C. and L\'{o}pez-Morales, Jose Mar\'{\i}a and P\'{e}rez-Soler, Sara and Guerra, Esther and de Lara, Juan},
title = {Measuring and Clustering Heterogeneous Chatbot Designs},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3637228},
doi = {10.1145/3637228},
abstract = {Conversational agents, or chatbots, have become popular to access all kind of software services. They provide an intuitive natural language interface for interaction, available from a wide range of channels including social networks, web pages, intelligent speakers or cars. In response to this demand, many chatbot development platforms and tools have emerged. However, they typically lack support to statically measure properties of the chatbots being built, as indicators of their size, complexity, quality or usability. Similarly, there are hardly any mechanisms to compare and cluster chatbots developed with heterogeneous technologies.To overcome this limitation, we propose a suite of 21 metrics for chatbot designs, as well as two clustering methods that help in grouping chatbots along their conversation topics and design features. Both the metrics and the clustering methods are defined on a neutral chatbot design language, becoming independent of the implementation platform. We provide automatic translations of chatbots defined on some major platforms into this neutral notation to perform the measurement and clustering. The approach is supported by our tool Asymob, which we have used to evaluate the metrics and the clustering methods over a set of 259 Dialogflow and Rasa chatbots from open-source repositories. The results open the door to incorporating the metrics within chatbot development processes for the early detection of quality issues, and to exploit clustering to organise large collections of chatbots into significant groups to ease chatbot comprehension, search and comparison.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {90},
numpages = {43},
keywords = {Chatbot design, metrics, clustering, quality assurance, model-driven engineering}
}

@inproceedings{10.1145/2976767.2976812,
author1 = {Harrand, Nicolas and Fleurey, Franck and Morin, Brice and Husa, Knut Eilif},
title = {ThingML: a language and code generation framework for heterogeneous targets},
year = {2016},
isbn = {9781450343213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976767.2976812},
doi = {10.1145/2976767.2976812},
abstract = {One of the selling points of Model-Driven Software Engineering (MDSE) is the increase in productivity offered by automatically generating code from models. However, the practical adoption of code generation remains relatively slow and limited to niche applications. Tooling issues are often pointed out but more fundamentally, experience shows that: (i) models and modeling languages used for other purposes are not necessarily well suited for code generation and (ii) code generators are often seen as black-boxes which are not easy to trust and produce sub-optimal code. This paper presents and discusses our experiences applying the ThingML approach to different domains. ThingML includes a modeling language and tool designed for supporting code generation and a highly customizable multi-platform code generation framework. The approach is implemented in an open-source tool providing a family of code generators targeting heterogeneous platforms. It has been evaluated through several case studies and is being used for in the development of a commercial ambient assisted living system.},
booktitle = {Proceedings of the ACM/IEEE 19th International Conference on Model Driven Engineering Languages and Systems},
pages = {125–135},
numpages = {11},
keywords = {heterogeneous, customization, code generation, MDE, DSML},
location = {Saint-malo, France},
series = {MODELS '16}
}

@article{10.1145/3591335.3591350,
author1 = {Bagnato, Alessandra and Krasnodebska, J\'{o}zefina},
title = {MORPHEMIC - Optimization of the Deployment and Life-cycle Management of Data-intensive Applications in the Cloud Computing Continuum},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3591335.3591350},
doi = {10.1145/3591335.3591350},
abstract = {In their Cloud strategy companies are choosing more and more multi-cloud computing giving them the opportunity to distribute its assets, redundancies, software, applications, and anything it deems worthy not only on one Cloud-hosting environment, but rather across several. The model of using multiple Cloud services to host the business's functions and features has a list of advantages that can provide security, flexibility, cost-effectiveness and more to increase business's efficiency and ensure it stays up and running 24 hours a day. The paper presents the MORPHEMIC H2020 project and its unique way of adapting and optimising Cloud computing applications. The Morphemic project covers several features from modelling cross-cloud applications, continuous and autonomous optimization and deployment and providing access to several cloud capabilities for data intensive applications. The outcome of the project will be implemented in the form of an open-source platform covering all the data intensive applications deployment phases starting from modelling, through profiling, optimization, runtime reconfiguration and monitoring.},
journal = {Ada Lett.},
month = apr,
pages = {104–108},
numpages = {5},
keywords = {multi-cloud platform, model-driven engineering, cloud services, cloud computing}
}

@inproceedings{10.1109/ICSE-C.2017.162,
author1 = {Arta\v{c}, Matej and Borov\v{s}ak, Tadej and Di Nitto, Elisabetta and Guerriero, Michele and Tamburri, Damian Andrew},
title = {DevOps: introducing infrastructure-as-code},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.162},
doi = {10.1109/ICSE-C.2017.162},
abstract = {DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes. One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud. This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS "Topology and Orchestration Specification for Cloud Applications" (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {497–498},
numpages = {2},
keywords = {infrastructure-as-code, TOSCA, DevOps},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1145/3277593.3277602,
author1 = {Nguyen, Phu H. and Phung, Phu H. and Truong, Hong-Linh},
title = {A security policy enforcement framework for controlling IoT tenant applications in the edge},
year = {2018},
isbn = {9781450365642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277593.3277602},
doi = {10.1145/3277593.3277602},
abstract = {In the context of edge computing, IoT-as-a-Service (IoTaaS) with IoT data hubs and execution services allow IoT tenant applications (apps) to be executed next to IoT devices, enabling edge analytics and controls. However, this brings up new security challenges on controlling tenant apps in IoTaaS, whilst the great potential of IoTaaS can only be realized by flexible security mechanisms to govern such applications. In this paper, we propose a Model-Driven Security policy enforcement framework, named MDSIoT, for IoT tenant apps deployed in edge servers. This framework allows execution policies specified at the model level and then transformed into the code that can be deployed for policy enforcement at runtime. Moreover, our approach supports for the interoperability of IoT tenant apps when deployed in the edge to access IoTaaS services. The interoperability is enabled by an intermediate proxy layer (gatekeeper) that abstracts underlying communication protocols to the different IoTaaS services from IoT tenant apps. Therefore, our approach supports different IoT tenant apps to be deployed and controlled automatically, independently from their technologies, e.g. programming languages. We have developed a proof-of-concept of the proposed gatekeepers based on ThingML, derived from execution policies. Thanks to the ThingML tool, we can generate platform-specific code of gatekeepers that can be deployed in the edge for controlling IoT tenant apps based on the execution policies.},
booktitle = {Proceedings of the 8th International Conference on the Internet of Things},
articleno = {4},
numpages = {8},
keywords = {services computing, model-driven security, edge computing, access control, ThingML, IoT},
location = {Santa Barbara, California, USA},
series = {IOT '18}
}

@inproceedings{10.1109/ASE56229.2023.00154,
author1 = {Birchler, Christian and Rohrbach, Cyrill and Kim, Hyeongkyun and Gambi, Alessio and Liu, Tianhai and Horneber, Jens and Kehrer, Timo and Panichella, Sebastiano},
title = {TEASER: Simulation-based CAN Bus Regression Testing for Self-driving Cars Software},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00154},
doi = {10.1109/ASE56229.2023.00154},
abstract = {Safety-critical systems such as self-driving cars (SDCs) must be rigorously tested. Especially electronic control units (ECUs) of SDCs should be tested with realistic input data. In this context, a communication protocol called Controller Area Network (CAN) is typically used to transfer sensor data to the SDC control units. A challenge for SDC maintainers and testers is the need to manually define the CAN inputs that realistically represent the state of the SDC in the real world. To address this challenge, we developed TEASER; a tool that generates realistic CAN signals for SDCs obtained from sensors from state-of-the-art car simulators. We evaluated TEASER based on its integration capability into a DevOps pipeline of aicas GmbH, a company in the automotive sector. Concretely, we integrated TEASER in a Continous Integration (CI) pipeline configured with Jenkins. The pipeline executes the test cases in simulation environments and sends the sensor data over the CAN bus to a physical CAN device, the test subject. Our evaluation shows the ability of TEASER to generate and execute CI test cases that expose simulation-based faults (using regression strategies); the tool produces CAN inputs that realistically represent the state of the SDC in the real world. This result is critically important for increasing the automation and effectiveness of simulation-based CAN bus regression testing for SDCs.Tool: https://doi.org/10.5281/zenodo.7964890GitHub: https://github.com/christianbirchler-org/sdc-scissor/releases/tag/v2.2.0-rc.1Documentation: https://sdc-scissor.readthedocs.io},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2058–2061},
numpages = {4},
keywords = {autonomous systems, regression testing, simulation environment, CAN bus},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@article{10.1145/3653697,
author1 = {Shankar, Shreya and Garcia, Rolando and Hellerstein, Joseph M. and Parameswaran, Aditya G.},
title = {"We Have No Idea How Models will Behave in Production until Production": How Engineers Operationalize Machine Learning},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653697},
doi = {10.1145/3653697},
abstract = {Organizations rely on machine learning engineers (MLEs) to deploy models and maintain ML pipelines in production. Due to models' extensive reliance on fresh data, the operationalization of machine learning, or MLOps, requires MLEs to have proficiency in data science and engineering. When considered holistically, the job seems staggering---how do MLEs do MLOps, and what are their unaddressed challenges? To address these questions, we conducted semi-structured ethnographic interviews with 18 MLEs working on various applications, including chatbots, autonomous vehicles, and finance. We find that MLEs engage in a workflow of (i) data preparation, (ii) experimentation, (iii) evaluation throughout a multi-staged deployment, and (iv) continual monitoring and response. Throughout this workflow, MLEs collaborate extensively with data scientists, product stakeholders, and one another, supplementing routine verbal exchanges with communication tools ranging from Slack to organization-wide ticketing and reporting systems. We introduce the 3Vs of MLOps: velocity, visibility, and versioning --- three virtues of successful ML deployments that MLEs learn to balance and grow as they mature. Finally, we discuss design implications and opportunities for future work.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {206},
numpages = {34},
keywords = {interview study, mlops}
}

@inproceedings{10.5555/3291291.3291319,
author1 = {Beigi-Mohammadi, Nasim and Litoiu, Marin and Emami-Taba, Mahsa and Tahvildari, Ladan and Fokaefs, Marios and Merlo, Ettore and Onut, Iosif Viorel},
title = {A DevOps framework for quality-driven self-protection in web software systems},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Modern software is developed, deployed and operates continuously. At the same time, cyberattacks are on the rise. The continuity of development and operations and the constant threat of attacks requires novel approaches to identify, analyze and address potential security vulnerabilities. In this continuous and volatile execution environment, factors like security, performance, cost and functionality may not be able to be guaranteed in the same degree at the same time. In this work, we propose a DevOps framework for security adaptation that enables the development and operations teams to collaborate and address security vulnerabilities. The proposed framework spans across the different phases of software (development, operations, maintenance) and considers all other factors (performance, cost, functionality), when deciding for security adaptations. We demonstrate the approach on a prototype tool that shows how teams work together to tackle security concerns.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {270–274},
numpages = {5},
keywords = {web software, software defined infrastructure, self-protection, self-adaptive systems, security, devops},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inproceedings{10.1145/3053600.3053631,
author1 = {Guerriero, Michele and Tamburri, Damian A. and Ridene, Youssef and Marconi, Francesco and Bersani, Marcello M. and Artac, Matej},
title = {Towards DevOps for Privacy-by-Design in Data-Intensive Applications: A Research Roadmap},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053631},
doi = {10.1145/3053600.3053631},
abstract = {With the onset of Big Data and Data-Intensive Applications (DIAs) exploiting such big data, the problem of offering privacy guarantees to data owners becomes crucial, even more so with the emergence of DevOps development strategies where speed is paramount. This paper outlines this complex scenario and the challenges therein. On one hand, we outline a tool prototype that addresses the key challenge we found in industry, more specifically, assisting the process of continuous DIA architecting for the purpose of offering privacy-by-design guarantees. On the other hand we define a research roadmap in pursuit of a more correct and complete solution for ensured privacy-by-design in the context of Big Data DevOps.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {139–144},
numpages = {6},
keywords = {trace-checking, privacy-by-design, devops, big data},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/3486607.3486753,
author1 = {Jouneaux, Gwendal and Barais, Olivier and Combemale, Benoit and Mussbacher, Gunter},
title = {Towards self-adaptable languages},
year = {2021},
isbn = {9781450391108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486607.3486753},
doi = {10.1145/3486607.3486753},
abstract = {Over recent years, self-adaptation has become a concern for many software systems that have to operate in complex and changing environments. At the core of self-adaptation, there is a feedback loop and associated trade-off reasoning to decide on the best course of action. However, existing software languages do not abstract the development and execution of such feedback loops for self-adaptable systems. Developers have to fall back to ad-hoc solutions to implement self-adaptable systems, often with wide-ranging design implications (e.g., explicit MAPE-K loop). Furthermore, existing software languages do not capitalize on monitored usage data of a language and its modeling environment. This hinders the continuous and automatic evolution of a software language based on feedback loops from the modeling environment and runtime software system. To address the aforementioned issues, this paper introduces the concept of Self-Adaptable Language (SAL) to abstract the feedback loops at both system and language levels. We propose L-MODA (Language, Models, and Data) as a conceptual reference framework that characterizes the possible feedback loops abstracted into a SAL. To demonstrate SALs, we present emerging results on the abstraction of the system feedback loop into the language semantics. We report on the concept of Self-Adaptable Virtual Machines as an example of semantic adaptation in a language interpreter and present a roadmap for SALs.},
booktitle = {Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {97–113},
numpages = {17},
keywords = {trade-off analysis, software language, self-adaptation, feedback loop, L-MODA framework},
location = {Chicago, IL, USA},
series = {Onward! 2021}
}

@inproceedings{10.5555/2820489.2820507,
author1 = {Casale, G. and Ardagna, D. and Artac, M. and Barbier, F. and Nitto, E. Di and Henry, A. and Iuhasz, G. and Joubert, C. and Merseguer, J. and Munteanu, V. I. and P\'{e}rez, J. F. and Petcu, D. and Rossi, M. and Sheridan, C. and Spais, I. and Vladu\v{s}i\v{c}, D.},
title = {DICE: quality-driven development of data-intensive cloud applications},
year = {2015},
publisher = {IEEE Press},
abstract = {Model-driven engineering (MDE) often features quality assurance (QA) techniques to help developers creating software that meets reliability, efficiency, and safety requirements. In this paper, we consider the question of how quality-aware MDE should support data-intensive software systems. This is a difficult challenge, since existing models and QA techniques largely ignore properties of data such as volumes, velocities, or data location. Furthermore, QA requires the ability to characterize the behavior of technologies such as Hadoop/MapReduce, NoSQL, and stream-based processing, which are poorly understood from a modeling standpoint. To foster a community response to these challenges, we present the research agenda of DICE, a quality-aware MDE methodology for data-intensive cloud applications. DICE aims at developing a quality engineering tool chain offering simulation, verification, and architectural optimization for Big Data applications. We overview some key challenges involved in developing these tools and the underpinning models.},
booktitle = {Proceedings of the Seventh International Workshop on Modeling in Software Engineering},
pages = {78–83},
numpages = {6},
keywords = {quality assurance, model-driven engineering, big data},
location = {Florence, Italy},
series = {MiSE '15}
}

@inproceedings{10.1145/2962695.2962707,
author1 = {Jabbari, Ramtin and bin Ali, Nauman and Petersen, Kai and Tanveer, Binish},
title = {What is DevOps? A Systematic Mapping Study on Definitions and Practices},
year = {2016},
isbn = {9781450341349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2962695.2962707},
doi = {10.1145/2962695.2962707},
abstract = {Context: DevOps, the combination of Development and Operations, is a new way of thinking in the software engineering domain that recently received much attention. Given that DevOps is a new term and novel concept recently introduced, no common understanding of what it entails has been achieved yet. Consequently, definitions of DevOps often only represent a part that is relevant to the concept.Objective:This study aims to characterize DevOps by exploring central components of DevOps definitions reported in the literature, specifying practices explicitly proposed for DevOps and investigating the similarities and differences between DevOps and other existing methods in software engineering.Method: A systematic mapping study was conducted that used six electronic databases: IEEE, ACM, Inspec, Scopus, Wiley Online Library and Web of Science.Result: 44 studies have been selected that report a definition of DevOps, 15 studies explicitly stating DevOps practices, and 15 studies stating how DevOps is related to other existing methods. Papers in some cases stated a combination of a definition, practices, and relations to other methods, the total number of primary studies was 49.Conclusion: We proposed a definition for DevOps which may overcome inconsistencies over the various existing definitions of individual research studies. In addition, the practices explicitly proposed for DevOps have been presented as well as the relation to other software development methods.},
booktitle = {Proceedings of the Scientific Workshop Proceedings of XP2016},
articleno = {12},
numpages = {11},
keywords = {Software development method, DevOps practice, DevOps definition},
location = {Edinburgh, Scotland, UK},
series = {XP '16 Workshops}
}

@inproceedings{10.1145/2804371.2804377,
author1 = {Ferry, Nicolas and Chauvel, Franck and Song, Hui and Solberg, Arnor},
title = {Continous deployment of multi-cloud systems},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804377},
doi = {10.1145/2804371.2804377},
abstract = {In this paper we present our mechanism and tooling for the continuous deployment and resource provisioning of multi-cloud applications. In order to facilitate collaboration between development and operation teams as promoted in the DevOps movement, our deployment and resource provisioning engine is based on the Models@Runtime principles. This enables applying the same concepts and language (i.e., CloudML) for deployment and resource provisioning at development-and operation-time.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {27–28},
numpages = {2},
keywords = {model-driven engineering, deployment, Models@Runtime, CloudML, Cloud computing},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}

@inproceedings{10.1109/UCC.2014.36,
author1 = {Ferry, Nicolas and Song, Hui and Rossini, Alessandro and Chauvel, Franck and Solberg, Arnor},
title = {Cloud MF: Applying MDE to Tame the Complexity of Managing Multi-cloud Applications},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.36},
doi = {10.1109/UCC.2014.36},
abstract = {The market of cloud computing encompasses an ever-growing number of cloud providers offering a multitude of infrastructure-as-a-service (IaaS) and platform-as-a-service (PaaS) solutions. The heterogeneity of these solutions hinders the proper exploitation of cloud computing since it prevents interoperability and promotes vendor lock-in, which increases the complexity of executing and managing multi-cloud applications (i.e., Applications that can be deployed across multiple cloud infrastructures and platforms). Providers of multi-cloud applications seek to exploit the peculiarities of each cloud solution and to combine the delivery models of IaaS and PaaS in order to optimise performance, availability, and cost. In this paper, we show how the Cloud Modelling Framework leverages upon model-driven engineering to tame this complexity by providing: (i) a tool-supported domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for enacting the provisioning, deployment, and adaptation of these applications.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {269–277},
numpages = {9},
keywords = {multi-cloud, Model-driven engineering, Cloud computing, Cloud ML},
series = {UCC '14}
}

@inproceedings{10.1145/3358505.3358522,
author1 = {Alonso, Juncal and Stefanidis, Kyriakos and Orue-Echevarria, Leire and Blasi, Lorenzo and Walker, Michael and Escalante, Marisa and L\'{o}pez, Mar\'{\i}a Jos\'{e} and Dutkowski, Simon},
title = {DECIDE: An Extended DevOps Framework for Multi-cloud Applications},
year = {2019},
isbn = {9781450371650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358505.3358522},
doi = {10.1145/3358505.3358522},
abstract = {DevOps represents a model for application development that enables close collaboration between software developers and IT operations with the objective of implementing continuous integration, continuous delivery and continuous development of software applications. This paper proposes an approach for extending the DevOps philosophy with the objective of supporting the development and operation of multi-cloud native applications deployed over heterogeneous cloud resources. The author1s present the extended DECIDE DevOps framework and the supporting tool suite developed in the context of the DECIDE H2020 action},
booktitle = {Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing},
pages = {43–48},
numpages = {6},
keywords = {deployment optimization, continuous monitoring, continuous adaptation, Multi-cloud, DevOps, Continuous pre-deployment, Continuous Design, Cloud Computing},
location = {Oxford, United Kingdom},
series = {ICCBDC '19}
}

@inproceedings{10.1109/UCC.2014.14,
author1 = {Wettinger, Johannes and Breitenb\"{u}cher, Uwe and Leymann, Frank},
title = {Standards-Based DevOps Automation and Integration Using TOSCA},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.14},
doi = {10.1109/UCC.2014.14},
abstract = {DevOps is an emerging paradigm to tightly integrate developers with operations personnel. This is required to enable fast and frequent releases in the sense of continuously delivering software. Users and customers of today's Web applications and mobile apps running in the Cloud expect fast feedback to problems and feature requests. Thus, it is a critical competitive advantage to be able to respond quickly. Beside cultural and organizational changes that are necessary to implement DevOps in practice, tooling is required to implement end-to-end automation of deployment processes. Automation is the key to efficient collaboration and tight integration between development and operations. The DevOps community is constantly pushing new approaches, tools, and open-source artifacts to implement such automated processes. However, as all these proprietary and heterogeneous DevOps automation approaches differ from each other, it is hard to integrate and combine them to deploy applications in the Cloud. In this paper we present a systematic classification of DevOps artifacts and show how different kinds of artifacts can be transformed toward TOSCA, an emerging standard in this field. This enables the seamless and interoperable orchestration of arbitrary artifacts to model and deploy application topologies. We validate the presented approach by a prototype implementation, show its practical feasibility by a detailed case study, and evaluate its performance.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {59–68},
numpages = {10},
keywords = {Transformation, TOSCA, Juju, DevOps, Deployment Automation, Cloud Standards, Cloud Computing, Chef},
series = {UCC '14}
}

@inproceedings{10.1145/3084100.3084107,
author1 = {Rosenberg, Doug and Boehm, Barry and Wang, Bo and Qi, Kan},
title = {Rapid, evolutionary, reliable, scalable system and software development: the resilient agile process},
year = {2017},
isbn = {9781450352703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084100.3084107},
doi = {10.1145/3084100.3084107},
abstract = {The increasing pace of change in competition, technology, and complexity of software-intensive systems has increased the demand for rapid, reliable, scalable, and evolvable processes. Agile methods have made significant contributions to speeding up software development, but often encounter problems with reliability, scalability, and evolvability. Over the past 3 years, we have been experimenting with an approach called Resilient Agile (RA), which addresses these problems while also speeding up development by finding enablers for parallel systems engineering, development, and test. This paper summarizes our experience in defining and evolving RA by applying it to three representative emergent-technology applications: Location-Based Advertising, Picture Sharing, and Bad Driver Reporting. In comparison with the mainstream Architected Agile process that we had been using on similar systems, the RA process achieved fewer defects and significant speedups in system development and evolution.  The paper summarizes the overall challenge of software schedule compression; identifies managed parallel development as generally the most powerful but least-practiced strategy for schedule compression; summarizes the key elements required to support parallelism, including specific model-driven system development techniques, automatic generation of key elements and realistic schedule and effort estimation. It then summarizes the three successful Resilient Agile projects to date, provides criteria for selecting a Resilient Agile process, and summarizes the key techniques for scaling up Resilient Agile, using a previous million-line command and control project as an example.},
booktitle = {Proceedings of the 2017 International Conference on Software and System Process},
pages = {60–69},
numpages = {10},
keywords = {ICSM, MVC, NoSQL, REST, UML modeling, agile development, code generation, microservice architecture, parallel development, rapid delivery, resilient software, scalable software development, schedule compression, use case driven development},
location = {Paris, France},
series = {ICSSP '17}
}

@inproceedings{10.1145/3643667.3648224,
author1 = {Sep\'{u}lveda, Samuel and Piattini, Mario and P\'{e}rez Del Castillo, Ricardo},
title = {Developing hybrid quantum-classical software: a software product line approach},
year = {2024},
isbn = {9798400705700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643667.3648224},
doi = {10.1145/3643667.3648224},
abstract = {Quantum computing is rapidly emerging as a transformative force in technology. In the near future we will increasingly encounter hybrid systems that combine quantum technology with classical software. Software engineering techniques will be needed to manage the complexity of designing such systems and their reuse. This paper introduces preliminary ideas for developing quantum-classical software using a Software Product Line approach in line with the Model-Driven Engineering principles. This approach addresses the mentioned challenges and drafts a framework for developing hybrid quantum-classical software. The preliminary insights show the feasibility and suitability of applying the proposed approach for developing complex quantum-classical software systems with high levels of variability.},
booktitle = {Proceedings of the 5th ACM/IEEE International Workshop on Quantum Software Engineering},
pages = {37–40},
numpages = {4},
keywords = {quantum computing, software product lines, variability, feature modeling},
location = {Lisbon, Portugal},
series = {Q-SE 2024}
}

@inproceedings{10.1145/2945408.2945412,
author1 = {G\'{o}mez, Abel and Merseguer, Jos\'{e} and Di Nitto, Elisabetta and Tamburri, Damian A.},
title = {Towards a UML profile for data intensive applications},
year = {2016},
isbn = {9781450344111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2945408.2945412},
doi = {10.1145/2945408.2945412},
abstract = {Data intensive applications that leverage Big Data technologies are rapidly gaining market trend. However, their design and quality assurance are far from satisfying software engineers needs. In fact, a CapGemini research shows that only 13% of organizations have achieved full-scale production for their Big Data implementations. We aim at addressing an early design and a quality evaluation of data intensive applications,being our goal to help software engineers on assessing quality metrics, such as the response time of theapplication. We address this goal by means of a quality analysis tool-chain.At the core of the tool, we are developing a Profile that converts the Unified Modeling Language into a domain specific modeling language for quality evaluation of data intensive applications.},
booktitle = {Proceedings of the 2nd International Workshop on Quality-Aware DevOps},
pages = {18–23},
numpages = {6},
keywords = {Unified Modeling Language (UML), UML Profiles, Model-Driven Engineering (MDE), Data-Intensive Applications},
location = {Saarbr\"{u}cken, Germany},
series = {QUDOS 2016}
}

@inproceedings{10.1145/3344948.3344986,
author1 = {Castellanos, Camilo and Varela, Carlos A. and Correal, Dario},
title = {Measuring performance quality scenarios in big data analytics applications: a DevOps and domain-specific model approach},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344986},
doi = {10.1145/3344948.3344986},
abstract = {Big data analytics (BDA) applications use advanced analysis algorithms to extract valuable insights from large, fast, and heterogeneous data sources. These complex BDA applications require software design, development, and deployment strategies to deal with volume, velocity, and variety (3vs) while sustaining expected performance levels. BDA software complexity frequently leads to delayed deployments, longer development cycles and challenging performance monitoring. This paper proposes a DevOps and Domain Specific Model (DSM) approach to design, deploy, and monitor performance Quality Scenarios (QS) in BDA applications. This approach uses high-level abstractions to describe deployment strategies and QS enabling performance monitoring. Our experimentation compares the effort of development, deployment and QS monitoring of BDA applications with two use cases of near mid-air collisions (NMAC) detection. The use cases include different performance QS, processing models, and deployment strategies. Our results show shorter (re)deployment cycles and the fulfillment of latency and deadline QS for micro-batch and batch processing.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {165–172},
numpages = {8},
keywords = {software architecture, performance quality scenarios, domain specific model, big data analytics, DevOps},
location = {Paris, France},
series = {ECSA '19}
}

@article{10.1145/3591335.3591349,
author1 = {Bagnato, Alessandra and Cicchetti, Antonio and Berardinelli, Luca and Bruneliere, Hugo and Eramo, Romina},
title = {AI-augmented Model-Based Capabilities in the AIDOaRt Project: Continuous Development of Cyber-Physical Systems},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3591335.3591349},
doi = {10.1145/3591335.3591349},
abstract = {The paper presents the AIDOaRT project, a 3 years long H2020-ECSEL European project involving 32 organizations, grouped in clusters from 7 different countries, focusing on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in Cyber-Physical Systems (CPS). To this end, the project proposes to combine Model Driven Engineering principles and techniques with AI-enhanced methods and tools for engineering more trustable and reliable CPSs. This paper introduces the AIDOaRt project, its overall objectives, and used requirement engineering methodology. Based on that, it also focuses on describing the current plan regarding a set of tools intended to cover the modelbased capabilities requirements from the project.},
journal = {Ada Lett.},
month = apr,
pages = {99–103},
numpages = {5},
keywords = {model-based engineering, development operations, cyber-physical systems, artificial intelligence}
}

@inproceedings{10.1145/3555776.3577668,
author1 = {Verreydt, Stef and Van Landuyt, Dimitri and Joosen, Wouter},
title = {Expressive and Systematic Risk Assessments with Instance-Centric Threat Models},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577668},
doi = {10.1145/3555776.3577668},
abstract = {A threat modeling exercise involves systematically assessing the likelihood and potential impact of diverse threat scenarios. As threat modeling approaches and tools act at the level of a software architecture or design (e.g., a data flow diagram), they consider threat scenarios at the level of classes or types of system elements. More fine-grained analyses in terms of concrete instances of these elements are typically not conducted explicitly nor rigorously. This hinders (i) expressiveness, as threats that require articulation at the level of instances can not be expressed nor managed properly, and (ii) systematic risk calculation, as risk cannot be expressed and estimated with respect to instance-level properties.In this paper, we present a novel threat modeling approach that acts on two layers: (i) the design layer defines the classes and entity types in the system, and (ii) the instance layer models concrete instances and their properties. This, in turn, allows both rough risk estimates at the design-level, and more precise ones at the instance-level. Motivated by a connected vehicles application, we present the key challenges, the modeling approach and a tool prototype. The presented approach is a key enabler for more continuous and frequent threat (re-)assessment, the integration of threat analysis models in CI/CD pipelines and agile development environments on the one hand (development perspective), and in risk management approaches at run-time (operations perspective).},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {1450–1457},
numpages = {8},
keywords = {risk management, security-by-design, threat modeling},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3622758.3622894,
author1 = {Wilczynski, Peter and Gregoire-Wright, Taylor and Jackson, Daniel},
title = {Concept-Centric Software Development: An Experience Report},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622758.3622894},
doi = {10.1145/3622758.3622894},
abstract = {Developers have long recognized the importance of the concepts underlying the systems they build, and the primary role that concepts play in shaping user experience. To date, however, concepts have tended to be only implicit in software design with development being organized instead around more concrete artifacts (such as wireframes and code modules).  

Palantir, a software company whose data analytics products are widely used by major corporations, recently reworked the internal representation of its software development process to bring concepts to the fore, making explicit the concepts underlying its products, including how they are clustered together, used in applications, and governed by teams. With a centralized repository of concepts, Palantir engineers are able to align products more closely based on shared concepts, evolve concepts in response to user needs, and communicate more effectively with non-engineering groups within the company.  

This paper reports on Palantir's experiences to date, analyzing both successes and challenges, and offers advice to other organizations considering adopting a concept-centric approach to software development.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {120–135},
numpages = {16},
keywords = {software design, ontology, concepts},
location = {Cascais, Portugal},
series = {Onward! 2023}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00094,
author1 = {Zeller, Marc},
title = {DevCertOps: Strategies to Realize Continuous Delivery of Safe Software in Regulated Domain},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00094},
doi = {10.1109/ICSE-Companion58688.2023.00094},
abstract = {Traditionally, promoted by the internet companies, DevOps is more and more appealing to industries which develop systems with safety-critical functions. Since safety-critical systems must meet regulatory requirements and require specific safety assurance processes in addition to the normal development steps, enabling continuous delivery of software in safety-critical systems requires the automation of the safety assurance process in the delivery pipeline. In this technical briefing, we describe relevant challenges to speed-up the development of safety-critical software-intensive systems from an industrial point of view. Moreover, we outline how to integrate software/system engineering and safety assurance life-cycle into a so-called DevCertOps concept realizing continuous safety assurance safety-critical systems using MBSE and model-based safety assurance concepts.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {334–335},
numpages = {2},
keywords = {continuous delivery, DevOps, agile, safety},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3254604,
author1 = {Ardagna, Danilo and Casale, Giuliano and van Hoorn, Andre and Willnecker, Felix and Di Nitto, Elisabetta and Leitner, Philipp},
title = {Session details: Third International Workshop on Quality-aware DevOps (QUDOS'17)},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3254604},
doi = {10.1145/3254604},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/2945408.2945413,
author1 = {Bernardi, Simona and Requeno, Jos\'{e} Ignacio and Joubert, Christophe and Romeu, Alberto},
title = {A systematic approach for performance evaluation using process mining: the POSIDONIA operations case study},
year = {2016},
isbn = {9781450344111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2945408.2945413},
doi = {10.1145/2945408.2945413},
abstract = {Modelling plays an important role in the development of software applications, in particular for the assessment of non functional requirements such as performance. The value of a model depends on the level of alignment with the reality. In this paper, we propose a systematic approach to get a performance model that is a good representation of the system under analysis. From an UML-based system design we get automatically a normative Petri net model, which formally represents the system supposed behaviour, by applying model-to-model (M2M) transformation techniques. Then, a conformance checking technique is iteratively applied to align -from the qualitative point of view- the normative model and the data log until the required fitness threshold is not reached. Finally, a trace-driven simulation technique is used to enrich the aligned model with timing specification from the data log, then obtaining the performance Generalized Stochastic Petri Net (GSPN) model. The proposed approach has been applied to a customizable Integrated Port Operations Management System, POSIDONIA Operations, where the performance model has been used to analyse the scalability of the product considering different deployment configurations.},
booktitle = {Proceedings of the 2nd International Workshop on Quality-Aware DevOps},
pages = {24–29},
numpages = {6},
keywords = {trace and log analysis, process mining, performance, data-intensive application, Unified Modelling Language, Model-driven transformation, Generalized Stochastic Petri Nets},
location = {Saarbr\"{u}cken, Germany},
series = {QUDOS 2016}
}

@article{10.1145/3596597,
author1 = {Hossain, Bayzid Ashik and Mukta, Md. Saddam Hossain and Islam, Md Adnanul and Zaman, Akib and Schwitter, Rolf},
title = {Natural Language–Based Conceptual Modelling Frameworks: State of the Art and Future Opportunities},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3596597},
doi = {10.1145/3596597},
abstract = {Identifying requirements for an information system is an important task and conceptual modelling is the first step in this process. Conceptual modelling plays a critical role in the information system design process and usually involves domain experts and knowledge engineers who brainstorm together to identify the required knowledge to build an information system. The conceptual modelling process starts with the collection of necessary information from the domain experts by the knowledge engineers. Afterwards, the knowledge engineers use traditional model driven engineering techniques to design the system based on the collected information. Natural language–based conceptual modelling frameworks or systems are used to help domain experts and knowledge engineers in eliciting requirements and building conceptual models from a natural language text. In this article, we discuss the state of the art of some recent conceptual modelling frameworks that are based on natural language. We take a closer look at how these frameworks are built, in particular at the underlying motivation, architecture, types of natural language used (e.g., restricted vs. unrestricted), types of the conceptual model generated, verification support of the requirements specifications as well as the conceptual models, and underlying knowledge representation formalism. We also discuss some future research opportunities that these frameworks offer.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {12},
numpages = {26},
keywords = {semantic round-tripping, knowledge representation, conceptual modelling, information extraction, Natural language processing}
}

@inproceedings{10.1145/3197231.3197263,
author1 = {Grundy, John and Abdelrazek, Mohamed and Curumsing, Maheswaree Kissoon},
title = {Vision: improved development of mobile ehealth applications},
year = {2018},
isbn = {9781450357128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3197231.3197263},
doi = {10.1145/3197231.3197263},
abstract = {Mobile eHealth applications have become very popular, not just using mobile phones but also wearables, mobile AR/VR, and increasingly "smart houses" and "smart care" sensing and interaction facilities. However, a large majority of these solutions, despite early promise, suffer from a range of challenges including effort to develop, deploy and maintain; lack of end user acceptance; integration with other health systems; difficulty in tailoring to divergent users; lack of adequate feedback to developers; lack of sustainable adoption; and ultimately lack of success. In this MobileSoft vision paper we characterise these key issues from a Software Engineering perspective and present and discuss some approaches to mitigating them, building on our and others prior work.},
booktitle = {Proceedings of the 5th International Conference on Mobile Software Engineering and Systems},
pages = {219–223},
numpages = {5},
keywords = {user feedback, model-driven engineering, mobile ehealth applications, living lab, emotion-oriented requirements, configuration and adaptation, behavioural requirements},
location = {Gothenburg, Sweden},
series = {MOBILESoft '18}
}

@inproceedings{10.1145/3660829.3660849,
author1 = {Ishikawa, Fuyuki and Saito, Shinobu},
title = {Model-Based Framework for Continuous Adaptation and Evolution of Quantum-Classical Hybrid Systems},
year = {2024},
isbn = {9798400706349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660829.3660849},
doi = {10.1145/3660829.3660849},
abstract = {Although quantum computing has been attracting increasing attention, hardware restrictions are tight in current implementations. Intensive design exploration is therefore essential to match requirements, such as the problem scale and acceptable error rate, with potential designs to combine quantum computing and classical computing. The design decision made in this way is often fragile as it is sensitive to the problem scale as well as still evolving quantum services. We need continuous design decision, or adaptation and evolution, given changes in requirements or environments. In this paper, we present a framework for model-based engineering to support the continuous adaptation and evolution of quantum-classical hybrid systems. Modeling in our framework involves not only potential designs, but also rationale or evidence of design decision, which often requires simulation and experiments. This focus allows for tracing and analyzing whether the past decision is still valid or not, or whether there is uncertainty and we need further simulation and experiments. The usage of the framework is demonstrated with an example problem from steel manufacturing.},
booktitle = {Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming},
pages = {118–125},
numpages = {8},
keywords = {DevOps, Hybrid Quantum Computing, Models@run.time, Quantum Software Engineering, Self-Adaptive Systems, Services Computing},
location = {Lund, Sweden},
series = {Programming '24}
}

@inproceedings{10.1145/2997364.2997380,
author1 = {Seybold, Daniel and Domaschka, J\"{o}rg and Rossini, Alessandro and Hauser, Christopher B. and Griesinger, Frank and Tsitsipas, Athanasios},
title = {Experiences of models@run-time with EMF and CDO},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2997364.2997380},
doi = {10.1145/2997364.2997380},
abstract = {Model-drivenengineering promotes models and modeltrans-  formations as the primary assets in software development.  The models@run-time approach provides an abstract rep-  resentation of a system at run-time, whereby changes in  the model and the system are constantly reflected on each  other. In this paper, we report on more than three years  of experience with realising models@run-time in scalable  cloud scenarios using a technology stack consisting of the  Eclipse Modelling Framework (EMF) and Connected Data  Objects(CDO).We establish requirements for the three roles  domain-specific language (DSL) designer, developer, and  operator, and compare them against the capabilities of EM-  F/CDO. It turns out that this technology stack is well-suited  for DSL designers, but less recommendable for developers  and even less suited for operators. For these roles, we experi-  enced a steep learning curve and several lacking features that  hinder the implementation of models@run-time in scalable  cloud scenarios. Performance experiences show limitations  for write heavy scenarios with an increasing amount of total  elements. While we do not discourage the use of EMF/CDO  for such scenarios, we recommend that its adoption for sim-  ilar use cases is carefully evaluated until this technology  stack has realised our wish list of advanced features.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {46–56},
numpages = {11},
keywords = {models@run-time, model-driven engineering, model repository, eclipse modeling framework, connected data objects},
location = {Amsterdam, Netherlands},
series = {SLE 2016}
}

@article{10.1145/3173572,
author1 = {Xie, Tao and van Hoorn, Andre and Wang, Huaimin and Weber, Ingo},
title = {Introduction to the Special Issue on Emerging Software Technologies for Internet-Based Systems: Internetware and DevOps},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3173572},
doi = {10.1145/3173572},
journal = {ACM Trans. Internet Technol.},
month = mar,
articleno = {13},
numpages = {2}
}

@inproceedings{10.1145/3491204.3527484,
author1 = {D\"{u}llmann, Thomas F. and van Hoorn, Andr\'{e} and Yussupov, Vladimir and Jakovits, Pelle and Adhikari, Mainak},
title = {CTT: Load Test Automation for TOSCA-based Cloud Applications},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527484},
doi = {10.1145/3491204.3527484},
abstract = {Despite today's fast and rapid modeling and deployment capabilities to meet customer requirements in an agile manner, testing is still of utmost importance to avoid outages, unsatisfied customers, and performance problems. To tackle such issues, (load) testing is one of several approaches. In this paper, we introduce the Continuous Testing Tool (CTT), which enables the modeling of tests and test infrastructures along with the cloud system under test, as well as deploying and executing (load) tests against a fully deployed system in an automated manner. CTT employs the OASIS TOSCA Standard to enable end-to-end support for continuous testing of cloud-based applications. We demonstrate CTT's workflow, its architecture, as well as its application to DevOps-oriented load testing and load testing of data pipelines.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {89–96},
numpages = {8},
keywords = {tosca, devops, continuous testing, continuous integration, agile},
location = {Bejing, China},
series = {ICPE '22}
}

@inproceedings{10.1109/ASE51524.2021.9678708,
author1 = {Wang, Hanzhang and Wu, Zhengkai and Jiang, Huai and Huang, Yichao and Wang, Jiamu and Kopru, Selcuk and Xie, Tao},
title = {Groot: an event-graph-based approach for root cause analysis in industrial settings},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678708},
doi = {10.1109/ASE51524.2021.9678708},
abstract = {For large-scale distributed systems, it is crucial to efficiently diagnose the root causes of incidents to maintain high system availability. The recent development of microservice architecture brings three major challenges (i.e., complexities of operation, system scale, and monitoring) to root cause analysis (RCA) in industrial settings. To tackle these challenges, in this paper, we present Groot, an event-graph-based approach for RCA. Groot constructs a real-time causality graph based on events that summarize various types of metrics, logs, and activities in the system under analysis. Moreover, to incorporate domain knowledge from site reliability engineering (SRE) engineers, Groot can be customized with user-defined events and domain-specific rules. Currently, Groot supports RCA among 5,000 real production services and is actively used by the SRE teams in eBay, a global e-commerce system serving more than 159 million active buyers per year. Over 15 months, we collect a data set containing labeled root causes of 952 real production incidents for evaluation. The evaluation results show that Groot is able to achieve 95% top-3 accuracy and 78% top-1 accuracy. To share our experience in deploying and adopting RCA in industrial settings, we conduct a survey to show that users of Groot find it helpful and easy to use. We also share the lessons learned from deploying and adopting Groot to solve RCA problems in production environments.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {419–429},
numpages = {11},
keywords = {root cause analysis, observability, microservices, AIOps},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/3368235.3368831,
author1 = {Elhabbash, Abdessalam and Elkhatib, Yehia and Blair, Gordon S. and Lin, Yuhui and Barker, Adam and Thomson, John},
title = {Envisioning SLO-driven Service Selection in Multi-cloud Applications},
year = {2019},
isbn = {9781450370448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368235.3368831},
doi = {10.1145/3368235.3368831},
abstract = {The current large selection of cloud instances that are functionally equivalent makes selecting the right cloud service a challenging decision. We envision a model driven engineering (MDE) approach to raise the level of abstraction for cloud service selection. One way to achieve this is through a domain specific language (DSL) for modelling the service level objectives (SLOs) and a brokerage system that utilises the SLO model to select services. However, this demands an understanding of the provider SLAs and the capabilities of the current cloud modelling languages (CMLs). This paper investigates the state-of-the-art for SLO support in both cloud providers SLAs and CMLs in order to identify the gaps for SLO support. We then outline research directions towards achieving the MDE-based cloud brokerage.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
pages = {9–14},
numpages = {6},
keywords = {service level objectives, service level agreements, domain specific language, cloud modelling languages, cloud computing},
location = {Auckland, New Zealand},
series = {UCC '19 Companion}
}

@article{10.1145/3104028,
author1 = {Pahl, Claus and Jamshidi, Pooyan and Zimmermann, Olaf},
title = {Architectural Principles for Cloud Software},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3104028},
doi = {10.1145/3104028},
abstract = {A cloud is a distributed Internet-based software system providing resources as tiered services. Through service-orientation and virtualization for resource provisioning, cloud applications can be deployed and managed dynamically. We discuss the building blocks of an architectural style for cloud-based software systems. We capture style-defining architectural principles and patterns for control-theoretic, model-based architectures for cloud software. While service orientation is agreed on in the form of service-oriented architecture and microservices, challenges resulting from multi-tiered, distributed and heterogeneous cloud architectures cause uncertainty that has not been sufficiently addressed. We define principles and patterns needed for effective development and operation of adaptive cloud-native systems.},
journal = {ACM Trans. Internet Technol.},
month = feb,
articleno = {17},
numpages = {23},
keywords = {uncertainty, software architecture, model-based controller, microservice, devops, control theory, cloud-native, architectural style, adaptive system, Cloud computing}
}

@article{10.1145/3595376,
author1 = {Coullon, H\'{e}l\'{e}ne and Henrio, Ludovic and Loulergue, Fr\'{e}d\'{e}ric and Robillard, Simon},
title = {Component-based Distributed Software Reconfiguration:A Verification-oriented Survey},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3595376},
doi = {10.1145/3595376},
abstract = {Distributed software built from components has become a mainstay of service-oriented applications, which frequently undergo reconfigurations to adapt to changes in their operating environment or their functional requirements. Given the complexity of distributed software and the adverse effects of incorrect reconfigurations, a suitable methodology is needed to ensure the correctness of reconfigurations in component-based systems. This survey gives the reader a global perspective over existing formal techniques that pursue this goal. It distinguishes different ways in which formal methods can improve the reliability of reconfigurations, and lists techniques that contribute to solving each of these particular scientific challenges.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {2},
numpages = {37},
keywords = {verification, formal methods, component-based software engineering, software adaptation, Reconfiguration}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00055,
author1 = {Kapel, Eileen},
title = {Incident Prevention through Reliable Changes Deployment},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00055},
doi = {10.1109/ICSE-Companion58688.2023.00055},
abstract = {Ensuring the reliability of changes deployment is essential to prevent incidents in businesses that strongly depend on software and services. Incidents should be avoided since they may lead to customer dissatisfaction, financial losses and reputational damage. Currently, the majority of outages are being caused by changes, so we believe there is a need for a higher focus on the risk management pre-change deployment. This paper presents a research plan that proposes a risk management AIOps framework utilising real-world change, CI/CD pipeline and incident data for incident prevention through reliable changes deployment. This research will explore 1) obtaining background information on the current state of practice of service management with a case study on a software-defined business; 2) a risk management AIOps framework that utilises the traces of change, incident and CI/CD pipeline code for predicting the risk of changes deployment; and 3) testing the generalisability of the framework for reducing the risk of change deployment.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {200–202},
numpages = {3},
keywords = {incident prevention, change risk, traceability, service management, change management, incident management},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/2851553.2858666,
author1 = {Casale, Giuliano and Spinner, Simon and Wang, Weikun},
title = {Automated Parameterization of Performance Models from Measurements},
year = {2016},
isbn = {9781450340809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851553.2858666},
doi = {10.1145/2851553.2858666},
abstract = {Estimating parameters of performance models from empirical measurements is a critical task, which often has a major influence on the predictive accuracy of a model. This tutorial presents the problem of parameter estimation in queueing systems and queueing networks. The focus is on reliable estimation of the arrival rates of the requests and of the service demands they place at the servers. The tutorial covers common estimation techniques such as regression methods, maximum-likelihood estimation, and moment-matching, discussing their sensitivity with respect to data and model characteristics. The tutorial also demonstrates the automated estimation of model parameters using new open source tools.},
booktitle = {Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering},
pages = {325–326},
numpages = {2},
keywords = {demand estimation, arrival processes},
location = {Delft, The Netherlands},
series = {ICPE '16}
}

@inproceedings{10.1145/3382025.3414970,
author1 = {Kr\"{u}ger, Jacob and Mahmood, Wardah and Berger, Thorsten},
title = {Promote-pl: a round-trip engineering process model for adopting and evolving product lines},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414970},
doi = {10.1145/3382025.3414970},
abstract = {Process models for software product-line engineering focus on proactive adoption scenarios---that is, building product-line platforms from scratch. They comprise the two phases domain engineering (building a product-line platform) and application engineering (building individual variants), each of which defines various development activities. Established more than two decades ago, these process models are still the de-facto standard for steering the engineering of platforms and variants. However, observations from industrial and open-source practice indicate that the separation between domain and application engineering, with their respective activities, does not fully reflect reality. For instance, organizations rarely build platforms from scratch, but start with developing individual variants that are re-engineered into a platform when the need arises. Organizations also appear to evolve platforms by evolving individual variants, and they use contemporary development activities aligned with technical advances. Recognizing this discrepancy, we present an updated process model for engineering software product lines. We employ a method for constructing process theories, building on recent literature as well as our experiences with industrial partners to identify development activities and the orders in which these are performed. Based on these activities, we synthesize and discuss the new process model, called promote-pl. Also, we explain its relation to modern software-engineering practices, such as continuous integration, model-driven engineering, or simulation testing. We hope that our work offers contemporary guidance for product-line engineers developing and evolving platforms, and inspires researchers to build novel methods and tools aligned with current practice.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {2},
numpages = {12},
keywords = {software reuse, round-trip engineering, process model},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/ECASE.2019.00013,
author1 = {Yuan, Eric},
title = {Architecture interoperability and repeatability with microservices: an industry perspective},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ECASE.2019.00013},
doi = {10.1109/ECASE.2019.00013},
abstract = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
pages = {26–33},
numpages = {8},
keywords = {software architecture, microservice, cloud computing, DevOps},
location = {Montreal, Quebec, Canada},
series = {ECASE '19}
}

@inproceedings{10.5555/3172795.3172821,
author1 = {Jim\'{e}nez, Miguel and Villegas, Norha M. and Tamura, Gabriel and M\"{u}ller, Hausi A.},
title = {Deployment Specification challenges in the context of large scale systems},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Traditionally, the focus of software deployment has been mainly on the infrastructure to realise deployment and configuration (D&amp;C) of complex and distributed systems, with an increasing interest in deployment of internet of things and cyber-physical systems. Advances in job scheduling, storage orchestration, containerized applications, along with agile practices such as continuous integration and microservices architecture, have improved the state of the practice. However, little effort has been devoted to the need for D&amp;C specifications to support the various levels of detail and abstraction present in large-scale systems. The understanding of the software components hierarchy has shifted from the comprehension of design artefacts, usually specified with static diagrams, to the understanding of runtime concepts. The DevOps movement has dramatically influenced how and when deployment is realised, but little has been done from the software perspective in terms of documentation and linkage between design and runtime artefacts in the sense of software specification as such. This paper presents an overview of the state of the art of deployment requirements for large-scale, distributed and complex software and its automation and characterises a set of deployment specification challenges intended as starting points for advancing the field of software deployment.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {220–226},
numpages = {7},
keywords = {runtime artefacts, models at runtime, deployment specification, continuous software deployment, continuous integration continuous configuration, DevOps},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@inproceedings{10.1145/3147704.3147742,
author1 = {Van Heesch, U. and Theunissen, T. and Zimmermann, O. and Zdun, U.},
title = {Software Specification and Documentation in Continuous Software Development: A Focus Group Report},
year = {2017},
isbn = {9781450348485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147704.3147742},
doi = {10.1145/3147704.3147742},
abstract = {We have been observing an ongoing trend in the software engineering domain towards development practices that rely heavily on verbal communication and small, closely-interacting teams. Among others, approaches like Scrum, Lean Software Development, and DevOps fall under this category. We refer to such development practices as Continuous Software Development (ConSD). Some core principles of ConSD are working in short iterations with frequent delivery, striving for an optimal balance between effectiveness and efficiency, and amplify learning in the development team. In such a context, many traditional patterns of software specification, documentation and knowledge preservation are not applicable anymore.To explore relevant topics, opinions, challenges and chances around specification, documentation and knowledge preservation in ConSD, we conducted a workshop at the 22nd European Conference on Pattern Languages of Programs (EuroPLoP), held in Germany in July 2017. The workshop participants came from the industry and academia.In this report, we present the results of the workshop. Among others, we elaborate on the difference between specification and documentation, the special role of architecture in ConSD in general, and architecture decision documentation in particular, and the importance of tooling that combines aspects of development, project management, and quality assurance. Furthermore, we describe typical issues with documentation and identify means to efficiently and effectively organize specification and documentation tasks in ConSD.},
booktitle = {Proceedings of the 22nd European Conference on Pattern Languages of Programs},
articleno = {35},
numpages = {13},
keywords = {Specification, Software engineering, Lean, DevOps, Continuous Software Development, Agile},
location = {Irsee, Germany},
series = {EuroPLoP '17}
}

@inproceedings{10.1145/2889160.2889207,
author1 = {Staples, Mark and Zhu, Liming and Grundy, John},
title = {Continuous validation for data analytics systems},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889207},
doi = {10.1145/2889160.2889207},
abstract = {From a future history of 2025: Continuous development is common for build/test (continuous integration) and operations (devOps). This trend continues through the lifecycle, into what we call 'devUsage': continuous usage validation. In addition to ensuring systems meet user needs, organisations continuously validate their legal and ethical use. The rise of end-user programming and multi-sided platforms exacerbate validation challenges. A separate trend is the specialisation of software engineering for technical domains, including data analytics. This domain has specific validation challenges. We must validate the accuracy of statistical models, but also whether they have illegal or unethical biases. Usage needs addressed by machine learning are sometimes not specifiable in the traditional sense, and statistical models are often 'black boxes'. We describe future research to investigate solutions to these devUsage challenges for data analytics systems. We will adapt risk management and governance frameworks previously used for software product qualities, use social network communities for input from aligned stakeholder groups, and perform cross-validation using autonomic experimentation, cyber-physical data streams, and online discursive feedback.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {769–772},
numpages = {4},
keywords = {software validation, machine learning, governance, ethics, devOps, data analytics, continuous development},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3644815.3644983,
author1 = {Washizaki, Hironori and Yoshioka, Nobukazu},
title = {AI Security Continuum: Concept and Challenges},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644983},
doi = {10.1145/3644815.3644983},
abstract = {We propose a conceptual framework, named "AI Security Continuum," consisting of dimensions to deal with challenges of the breadth of the AI security risk sustainably and systematically under the emerging context of the computing continuum as well as continuous engineering. The dimensions identified are the continuum in the AI computing environment, the continuum in technical activities for AI, the continuum in layers in the overall architecture, including AI, the level of AI automation, and the level of AI security measures. We also prospect an engineering foundation that can efficiently and effectively raise each dimension.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {269–270},
numpages = {2},
keywords = {AI security, software engineering for AI and machine learning, metamodel, security risk management},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.5555/3507788.3507844,
author1 = {Kontogiannis, Kostas and Amyot, Daniel and Mylopoulos, John},
title = {Software techniques for engineering cyber-physical systems},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cyber-Physical Systems (CPSs) refer to systems comprising software components, physical components, and social entities which monitor, control, and coordinate processes within a physical environment. CPSs apply to a wide range of mission-critical applications that span from the intelligent management of logistics in complex supply chains, advanced manufacturing systems, and smart contracts, all the way to autonomous systems, and systems that support the smart interactions between humans and machines (M2H), or between machines (M2M). In this respect, the engineering of CPSs goes beyond existing Software Engineering concepts, tools, and techniques because of the very nature of CPSs that spans three realms (cyber, physical, social) and therefore needs to address requirements that span these realms. During the workshop, the participants discussed and debated techniques and directions in six main thematic areas on engineering Cyber-Physical Systems. These thematic areas deal with specification and modeling, DevOps processes for CPSs, data management and analytics, infrastructure and event handling, run-time adaptivity, and finally security, trust, and traceability.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {289–290},
numpages = {2},
keywords = {software repositories, process metrics, fault-proneness prediction, continuous software engineering},
location = {Toronto, Canada},
series = {CASCON '21}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2975969.2975974,
author1 = {F\"{o}rd\H{o}s, Vikt\'{o}ria and Cesarini, Francesco},
title = {CRDTs for the configuration of distributed Erlang systems},
year = {2016},
isbn = {9781450344319},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2975969.2975974},
doi = {10.1145/2975969.2975974},
abstract = {CRDT (Conflict-free replicated data type) is a data type that supports conflict free resolution of concurrent, distributed updates. It is often mentioned alongside storage systems that are distributed, fault-tolerant and reliable. These are similar properties and features of Erlang/OTP systems. What distributed Erlang/OTP systems lack, however, is a standardised way to configure multiple nodes. OTP middleware allows you to set configuration parameters called application environment variables on a node basis, they can be updated at runtime, but will not survive a restart unless persisted in the business logic of the system. There is no widely adopted solution to address this omission. In some installations, changes are done manually in the Erlang shell and persisted by editing the configuration files. In others, changes and updates are implemented as part of a new releases and deployed through an upgrade procedure. These tools expect a happy path, and rarely take network failures and consistency into consideration. As a result, issues have been known to cause outages and have left the system in an inconsistent state, with no automated means of detecting the root cause of the problem. In this paper, we introduce a configuration management approach designed for distributed Erlang/OTP systems. They are systems which often trade consistency for availability and scalability, making them a perfect fit for CRDTs. We use a proprietary tool called WombatOAM to update environment variables and check their consistency on both node and cluster-levels. Inconsistencies and failed updates are detected and reported in the form of an alarms, and the history and status of all performed changes are logged, facilitating troubleshooting and recovery efforts. In this paper, we show our approaches to configuration management, and discuss how we approached the issue of consistency in the presence of unreliable networks. We present a qualitative evaluation and a case study to assess the capabilities of WombatOAM’s CRDT based configuration management feature.},
booktitle = {Proceedings of the 15th International Workshop on Erlang},
pages = {42–53},
numpages = {12},
keywords = {WombatOAM, Erlang, Elixir, DevOps, Configuration management, CRDT},
location = {Nara, Japan},
series = {Erlang 2016}
}

@inproceedings{10.1145/2804371.2804374,
author1 = {Ustinova, Tatiana and Jamshidi, Pooyan},
title = {Modelling multi-tier enterprise applications behaviour with design of experiments technique},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804374},
doi = {10.1145/2804371.2804374},
abstract = {Queueing network models are commonly used for performance modelling. However, through application development stage analytical models might not be able to continuously reflect performance, for example due to performance bugs or minor changes in the application code that cannot be readily reflected in the queueing model. To cope with this problem, a measurement-based approach adopting Design of Experiments (DoE) technique is proposed. The applicability of the proposed method is demonstrated on a complex 3-tier e-commerce application that is difficult to model with queueing networks.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {13–18},
numpages = {6},
keywords = {two-level factorial designs, software performance testing, response surface models, linear regression, design of experiments, Multi-tier enterprise applications},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}

@inproceedings{10.1145/2804371.2804375,
author1 = {Incerto, Emilio and Tribastone, Mirco and Trubiani, Catia},
title = {A proactive approach for runtime self-adaptation based on queueing network fluid analysis},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804375},
doi = {10.1145/2804371.2804375},
abstract = {Complex software systems are required to adapt dynamically to changing workloads and scenarios, while guaranteeing a set of performance objectives. This is not a trivial task, since run-time variability makes the process of devising the needed resources challenging for software designers. In this context, self-adaptation is a promising technique that work towards the specification of the most suitable system configuration, such that the system behavior is preserved while meeting performance requirements. In this paper we propose a proactive approach based on queuing networks that allows self-adaptation by predicting performance flaws and devising the most suitable system resources allocation. The queueing network model represents the system behavior and embeds the input parameters (e.g., workload) observed at run-time. We rely on fluid approximation to speed up the analysis of transient dynamics for performance indices. To support our approach we developed a tool that automatically generates simulation and fluid analysis code from an high-level description of the queueing network. An illustrative example is provided to demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {19–24},
numpages = {6},
keywords = {Runtime Self-Adaptation, Queueing Networks, Fluid Approximation Analysis},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}

@proceedings{10.1145/3666015,
title = {ICSSP '24: Proceedings of the 2024 International Conference on Software and Systems Processes},
year = {2024},
isbn = {9798400709913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {M\, Germany}
}

@article{10.1145/3623378,
author1 = {Hoffmann, Marcel Andr\'{e} and Lasch, Rainer},
title = {Tackling Industrial Downtimes with Artificial Intelligence in Data-Driven Maintenance},
year = {2023},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3623378},
doi = {10.1145/3623378},
abstract = {The application of Artificial Intelligence (AI) approaches in industrial maintenance for fault detection and prediction has gained much attention from scholars and practitioners. This survey systematically assesses and classifies the state-of-the-art algorithms applied to data-driven maintenance in recent literature. The taxonomy provides a so far not existing overview and decision aid for research and practice regarding suitable AI approaches for each maintenance application. Moreover, we consider trends and further research demand in this area. Finally, a newly developed holistic maintenance framework contributes to a practice-oriented implementation of AI and considers crucial managerial aspects of an efficient maintenance system.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {82},
numpages = {33},
keywords = {RUL, condition monitoring, machine learning, Artificial Intelligence, prescriptive maintenance, Predictive maintenance}
}

@proceedings{10.1145/3624486,
title = {eSAAM '23: Proceedings of the 3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum},
year = {2023},
isbn = {9798400708350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ludwigsburg, Germany}
}

@inproceedings{10.1145/3643665.3648568,
author1 = {Assun\c{c}\~{a}o, Wesley K. G.},
title = {Keynote on Software Modernization: From Industry Needs to Developers' Perception},
year = {2024},
isbn = {9798400705687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643665.3648568},
doi = {10.1145/3643665.3648568},
abstract = {The large majority of existing pieces of software in operation are long-living systems (a.k.a., legacy systems), which represent strategic value to companies. However, over the years, user requirements changed, technologies evolved, and new business models emerged, leading to changes of such systems. As a result of extensive maintenance and obsolete technology, legacy systems usually have decayed and degraded architectures. Consequently, any maintenance/evolution activities such as fixing bugs, adding a new feature, or keeping up with new trends (e.g., digital transformation) become extremely complex, time-consuming, and costly (e.g., the US government spent over $90 billion on IT in 2019, from which about 80% to operate and maintain legacy systems). To remain competitive, efficient, sustainable, retain value, and embrace digital transformation, companies must have their legacy systems modernized. Nowadays, a common modernization strategy is to move systems to the cloud using modular and highly-decoupled architectures (e.g., microservices). However, several challenges are faced by practitioners when planning and performing modernization.This talk presents industry needs, challenges, automated support (i.e., using AI), and the developers' perception on using automatically generated solution. The content is based on work in collaboration with an industry partner and many research collaborators, resulting and several studies, covering both empirical results and solution proposals. Additionally, existing limitations/gaps in the field and research opportunities are identified.},
booktitle = {Proceedings of the 1st IEEE/ACM Workshop on Software Engineering Challenges in Financial Firms},
pages = {21–22},
numpages = {2},
location = {Lisbon, Portugal},
series = {FinanSE '24}
}

@inproceedings{10.1145/3486609.3487199,
author1 = {Atouani, Abdallah and Kirchhof, J\"{o}rg Christian and Kusmenko, Evgeny and Rumpe, Bernhard},
title = {Artifact and reference models for generative machine learning frameworks and build systems},
year = {2021},
isbn = {9781450391122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486609.3487199},
doi = {10.1145/3486609.3487199},
abstract = {Machine learning is a discipline which has become ubiquitous in the last few years. While the research of machine learning algorithms is very active and continues to reveal astonishing possibilities on a regular basis, the wide usage of these algorithms is shifting the research focus to the integration, maintenance, and evolution of AI-driven systems. Although there is a variety of machine learning frameworks on the market, there is little support for process automation and DevOps in machine learning-driven projects. In this paper, we discuss how metamodels can support the development of deep learning frameworks and help deal with the steadily increasing variety of learning algorithms. In particular, we present a deep learning-oriented artifact model which serves as a foundation for build automation and data management in iterative, machine learning-driven development processes. Furthermore, we show how schema and reference models can be used to structure and maintain a versatile deep learning framework. Feasibility is demonstrated on several state-of-the-art examples from the domains of image and natural language processing as well as decision making and autonomous driving.},
booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {55–68},
numpages = {14},
keywords = {training, reference models, metamodeling, machine learning, compiler, build systems, artificial intelligence, artifact models},
location = {Chicago, IL, USA},
series = {GPCE 2021}
}

@inproceedings{10.1145/3375555.3383120,
author1 = {Gias, Alim U. and van Hoorn, Andr\'{e} and Zhu, Lulai and Casale, Giuliano and D\"{u}llmann, Thomas F. and Wurster, Michael},
title = {Performance Engineering for Microservices and Serverless Applications: The RADON Approach},
year = {2020},
isbn = {9781450371094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375555.3383120},
doi = {10.1145/3375555.3383120},
abstract = {Microservices and serverless functions are becoming integral parts of modern cloud-based applications. Tailored performance engineering is needed for assuring that the applications meet their requirements for quality attributes such as timeliness, resource efficiency, and elasticity. A novel DevOps-based framework for developing microservices and serverless applications is being developed in the RADON project. RADON contributes to performance engineering by including novel approaches for modeling, deployment optimization, testing, and runtime management. This paper summarizes the contents of our tutorial presented at the 11th ACM/SPEC International Conference on Performance Engineering (ICPE).},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {46–49},
numpages = {4},
keywords = {serverless, performance engineering, microservices},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@article{10.1145/3638243,
author1 = {Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari},
title = {Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638243},
doi = {10.1145/3638243},
abstract = {Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {50},
keywords = {Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework}
}

@article{10.1145/3579342.3579350,
author1 = {Gias, Alim Ul},
title = {Model-based Resource Management for Fine-grained Services},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/3579342.3579350},
doi = {10.1145/3579342.3579350},
abstract = {Brief Biography: Alim Ul Gias is currently a Research Associate at the Centre for Parallel Computing (CPC), University of Westminster. He completed his PhD from Imperial College London in 2022. Before starting his PhD, Alim was a lecturer at Institute of Information Technology (IIT), University of Dhaka (DU). He completed his bachelor's and master's program from the same institute. His current research focuses on different Quality of Service (QoS) aspects of cloud-native applications e.g., microservices. In particular, he aims to address the performance and resource management challenges concenrining the microservices architecture.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = jan,
pages = {28–31},
numpages = {4}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@inproceedings{10.1109/ICSE-NIER52604.2021.00027,
author1 = {Pashchenko, Ivan and Scandariato, Riccardo and Sabetta, Antonino and Massacci, Fabio},
title = {Secure software development in the era of fluid multi-party open software and services},
year = {2021},
isbn = {9780738133249},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER52604.2021.00027},
doi = {10.1109/ICSE-NIER52604.2021.00027},
abstract = {Pushed by market forces, software development has become fast-paced. As a consequence, modern development projects are assembled from 3rd-party components. Security &amp; privacy assurance techniques once designed for large, controlled updates over months or years, must now cope with small, continuous changes taking place within a week, and happening in sub-components that are controlled by third-party developers one might not even know they existed. In this paper, we aim to provide an overview of the current software security approaches and evaluate their appropriateness in the face of the changed nature in software development. Software security assurance could benefit by switching from a process-based to an artefact-based approach. Further, security evaluation might need to be more incremental, automated and decentralized. We believe this can be achieved by supporting mechanisms for lightweight and scalable screenings that are applicable to the entire population of software components albeit there might be a price to pay.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {91–95},
numpages = {5},
keywords = {vision, software security, open source software},
location = {Virtual Event, Spain},
series = {ICSE-NIER '21}
}

@proceedings{10.1145/3661167,
title = {EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salerno, Italy}
}

@proceedings{10.1145/3639476,
title = {ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3643794,
title = {SERP4IoT '24: Proceedings of the ACM/IEEE 6th International Workshop on Software Engineering Research &amp; Practices for the Internet of Things},
year = {2024},
isbn = {9798400705786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SERP4IoT begins to be recognized as an annual venue gathering researchers, industrials, and practitioners to share their vision, experience, and opinion on how to address the challenges of, find solutions for, and share experiences with the development, release, and testing of robust software for IoT systems.Even today, there is no precise definition of what is software engineering for the IoT, because it encompasses many different aspects of software design, development, evolution, deployment, and operation, with varying and conflicting criteria such as success, longevity, growth, resilience, survival, diversity, sustainability, transparency, privacy, security, etc.Yet, software engineering is vital for IoT to design systems that are secure, interoperable, modifiable, and scalable. It is crucial to bring good practices for developing projects for IoT, to devise and study the best architectures, to understand and secure communication protocols, and, generally, to overcome the many challenges faced by practitioners and researchers.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3643657,
title = {SATrends '24: Proceedings of the 1st International Workshop on New Trends in Software Architecture},
year = {2024},
isbn = {9798400705601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In this workshop, we aim at establishing a forum to collect practitioners' experiences and/or researchers' observations related to trends, and enable practitioners and researchers to exchange opinions, learn from each other, and progress the state of the art in the adoption of new trends.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@article{10.1145/3672089.3672101,
author1 = {Arnedo-Moreno, Joan and Cooper, Kendra M. L. and Lin, Dayi},
title = {Emerging Advanced Technologies for Game Engineering},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3672089.3672101},
doi = {10.1145/3672089.3672101},
abstract = {In this paper, the outcomes of the 8th International Workshop on Games and Software Engineering (GAS 2024)1 are reported. The one-day workshop has been held as part of the 46th International Conference on Software Engineering (ICSE 2024) in Lisbon, Portugal on April 14, 2024. The workshop programme includes two exciting keynotes discussing topics related to harnessing video game simulations to generate content and locate bugs, and the experience of maintaining a popular FOSS library, raylib. There are three research paper sessions. The first relates to automation in game engineering; the second explores testing and quality assurance; and the third discusses specification and quality of service. The conclusion of the workshop is anchored by a panel of four researchers, educators, and practitioners discussing the current strengths and limitations of large language models in game engineering.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {37–41},
numpages = {5}
}

@inproceedings{10.1145/3587102.3588815,
author1 = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3485952.3485959,
author1 = {Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l and Humayoun, Shah Rukh and Morales, Rodrigo and Saborido, Rub\'{e}n},
title = {SERP4IoT'21 Workshop Report},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3485952.3485959},
doi = {10.1145/3485952.3485959},
abstract = {We face a new software crisis. In 1968, computer scientists learned that developing robust software requires skills, methods, and tools. Today, software and hardware engineers realize that developing a robust Internet of Things (IoT) also pushes the states of their art and practice. Recent news illustrate the many problems faced by IoT: from lack of interoperability to broken updates to massive security attacks. In this context, the 3rd International Workshop on Software Engineering Research and Practices for the Internet of Things (SERP4IoT) aims to provide a highly interactive forum for researchers and practitioners to address the challenges of, nd solutions for, and share experiences with the development, release, and testing of robust software for IoT systems.},
journal = {SIGSOFT Softw. Eng. Notes},
month = oct,
pages = {26–27},
numpages = {2}
}

@article{10.1145/3664805,
author1 = {Fungprasertkul, Suwichak and Bahsoon, Rami and Kazman, Rick},
title = {Technical Debt Monitoring Decision Making with Skin in the Game},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3664805},
doi = {10.1145/3664805},
abstract = {Technical Debt Management (TDM) can suffer from unpredictability, communication gaps and the inaccessibility of relevant information, which hamper the effectiveness of its decision making. These issues can stem from division among decision-makers which takes root in unfair consequences of decisions among different decision-makers. One mitigation route is Skin in the Game thinking, which enforces transparency, fairness and shared responsibility during collective decision-making under uncertainty. This article illustrates characteristics which require Skin in the Game thinking in Technical Debt (TD) identification, measurement, prioritisation and monitoring. We point out crucial problems in TD monitoring rooted in asymmetric information and asymmetric payoff between different factions of decision-makers. A systematic TD monitoring method is presented to mitigate the said problems. The method leverages Replicator Dynamics and Behavioural Learning. The method supports decision-makers with automated TD monitoring decisions; it informs decision-makers when human interventions are required. Two publicly available industrial projects with a non-trivial number of TD and timestamps are utilised to evaluate the application of our method. Mann–Whitney U hypothesis tests are conducted on samples of decisions from our method and the baseline. The statistical evidence indicates that our method can produce cost-effective and contextual TD monitoring decisions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {168},
numpages = {27},
keywords = {Technical debt, software management, software maintenance, monitoring}
}

@inproceedings{10.1145/3576914.3588019,
author1 = {Kourtis, Michail Alexandros and Xilouris, George and Batistatos, Michael and Kourtis, Anastasios and Markakis, Albertos},
title = {Emergency communications leveraging decentralized swarm computing},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576914.3588019},
doi = {10.1145/3576914.3588019},
abstract = {Abstract—Reliable and ubiquitous communications, offering high data rates, low latency and supporting large numbers of connected devices, are critical requirements for modern emergency rescue missions. Multiple teams of First Responders, operating at remote areas, on rough terrain or under harsh conditions (e.g. wildfires, earthquakes, flooding etc.) need seamless connectivity to send/receive mission data and organize their operations. Decentralized swarm computing architectures offer a wide range of capabilities to enhance and accelerate edge processing for critical use case scenarios. This paper presents a converged approach on swarm computing and intelligence using Decentralized Autonomous Organizations for emergency communications, and how a swarm of drones can leverage different edge accelerators for different applications.},
booktitle = {Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
pages = {302–306},
numpages = {5},
keywords = {DAO, Keywords— Emergency communications, blockchain, decentralized computing, drones, swarm intelligence},
location = {San Antonio, TX, USA},
series = {CPS-IoT Week '23}
}

@inproceedings{10.1145/3412841.3442016,
author1 = {Brito, Miguel and Cunha, J\'{a}come and Saraiva, Jo\~{a}o},
title = {Identification of microservices from monolithic applications through topic modelling},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442016},
doi = {10.1145/3412841.3442016},
abstract = {Microservices emerged as one of the most popular architectural patterns in the recent years given the increased need to scale, grow and flexibilize software projects accompanied by the growth in cloud computing and DevOps. Many software applications are being submitted to a process of migration from its monolithic architecture to a more modular, scalable and flexible architecture of microservices. This process is slow and, depending on the project's complexity, it may take months or even years to complete.This paper proposes a new approach on microservice identification by resorting to topic modelling in order to identify services according to domain terms. This approach in combination with clustering techniques produces a set of services based on the original software. The proposed methodology is implemented as an open-source tool for exploration of monolithic architectures and identification of microservices. A quantitative analysis using the state of the art metrics on independence of functionality and modularity of services was conducted on 200 open-source projects collected from GitHub. Cohesion at message and domain level metrics' showed medians of roughly 0.6. Interfaces per service exhibited a median of 1.5 with a compact interquartile range. Structural and conceptual modularity revealed medians of 0.2 and 0.4 respectively.Our first results are positive demonstrating beneficial identification of services due to overall metrics' results.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1409–1418},
numpages = {10},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1145/3569927,
author1 = {Broy, Manfred and Rumpe, Bernhard},
title = {Development Use Cases for Semantics-Driven Modeling Languages},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {5},
issn = {0001-0782},
url = {https://doi.org/10.1145/3569927},
doi = {10.1145/3569927},
abstract = {Choosing underlying semantic theories and definition techniques must closely follow intended use cases for the modeling language.},
journal = {Commun. ACM},
month = apr,
pages = {62–71},
numpages = {10}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3540250.3558905,
author1 = {Fresno-Aranda, Rafael},
title = {Automated capacity analysis of limitation-aware microservices architectures},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3558905},
doi = {10.1145/3540250.3558905},
abstract = {Over the last years, the concept of API economy has fostered the creation of an ecosystem of public APIs used as business elements. These APIs include various pricing plans, which allow developers to consume an API for a specific price and under certain conditions. These conditions include capacity limits, a.k.a. limitations, that limit the usage of the API. Additionally, modern web applications are usually based on a microservices architecture (MSA), in which multiple services communicate with each other through public APIs using a standardized paradigm, commonly RESTful. When an MSA consumes external APIs with limitations, it is necessary to analyse the impact of these limitations in its capacity. These MSAs are known as Limitation-Aware Microservices Architecture (LAMA). This PhD dissertation aims to provide an automated framework to analyse the capacity of a LAMA given the formal description of its internal topology and the external pricing plans. This framework would be used to solve analysis operations, which deal with the extraction of useful information that helps developers build their LAMAs.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1780–1784},
numpages = {5},
keywords = {microservices, limitations, capacity analysis, automation, API},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@article{10.1145/3530813,
author1 = {Fahmideh, Mahdi and Grundy, John and Ahmad, Aakash and Shen, Jun and Yan, Jun and Mougouei, Davoud and Wang, Peng and Ghose, Aditya and Gunawardana, Anuradha and Aickelin, Uwe and Abedin, Babak},
title = {Engineering Blockchain-based Software Systems: Foundations, Survey, and Future Directions},
year = {2022},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3530813},
doi = {10.1145/3530813},
abstract = {Many scientific and practical areas have shown increasing interest in reaping the benefits of blockchain technology to empower software systems. However, the unique characteristics and requirements associated with Blockchain-based Software (BBS) systems raise new challenges across the development lifecycle that entail an extensive improvement of conventional software engineering. This article presents a systematic literature review of the state-of-the-art in BBS engineering research from the perspective of the software engineering discipline. We characterize BBS engineering based on the key aspects of theoretical foundations, processes, models, and roles. Based on these aspects, we present a rich repertoire of development tasks, design principles, models, roles, challenges, and resolution techniques. The focus and depth of this survey not only give software engineering practitioners and researchers a consolidated body of knowledge about current BBS development but also underpin a starting point for further research in this field.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {110},
numpages = {44},
keywords = {blockchain-based software systems, blockchain, Systems development methods, Software engineering}
}

@inproceedings{10.1145/3463274.3463786,
author1 = {Zhou, Peng and Ali Khan, Arif Ali and Liang, Peng and Badshah, Sher},
title = {System and Software Processes in Practice: Insights from Chinese Industry},
year = {2021},
isbn = {9781450390538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463274.3463786},
doi = {10.1145/3463274.3463786},
abstract = {Software development processes play a key role in the software and system development life cycle. Processes are becoming complex and evolve rapidly due to the modern-day continuous software engineering (CSE) concepts, which are mainly based on continuous integration, continuous delivery, infrastructure-as-code, automation and more. The fast growing Chinese software development industry adopts various processes to achieve potential benefits offered in the international market. This study is conducted with the aim to investigate the trends of processes in practice in the Chinese industry. The survey questionnaire data is collected from 34 practitioners working in software development firms across the China and the results highlight that iterative and agile processes are extensively used in industrial setting. Furthermore, agile and traditional approaches are combined to develop the hybrid processes. Most of the participants are satisfied using the current development processes, however, they show interest to continuously improve the existing process models and methods. Finally, we noticed that majority of the software development organizations used the ISO 9001 standard for process assessment and improvement activities. The given results provide preliminary overview of processes deployed in the Chinese industry.},
booktitle = {Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering},
pages = {394–401},
numpages = {8},
keywords = {Survey, Software processes, Process Improvement Standards, Chinese industry},
location = {Trondheim, Norway},
series = {EASE '21}
}

@inproceedings{10.1145/3549036.3562056,
author1 = {De Stefano, Manuel and Di Nucci, Dario and Palomba, Fabio and Taibi, Davide and De Lucia, Andrea},
title = {Towards Quantum-algorithms-as-a-service},
year = {2022},
isbn = {9781450394581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549036.3562056},
doi = {10.1145/3549036.3562056},
abstract = {Quantum computing is an emerging field of high interest. Many companies have started to work on developing more powerful and stable quantum computers. However, developers still struggle to master the art of programming with a quantum computer.  
One of the major challenges faced is the integration of quantum parts of a system with the classical one.  
This paper proposes a novel development model called Quantum-Algorithms-as-a-Service (QAaaS).  
This new model aims to allow developers to abstract the quantum components away from the design of the software they are building.  
The model leverages Software-as-a-Service and Function-as-a-Service to support multiple quantum cloud providers and run their algorithms regardless of the underlying hardware.},
booktitle = {Proceedings of the 1st International Workshop on Quantum Programming for Software Engineering},
pages = {7–10},
numpages = {4},
keywords = {XaaS, Quantum Software Engineering, Quantum Computing, QaaS},
location = {Singapore, Singapore},
series = {QP4SE 2022}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3594441.3594445,
author1 = {Telesko, Rainer and Spahic-Bogdanovic, Maja and Hinkelmann, Knut and Pande, Charuta},
title = {A new approach for teaching programming: Model-based Agile Programming (MBAD)},
year = {2023},
isbn = {9798400700613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594441.3594445},
doi = {10.1145/3594441.3594445},
abstract = {Designing courses for introductory programming courses with a heterogeneous audience (business and IT background as well) is a challenging task. In an internal project of the School of Business at the FHNW University of Applied Sciences and Arts Northwestern Switzerland (FHNW) a group of lecturers developed a concept entitled “Model-based agile development” (MBAD) which supports the learning of elementary programming concepts in an agile environment and builds the basis for advanced courses. MBAD will be used as a basic learning module for various Bachelor programs at the FHNW.},
booktitle = {Proceedings of the 2023 8th International Conference on Information and Education Innovations},
pages = {13–18},
numpages = {6},
location = {Manchester, United Kingdom},
series = {ICIEI '23}
}

@proceedings{10.1145/3643665,
title = {FinanSE '24: Proceedings of the 1st IEEE/ACM Workshop on Software Engineering Challenges in Financial Firms},
year = {2024},
isbn = {9798400705687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Software development has an integral role in every financial organisation; indeed, almost every service provided by a bank utilizes some form of software solution. While SE research has led to solutions and innovations for many popular SE problems, there remain unresolved challenges, particularly, those challenges faced in software development in financial firms. An example of such a challenge is defect prediction, where defects are not equal as some may lead to larger reputational and financial damage than others. Consequently, testing and verification is burdened with a further set of restraints for finance-based SE teams. Financial firms began automating processes as early as the 1960s, and as such, must maintain large legacy systems which may host critical operations. This problem is further exacerbated by the numerous mergers and acquisitions common in the financial sector, which leaves firms with a set of heterogeneous legacy systems that need to communicate with one another effectively and efficiently. Therefore, maintaining these systems while modernizing them leads to intriguing challenges, spanning from model extraction and process optimisation to code translation. Moreover, highly regulated institutions like financial firms require a high degree of transparency and accountability. This requirement facilitates the need for model fairness and explainability for any SE solution, in particular those that rely on AI.The 1st International Workshop on Software Engineering Challenges in Financial Firms (FinanSE 2024) is a forum to bring together academia and industry to share new ideas and results in tackling these challenges.},
location = {Lisbon, Portugal}
}

@article{10.1145/3672555,
author1 = {Mahdavi-Hezaveh, Rezvan and Fatima, Sameeha and Williams, Laurie},
title = {Paving a Path for a Combined Family of Feature Toggle and Configuration Option Research},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672555},
doi = {10.1145/3672555},
abstract = {Feature toggles and configuration options are techniques to include or exclude functionality in software. The research contributions to these two techniques have most often been focused on either one of them. However, focusing on the similarities of these two techniques and the use of a common terminology may enable a combined family of research on software configuration (a term we use to encompass both techniques) and prevent duplication of effort. The goal of this study is to aid researchers in conducting a family of research on software configuration by extending an existing model of software configuration that provides a common terminology for feature toggles and configuration options in research studies. We started with Siegmund et al.’s Model of Software Configuration (MSC), which was developed based on configuration option-related resources. We extend the MSC by qualitative analysis of feature toggle-related resources. From our analysis, we proposed MSCv2 and evaluated it through its application on publications and an industrial system. Our results indicate researchers studying the same system may provide different definitions of software configuration in publications, similar research questions may be answered repeatedly because of a lack of a clear definition of software configuration, and having an MSC may enable generalized research on this family of research.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {172},
numpages = {27},
keywords = {Feature toggle, configuration option, software configuration, software engineering}
}

@inproceedings{10.1145/3551349.3559551,
author1 = {Kienzle, Joerg and Combemale, Benoit and Mussbacher, Gunter and Alam, Omar and Bordeleau, Francis and Burgueno, Lola and Engels, Gregor and Galasso, Jessie and J\'{e}z\'{e}quel, Jean-Marc and Kemme, Bettina and Mosser, S\'{e}bastien and Sahraoui, Houari and Schiedermeier, Maximilian and Syriani, Eugene},
title = {Global Decision Making Over Deep Variability in Feedback-Driven Software Development},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559551},
doi = {10.1145/3551349.3559551},
abstract = {To succeed with the development of modern software, organizations must have the agility to adapt faster to constantly evolving environments to deliver more reliable and optimized solutions that can be adapted to the needs and environments of their stakeholders including users, customers, business, development, and IT. However, stakeholders do not have sufficient automated support for global decision making, considering the increasing variability of the solution space, the frequent lack of explicit representation of its associated variability and decision points, and the uncertainty of the impact of decisions on stakeholders and the solution space. This leads to an ad-hoc decision making process that is slow, error-prone, and often favors local knowledge over global, organization-wide objectives. The Multi-Plane Models and Data (MP-MODA) framework explicitly represents and manages variability, impacts, and decision points. It enables automation and tool support in aid of a multi-criteria decision making process involving different stakeholders within a feedback-driven software development process where feedback cycles aim to reduce uncertainty. We present the conceptual structure of the framework, discuss its potential benefits, and enumerate key challenges related to tool supported automation and analysis within MP-MODA.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {178},
numpages = {6},
keywords = {MODA, Iterative Software Development, Feedback Loop},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3284179.3284327,
author1 = {Conde, Miguel \'{A}. and Sarasa-Cabezuelo, Antonio and Sierra, Jos\'{e}-Luis},
title = {9th International Workshop on Software Engineering for ELearning (ISELEAR'18)},
year = {2018},
isbn = {9781450365185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284179.3284327},
doi = {10.1145/3284179.3284327},
abstract = {This paper introduces the 9th Edition of the International Workshop on Software Engineering for E-Learning (ISELEAR'18), organized as a track of TEEM'18, the 6th International Conference on Technological Ecosystems for Enhancing Multiculturality. The main goal of ISELEAR is to explore the different methods, techniques and tools used for the systematic development of E-Learning ecosystems. In this way, and contrarily to the pedagogical aspects promoted by other events in E-Learning, ISELEAR is focused on the technical and engineering aspects of the software supporting these systems. This introduction describes the workshop's history, the review and selection process, and summarizes the papers accepted for this 2018 edition.},
booktitle = {Proceedings of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {879–882},
numpages = {4},
keywords = {educational technology, e-Learning engineering, Software engineering},
location = {Salamanca, Spain},
series = {TEEM'18}
}

@inproceedings{10.1145/3579170.3579264,
author1 = {Nouacer, R\'{e}da and Hussein, Mahmoud and Detterer, Paul and Villar, Eugenio and Herrera, Fernando and Tieri, Carlo and Grolleau, Emmanuel},
title = {Towards a European Network of Enabling Technologies for Drones},
year = {2023},
isbn = {9798400700453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579170.3579264},
doi = {10.1145/3579170.3579264},
abstract = {Drone-based service and product innovation is curtailed by the growing dependence on poorly inter-operable proprietary technologies as well as by the risks posed to people on the ground, to other vehicles and to property (e.g. critical infrastructure). Regarding the innovation aspect, the Single European Sky Air Traffic Management (SESAR) Joint Research Undertaking is developing U-space, a set of services and procedures to help drones access airspace safely and efficiently. The aim of COMP4DRONES is to complements SESAR JU efforts by providing a framework of key enabling technologies for safe and autonomous drones with a specific focus on U2 and U3. The COMP4DRONES project has contributed to support (1) efficient customization and incremental assurance of drone-embedded platforms, (2) safe autonomous decision making concerning individual or cooperative missions, (3) trustworthy drone-to-drone and drone-to-ground communications even in presence of malicious attackers and under the intrinsic platform constraints, and (4) agile and cost-effective design and assurance of drone modules and systems. In this paper, we discuss the results of COMP4DRONES project to complement SESAR JU efforts with a particular focus on safe software and hardware drone architectures.},
booktitle = {Proceedings of the DroneSE and RAPIDO: System Engineering for Constrained Embedded Systems},
pages = {1–11},
numpages = {11},
keywords = {Security, Safety, Interoperability, Drones, Composition, Autonomy, Automation and Control Systems},
location = {Toulouse, France},
series = {RAPIDO '23}
}

@inproceedings{10.1145/3555776.3577704,
author1 = {Clawson, Garry},
title = {A Technology Readiness Level for Blockchain},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577704},
doi = {10.1145/3555776.3577704},
abstract = {Blockchain technology has seen practical application since 2009. However, the suitable selection of blockchain technology for any particular application is currently completed using no standard formalised process with limited understanding of where a particular blockchain is in its development maturity against its peers, or peer sector. Technology Readiness Levels (TRLs) offer a common and well known method for identifying the maturity of a technology. However, new TRL definitions have been required to address sector specific requirements. This work addresses these challenges and presents a novel Blockchain Readiness Level (BRL) for identifying the maturity of blockchain technology.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {249–257},
numpages = {9},
keywords = {technology readiness level, blockchain},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@article{10.1145/3402127.3402131,
author1 = {Piattini, Mario and Peterssen, Guido and P\'{e}rez-Castillo, Ricardo},
title = {Quantum Computing: A New Software Engineering Golden Age},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3402127.3402131},
doi = {10.1145/3402127.3402131},
abstract = {Quantum computing, and to an even greater extent quantum technology, is changing the world. Quantum computing is not an evolution of classical computer science; it is actually a revolution that completely changes the computing paradigm. Quantum computers are based on the principles of quantum mechanics, such as superposition and entanglement, and they seek to boost computational power exponentially. Many problems that have until now been impossible to solve, in practical terms, might very well be able to be addressed by means of quantum computing. The fact is that at the present time quantum computing is influencing most business sectors and research fields, due to its various promising applications. To make such applications become reality, quantum algorithms must be specially coded for these extremely different computers. Although some well-known quantum algorithms already exist, the need for quantum software will increase dramatically in the next years. In that context, quantum software has to be produced in a more industrial and controlled way, i.e., aspects such as quality, delivery, project management, or evolution of quantum software must be addressed. We are sure that quantum computing will be the main driver for a new software engineering golden age during the present decade of the 2020s.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {12–14},
numpages = {3},
keywords = {quantum software engineering., quantum software, quantum computing}
}

@proceedings{10.5555/3623288,
title = {ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2023},
isbn = {9798350300390},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Australia}
}

@proceedings{10.5555/3606013,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/3664476,
title = {ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@article{10.1145/3343454,
author1 = {Chakraborty, Supratik and Varma, Vasudeva},
title = {Highlights of software R&amp;D in India},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3343454},
doi = {10.1145/3343454},
journal = {Commun. ACM},
month = oct,
pages = {88–91},
numpages = {4}
}

@proceedings{10.1145/3629479,
title = {SBQS '23: Proceedings of the XXII Brazilian Symposium on Software Quality},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bras\'{\i}lia, Brazil}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@inproceedings{10.1145/3589806.3600043,
author1 = {Lefeuvre, Romain and Galasso, Jessie and Combemale, Benoit and Sahraoui, Houari and Zacchiroli, Stefano},
title = {Fingerprinting and Building Large Reproducible Datasets},
year = {2023},
isbn = {9798400701764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589806.3600043},
doi = {10.1145/3589806.3600043},
abstract = {Obtaining a relevant dataset is central to conducting empirical studies in software engineering. However, in the context of mining software repositories, the lack of appropriate tooling for large scale mining tasks hinders the creation of new datasets. Moreover, limitations related to data sources that change over time (e.g., code bases) and the lack of documentation of extraction processes make it difficult to reproduce datasets over time. This threatens the quality and reproducibility of empirical studies. In this paper, we propose a tool-supported approach facilitating the creation of large tailored datasets while ensuring their reproducibility. We leveraged all the sources feeding the Software Heritage append-only archive which are accessible through a unified programming interface to outline a reproducible and generic extraction process. We propose a way to define a unique fingerprint to characterize a dataset which, when provided to the extraction process, ensures that the same dataset will be extracted. We demonstrate the feasibility of our approach by implementing a prototype. We show how it can help reduce the limitations researchers face when creating or reproducing datasets.},
booktitle = {Proceedings of the 2023 ACM Conference on Reproducibility and Replicability},
pages = {27–36},
numpages = {10},
keywords = {dataset, empirical studies, open science, reproducibility},
location = {Santa Cruz, CA, USA},
series = {ACM REP '23}
}

@inproceedings{10.1145/3340481.3342730,
author1 = {Petrik, Dimitri and Herzwurm, Georg},
title = {iIoT ecosystem development through boundary resources: a Siemens MindSphere case study},
year = {2019},
isbn = {9781450368544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340481.3342730},
doi = {10.1145/3340481.3342730},
abstract = {Emerging Industrial Internet of Things (iIoT) platforms generate cross-company added value, providing functionalities and technologies for a variety of digital services in the industrial engineering. iIoT platforms integrate various stakeholders, such as end customers and complementors and build iIoT ecosystems. Earlier research has recognized boundary resources as an emergence and governance mechanism for software ecosystems. In this study we apply the boundary resources for iIoT by exploring the longitudinal case study of the Siemens MindSphere ecosystem. The goal of this exploratory paper is to show which boundary resources are currently used in iIoT ecosystems and how do they impact the development of iIoT ecosystems.},
booktitle = {Proceedings of the 2nd ACM SIGSOFT International Workshop on Software-Intensive Business: Start-Ups, Platforms, and Ecosystems},
pages = {1–6},
numpages = {6},
keywords = {iIoT Platform, iIoT Ecosystem, Platform Emergence, Industrial IoT, Boundary Resources},
location = {Tallinn, Estonia},
series = {IWSiB 2019}
}

@inproceedings{10.1145/3368235.3368840,
author1 = {Kritikos, Kyriakos and Skrzypek, Pawe\l{}},
title = {Are Cloud Modelling Languages Ready for Multi-Cloud?},
year = {2019},
isbn = {9781450370448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368235.3368840},
doi = {10.1145/3368235.3368840},
abstract = {Multi-cloud computing promises to deliver certain benefits, like performance optimisation and cost reduction. However, most cloud application modelling languages are tight to one cloud platform and do not have the right expressiveness to cover all application lifecycle phases. This survey attempts to review the most important from these languages, which facilitate application provisioning in commercial cloud platforms. The main review goals are to: (a) highlight those languages already or nearly multi-cloud enabled; (b) determine those parts of the remaining languages that must be extended to support multi-cloud application modelling. This review results also lead to drawing some future work directions towards producing an ideal multi-cloud application specification language.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
pages = {51–58},
numpages = {8},
keywords = {survey, multi-cloud, modelling, evaluation, comparison, application},
location = {Auckland, New Zealand},
series = {UCC '19 Companion}
}

@proceedings{10.1145/3641399,
title = {ISEC '24: Proceedings of the 17th Innovations in Software Engineering Conference},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@article{10.1145/3092698,
author1 = {Kaur, Kiranbir and Sharma, DR. Sandeep and Kahlon, DR. Karanjeet Singh},
title = {Interoperability and Portability Approaches in Inter-Connected Clouds: A Review},
year = {2017},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092698},
doi = {10.1145/3092698},
abstract = {Inter-connected cloud computing is an inherent evolution of Cloud Computing. Numerous benefits provided by connecting clouds have garnered attraction from the academic as well as the industry sector. Just as every new evolution faces challenges, inter-connected clouds have their own set of challenges such as security, monitoring, author1ization and identity management, vendor lock-in, and so forth. This article considers the vendor lock-in problem, which is a direct consequence of the lack of interoperability and portability. An extensive literature review by surveying more than 120 papers has been done to analyze and categorize various solutions suggested in literature for solving the interoperability and portability issues of inter-connected clouds. After categorizing the solutions, the literature has been mapped to a specific solution and a comparative analysis of the papers under the same solution has been done. The term “inter-connected clouds” has been used generically in this article to refer to any collaboration of clouds which may be from the user side (Multi-clouds or Aggregated service by Broker) or the provider side (Federated clouds or Hybrid clouds). Lastly, two closely related issues (Brokers and Meta-scheduling) and the remaining challenges of inter-connected clouds are discussed.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {49},
numpages = {40},
keywords = {standards, semantic-based techniques, open solutions, model-based techniques, inter-connected clouds, Cloud computing}
}

@inproceedings{10.1145/3544548.3580790,
author1 = {Robertson, Samantha and Wang, Zijie J. and Moritz, Dominik and Kery, Mary Beth and Hohman, Fred},
title = {Angler: Helping Machine Translation Practitioners Prioritize Model Improvements},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580790},
doi = {10.1145/3544548.3580790},
abstract = {Machine learning (ML) models can fail in unexpected ways in the real world, but not all model failures are equal. With finite time and resources, ML practitioners are forced to prioritize their model debugging and improvement efforts. Through interviews with 13 ML practitioners at Apple, we found that practitioners construct small targeted test sets to estimate an error’s nature, scope, and impact on users. We built on this insight in a case study with machine translation models, and developed Angler, an interactive visual analytics tool to help practitioners prioritize model improvements. In a user study with 7 machine translation experts, we used Angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive. Our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {832},
numpages = {20},
keywords = {Model evaluation, machine translation, visual analytics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3379177.3388896,
author1 = {Wang, Bo and Boehm, Barry W.},
title = {Process Implications of Executable Domain Models for Microservices Development},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388896},
doi = {10.1145/3379177.3388896},
abstract = {Microservice architecture has been recognized as an important enabler for continuous development of many cloud-based systems. Code generation has been tried in the tool chain of building microservices. However, most existing tools generally do not consider the risks from continuous development.We have been developing a toolkit which generates microservices from application domain models. Our approach aligns development process to this toolkit and coordinates domain modeling activity over project life cycles. In this paper, we describe its framework and corresponding development process which eliminates delays brought by the uncertainty of a project at a relatively early stage. Several minimum viable products have been built upon the proposed approach during the past years, including automated generation of code from domain decomposition. Our result shows 10% saving of effort and fewer issues. Effort saving increases to 30% under an extreme condition with high-rate personnel turnover. We also discuss our findings on running these projects and raise discussion and questions for future enhancement.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {41–50},
numpages = {10},
keywords = {microservices, domain modeling, continuous development, code generation, agile},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@proceedings{10.1145/3637543,
title = {CF '24 Companion: Proceedings of the 21st ACM International Conference on Computing Frontiers: Workshops and Special Sessions},
year = {2024},
isbn = {9798400704925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This is the companion proceedings of the 21st ACM International Conference on Computing Frontiers (Volume 2) collecting the papers from co-located workshops and invited papers from special sessions. For papers from the main track, as well as keynote abstract and poster abstracts, see Volume 1.},
location = {Ischia, Italy}
}

@inproceedings{10.1145/3463274.3463334,
author1 = {Wolfart, Daniele and Assun\c{c}\~{a}o, Wesley K. G. and da Silva, Ivonei F. and Domingos, Diogo C. P. and Schmeing, Ederson and Villaca, Guilherme L. Donin and Paza, Diogo do N.},
title = {Modernizing Legacy Systems with Microservices: A Roadmap},
year = {2021},
isbn = {9781450390538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463274.3463334},
doi = {10.1145/3463274.3463334},
abstract = {Legacy systems are long-lived applications, with obsolete technology and degraded architecture. These systems hamper digital transformation and innovation, and require a great amount of resources for maintenance. The modernization of monolithic legacy systems is a strategy to promote better evolution and maintenance, taking advantage of new technologies such as microservices. Microservice architectural style is a paradigm to develop systems as a suite of small and autonomous services, communicating through a lightweight protocol. However, the migration of legacy systems to microservices is complex. Although we can find several studies on this topic, they usually focus on specific activities, e.g., the identification of the microservice boundaries in the legacy code. Also, existing pieces of work do not cover real-world scenarios, since they do not take into account organizational, operational, and technical aspects. To overcome this limitation, in this paper we present a roadmap for modernizing monolithic legacy systems with microservices. The roadmap is distilled from the existing body of knowledge, describing common activities and input/output information. The proposed roadmap is composed of eight activities, grouped in four phases, namely initiation, planning, execution, and monitoring. The main contributions are: (i) serve as a basis for practitioners to plan, execute, and monitor the modernization process; (ii) be a reference for researchers to design new studies; and (iii) motivate tool builders to deal with existing needs.},
booktitle = {Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering},
pages = {149–159},
numpages = {11},
keywords = {Software Migration, Software Evolution, Cloud Computing},
location = {Trondheim, Norway},
series = {EASE '21}
}

@article{10.1145/3487043,
author1 = {Mart\'{\i}nez-Fern\'{a}ndez, Silverio and Bogner, Justus and Franch, Xavier and Oriol, Marc and Siebert, Julien and Trendowicz, Adam and Vollmer, Anna Maria and Wagner, Stefan},
title = {Software Engineering for AI-Based Systems: A Survey},
year = {2022},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3487043},
doi = {10.1145/3487043},
abstract = {AI-based systems are software systems with functionalities enabled by at least one AI component (e.g., for image-, speech-recognition, and autonomous driving). AI-based systems are becoming pervasive in society due to advances in AI. However, there is limited synthesized knowledge on Software Engineering (SE) approaches for building, operating, and maintaining AI-based systems. To collect and analyze state-of-the-art knowledge about SE for AI-based systems, we conducted a systematic mapping study. We considered 248 studies published between January 2010 and March 2020. SE for AI-based systems is an emerging research area, where more than 2/3 of the studies have been published since 2018. The most studied properties of AI-based systems are dependability and safety. We identified multiple SE approaches for AI-based systems, which we classified according to the SWEBOK areas. Studies related to software testing and software quality are very prevalent, while areas like software maintenance seem neglected. Data-related issues are the most recurrent challenges. Our results are valuable for: researchers, to quickly understand the state-of-the-art and learn which topics need more research; practitioners, to learn about the approaches and challenges that SE entails for AI-based systems; and, educators, to bridge the gap among SE and AI in their curricula.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {37e},
numpages = {59},
keywords = {systematic mapping study, AI-based systems, artificial intelligence, Software engineering}
}

@article{10.1145/3631976,
author1 = {Cederbladh, Johan and Cicchetti, Antonio and Suryadevara, Jagadish},
title = {Early Validation and Verification of System Behaviour in Model-based Systems Engineering: A Systematic Literature Review},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3631976},
doi = {10.1145/3631976},
abstract = {In the Systems Engineering (SE) domain there has been a paradigm shift from document-based to model-based system development artefacts; in fact, new methodologies are emerging to meet the increasing complexity of current systems and the corresponding growing need of digital workflows. In this regard, Model-Based Systems Engineering (MBSE) is considered as a key enabler by many central players of the SE community. MBSE has reached an adequate level of maturity, and there exist documented success stories in its adoption in industry. In particular, one significant benefit of utilising MBSE when compared to the traditional manual and document-centric workflows is that models are available from early phases of systems development; these enable a multitude of analyses prior any implementation effort together with other relevant capabilities, like the automation of development tasks. Nonetheless, it is noticeable there is a lack of a common understanding for how formal analyses for the verification and validation (V&amp;V) of systems behaviour, specifically in the early phases of development, could be placed in an MBSE setting.In this article, we report on the planning, execution, and results of a systematic literature review regarding the early V&amp;V of systems behaviour in the context of model-based systems engineering. The review aims to provide a structured representation of the state of the art with respect to motivations, proposed solutions, and limitations. From an initial set of potentially relevant 701 peer-reviewed publications we selected 149 primary studies, which we analysed according to a rigorous data extraction, analysis, and synthesis process. Based on our results, early V&amp;V has usually the goal of checking the quality of a system design to avoid discovering flaws when parts are being concretely realised; SysML is a de facto standard for describing the system under study, while the solutions for the analyses tend to be varied; also V&amp;V analyses tend to target varied properties with a slight predominance of functional concerns, and following the variation mentioned so far the proposed solutions are largely context specific; the proposed approaches are usually presented without explicit limitations, while when limitations are discussed, readiness of the solutions, handling of analyses simplifications/assumptions, and languages/tools integration are among the most frequently mentioned issues.Based on the survey results and the standard SE practices, we discuss how the current state-of-the-art MBSE supports early V&amp;V of systems behaviour with a special focus on industrial adoption and identify relevant challenges to be researched further.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {81},
numpages = {67},
keywords = {MBSE, validation, verification, system behaviour, systematic literature review}
}

@proceedings{10.5555/3623293,
title = {ICSE-SEIP '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3369740.3372778,
author1 = {Mondal, Kartick Chandra and Biswas, Neepa and Saha, Swati},
title = {Role of Machine Learning in ETL Automation},
year = {2020},
isbn = {9781450377515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369740.3372778},
doi = {10.1145/3369740.3372778},
abstract = {In the current business landscape, real-time analysis of enterprise data is very crucial for decision-makers of the organization to take strategic resolution and stay ahead of the competitors. Most of the time, it happens that data is outdated by the time it reaches to the user. The organization needs reliable, up to minute information to make better proactive business decisions, improve the process and organizational efficiency. Availability of information and business-critical report at real-time can be achieved through an automated ETL process. Typically, running a data warehouse in an enterprise requires coordination of many operations across many teams including applications and database teams. Also, it required a lot of manual intervention, which is error-prone. Executing all related steps in correct sequences under accurate conditions can be a challenge. Automated ETL process helps to address all these problems. Moreover, the preprocessing of data is a crucial step for making data ready to load in a data warehouse for analysis. Machine learning-based preprocessing can be used to ensure the quality of data. In this paper, we have addressed the issues faced in traditional data warehouse related to availability as well as the quality of data. We have explained how to automate the ETL process and how machine learning can be leveraged in the ETL process so that the quality and availability of data does not ever have been compromised and reached to the user on a near real-time basis.},
booktitle = {Proceedings of the 21st International Conference on Distributed Computing and Networking},
articleno = {57},
numpages = {6},
keywords = {Machine Learning, ETL, Database Release Automation, Data Warehouse},
location = {Kolkata, India},
series = {ICDCN '20}
}

@proceedings{10.1145/3544902,
title = {ESEM '22: Proceedings of the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2022},
isbn = {9781450394277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Helsinki, Finland}
}

@inproceedings{10.1145/2668930.2688201,
author1 = {Woodside, Murray},
title = {WOSP-C'15: Workshop on Challenges in Performance Methods for Software Development},
year = {2015},
isbn = {9781450332484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668930.2688201},
doi = {10.1145/2668930.2688201},
abstract = {The first ACM Workshop on Challenges in Performance Methods for Software Development is held in Austin, Texas, on Jan. 31 2015, and is co-located with the 2015 ACM/SPEC International Conference on Performance Engineering (ICPE). Its purpose is to open up new avenues of research on methods for software developers to address performance problems. The software world is changing, and there are new challenges. As its name implies, the workshop includes the description of problems as well as solutions. The acronym WOSP-C also recalls the original discussion-heavy format of WOSP, the ACM International Workshop on Software and Performance, which has been a co-organizer of ICPE since 2010.},
booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
pages = {349–350},
numpages = {2},
keywords = {software performance, performance engineering.},
location = {Austin, Texas, USA},
series = {ICPE '15}
}

@proceedings{10.1145/3634713,
title = {VaMoS '24: Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bern, Switzerland}
}

@proceedings{10.1145/3687997,
title = {SLE '24: Proceedings of the 17th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2024},
isbn = {9798400711800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 17th ACM SIGPLAN International Conference on Software Language Engineering (SLE), held in Pasadena, California, USA, October 20–21 2024, as part of SPLASH 2024. The SLE conference is devoted to the principles of software languages: their design, their implementation, and their evolution.},
location = {Pasadena, CA, USA}
}

@article{10.1145/2831270,
author1 = {Lemos, Angel Lagares and Daniel, Florian and Benatallah, Boualem},
title = {Web Service Composition: A Survey of Techniques and Tools},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2831270},
doi = {10.1145/2831270},
abstract = {Web services are a consolidated reality of the modern Web with tremendous, increasing impact on everyday computing tasks. They turned the Web into the largest, most accepted, and most vivid distributed computing platform ever. Yet, the use and integration of Web services into composite services or applications, which is a highly sensible and conceptually non-trivial task, is still not unleashing its full magnitude of power. A consolidated analysis framework that advances the fundamental understanding of Web service composition building blocks in terms of concepts, models, languages, productivity support techniques, and tools is required. This framework is necessary to enable effective exploration, understanding, assessing, comparing, and selecting service composition models, languages, techniques, platforms, and tools. This article establishes such a framework and reviews the state of the art in service composition from an unprecedented, holistic perspective.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {33},
numpages = {41},
keywords = {service oriented computing, service composition, Web services}
}

@inproceedings{10.1145/3399579.3399863,
author1 = {Singhal, Rekha and Chahal, Dheeraj and Kunde, Shruti and Mishra, Mayank and Nambiar, Manoj},
title = {A Vision on Accelerating Enterprise IT System 2.0},
year = {2020},
isbn = {9781450380232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3399579.3399863},
doi = {10.1145/3399579.3399863},
abstract = {The proliferation of commodity based big data platforms and an exponential increase in the research in machine learning techniques lead to a change in application development paradigm from traditional control-flow Software 1.0 to data-flow Software 2.0 programming paradigm e.g. use of machine learning based models over customer-scoring methods for generating recommendations. The Software 2.0 paradigm is a data-driven programming that requires specialized data management to get clean, governed and unbiased data sets, well defined neural network architectures for building a model, efficient model training, extensive testing and high performance deployment. Unlike Software 1.0 paradigm, a Software 2.0 program's output is probabilistic in nature as the correctness is highly dependent on the size and quality of the input data, however the program's performance is deterministic. This has led to the research in specialized hardware and high performance architectures for deep-learning algorithms. Also, the nature of Software 2.0 paradigm brings in heterogeneity in the whole life cycle starting from an application development until its deployment in the production environment and hence posing numerous architecture and performance challenges.In this paper, we outline the research problems that will emerge due to migration of apart of Software 1.0 to Software 2.0. We present the challenges and the approaches to address them, for accelerating the development and deployment of Software 2.0 programs. We also envision evolution of existing enterprise IT systems to the data-driven enterprise IT systems, referred to as EIT 2.0. We have compared a conventional development life-cycle of applications with that in EIT 2.0. We address research problems and approaches with the related state-of-art in the performance engineering of modern enterprise applications during its life cycle in EIT 2.0.},
booktitle = {Proceedings of the Fourth International Workshop on Data Management for End-to-End Machine Learning},
articleno = {8},
numpages = {9},
keywords = {Accelerating EIT 2.0, Enterprise IT 2.0, Software 2.0, data driven IT},
location = {Portland, OR, USA},
series = {DEEM '20}
}

@proceedings{10.1145/3596454,
title = {EICS '23 Companion: Companion Proceedings of the 2023 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
year = {2023},
isbn = {9798400702068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Swansea, United Kingdom}
}

@proceedings{10.1145/3528229,
title = {SESoS '22: Proceedings of the 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
year = {2022},
isbn = {9781450393348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SESoS 2022 provides researchers and practitioners with a forum to exchange ideas and experiences, analyze research and development issues, discuss promising solutions, and propose theoretical foundations for development and evolution of complex software-intensive systems, inspiring visions for the future of Software Engineering for Systems-of-Systems (SoS) and Software Ecosystems (SECO), as well as paving the way for a more structured community effort.},
location = {Pittsburgh, Pennsylvania}
}

@inproceedings{10.1145/2593882.2593883,
author1 = {Fuggetta, Alfonso and Di Nitto, Elisabetta},
title = {Software process},
year = {2014},
isbn = {9781450328654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593882.2593883},
doi = {10.1145/2593882.2593883},
abstract = {This paper is a travelogue of Software Process research and practice in the past 15 years. It is based on the paper written by one of the author1s for the FOSE Track at ICSE 2000. Since then, the landscape of Software Process research has significantly evolved: technological breakthroughs and market disruptions have defined new and complex challenges for Software Engineering researchers and practitioners.  In this paper we provide an overview of the current status of research and practice, highlight new challenges, and provide a non-exhaustive list of research issues that, in our view, need to be tackled by future research work.},
booktitle = {Future of Software Engineering Proceedings},
pages = {1–12},
numpages = {12},
keywords = {Software Process, Software Development Environments, Software Development, Social Fac- tors in Software Development, Empirical Studies, Agile Software De- velopment},
location = {Hyderabad, India},
series = {FOSE 2014}
}

@inproceedings{10.1145/3185768.3186285,
author1 = {Mazkatli, Manar and Koziolek, Anne},
title = {Continuous Integration of Performance Model},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186285},
doi = {10.1145/3185768.3186285},
abstract = {Applying model-based performance prediction requires that an up-to-date Performance Model (PM) is available throughout the development process. Creating such a model manually is an expensive process that is unsuitable for agile software development aiming to produce rapid releases in short cycles. Existing approaches automate the extraction of a PM based on reverse engineering and/or measurements techniques. However, these approaches require to monitor and analyse the whole application. Thus, they are too costly to be applied frequently, up to after each code change. Moreover, keeping potential manual changes of the PM is another challenge as long the PM is regenerated from scratch every time. To address these problems, this paper envisions an approach for efficient continuous integration of a parametrised performance model in an agile development process. Our work will combine static code analysis with adaptive, automatic, dynamic analysis covering updated parts of code to update the PM with parameters, like resource demands and branching probabilities. The benefit of our approach will be to automatically keep the PM up-to-date throughout the development process which enables the proactive identification of upcoming performance problems and provides a foundation for evaluating design alternatives at low costs.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {153–158},
numpages = {6},
keywords = {parametric performance model, model-based performance engineering, incremental reverse engineering, continuous/incremental performance management},
location = {Berlin, Germany},
series = {ICPE '18}
}

@article{10.1145/2994205.2994214,
author1 = {Sharma, Richa and Sureka, Ashish},
title = {A Nine Year Story of the India Software Engineering Conference from 2008 to 2016},
year = {2016},
issue_date = {September 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2994205.2994214},
doi = {10.1145/2994205.2994214},
abstract = {The India Software Engineering Conference (ISEC) is an annual conference in the field of Software Engineering (SE) in India. ISEC started in the year 2008 and completed 9 years in 2016. The ISEC conference has evolved into a high-quality academic event for SE researchers from universities and industry in India with considerable international participation. Assessment and evaluation of ISEC conference quality, status and evolution is important for the national SE scientific community, ISEC steering committee, sponsors and science and technology-related government bodies. In this paper, we conduct scientific paper publication mining and scientometric and bibliometric analysis of 9 years of ISEC publications and programs. We conduct an in-depth multi-dimensional analysis of the conference across various aspects such as a summary of 9 years of ISEC programs (paper submission data, tutorials, workshops, keynotes, invited talks, geographical location, program and general chairs), author1-affiliation-based geographical contribution (analysis at the international and national levels), topic analysis, university and industry collaborations, contributions across university types in India, prolific and new author1s, gender equality and imbalance, program committee characteristics, open-source or closed-source datasets and citation-based impact. We also present our recommendations for future editions of the ISEC based on our comprehensive analysis study presented in this paper.},
journal = {SIGSOFT Softw. Eng. Notes},
month = nov,
pages = {31–44},
numpages = {14},
keywords = {University and Industry Collaboration, Software Engineering, Scientific Paper Publication Mining, Research Assessment, Conference Review, Conference Citation and Impact, Bibliometric Analysis}
}

@inproceedings{10.1145/2993412.3010821,
author1 = {Jazayeri, Bahar},
title = {Architectural management of on-the-fly computing markets},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3010821},
doi = {10.1145/2993412.3010821},
abstract = {Existing software markets like Google Play allow users to search among available Apps and select one based on the description provided for the App or based on its rating. Future software markets facilitate on-the-fly composition of such Apps based on users' individual wishes. Realizing such On-The-Fly Computing (OTF) markets requires support of sophisticated software features. In addition, suitable orchestration among such features needs to ensure well-alignment of business and IT aspects in case of run-time changes like market dynamics. However, all these introduce new architectural and management complexities, which are specific to such markets.An architecture framework for OTF markets will include design solutions to overcome these complexities. In my PhD, I aim at identifying an architecture framework for OTF markets including main architectural building blocks and a systematic development process. Such an architecture framework enables the development of OTF markets in the future. Furthermore, this knowledge can be used as a basis to improve existing software markets by integrating missing functionalities.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {42},
numpages = {2},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@proceedings{10.1145/3632366,
title = {BDCAT '23: Proceedings of the IEEE/ACM 10th International Conference on Big Data Computing, Applications and Technologies},
year = {2023},
isbn = {9798400704734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The IEEE/ACM International Conference on Big Data Computing, Applications, and Technologies (BDCAT) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of big data computing and applications.},
location = {Taormina (Messina), Italy}
}

@proceedings{10.1145/3524614,
title = {IWSiB '22: Proceedings of the 5th International Workshop on Software-intensive Business: Towards Sustainable Software Business},
year = {2022},
isbn = {9781450393027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {There are many researchers and practitioners whose work is related to the field of software-intensive business. However, they are often not fully aware of each other's work as the research is scattered. For example, individual research contributions have emerged related to, for example, software engineering economics, digital ecosystems and software startups. The goal of the workshop on Software-intensive Business is to bring these different sub-fields together and strengthen their ties.},
location = {Pittsburgh, Pennsylvania}
}

@proceedings{10.1145/3650212,
title = {ISSTA 2024: Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd edition of the International Symposium on Software Testing and Analysis, ISSTA 2024, held on September 16--20, 2024 in Vienna, Austria. ISSTA 2024 is co-located with ECOOP and MPLR 2024. ISSTA brings together academics, industrial researchers, and practitioners from all over the world working on testing and analyzing software systems.},
location = {Vienna, Austria}
}

@proceedings{10.1145/3625549,
title = {HPDC '24: Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {HPDC is the premier annual conference for presenting the latest research on the design, implementation, evaluation, and use of parallel and distributed systems for high-end computing. HPDC provides research contributions in all aspects of parallel and distributed computing such as resilience, AI-based systems and applications, data compression, serverless computing, software systems, workflows, performance modeling, hardware accelerators, scientific computing, resource management, security aspects and many others. The scientific contribution of the conference lays its groundwork for the significant endeavor required to implement actual systems and applications, along with the priceless knowledge acquired through active measurement and experimentation in real-world use cases.},
location = {Pisa, Italy}
}

@proceedings{10.1145/3538969,
title = {ARES '22: Proceedings of the 17th International Conference on Availability, Reliability and Security},
year = {2022},
isbn = {9781450396707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@inproceedings{10.1109/ICSE-SEET.2019.00009,
author1 = {Kuhrmann, Marco and Nakatumba-Nabende, Joyce and Pfeiffer, Rolf-Helge and Tell, Paolo and Kl\"{u}nder, Jil and Conte, Tayana and MacDonell, Stephen G. and Hebig, Regina},
title = {Walking through the method zoo: does higher education really meet software industry demands?},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET.2019.00009},
doi = {10.1109/ICSE-SEET.2019.00009},
abstract = {Software engineering educators are continually challenged by rapidly evolving concepts, technologies, and industry demands. Due to the omnipresence of software in a digitalized society, higher education institutions (HEIs) have to educate the students such that they learn how to learn, and that they are equipped with a profound basic knowledge and with latest knowledge about modern software and system development. Since industry demands change constantly, HEIs are challenged in meeting such current and future demands in a timely manner. This paper analyzes the current state of practice in software engineering education. Specifically, we want to compare contemporary education with industrial practice to understand if frameworks, methods and practices for software and system development taught at HEIs reflect industrial practice. For this, we conducted an online survey and collected information about 67 software engineering courses. Our findings show that development approaches taught at HEIs quite closely reflect industrial practice. We also found that the choice of what process to teach is sometimes driven by the wish to make a course successful. Especially when this happens for project courses, it could be beneficial to put more emphasis on building learning sequences with other courses.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training},
pages = {1–11},
numpages = {11},
keywords = {survey research, software process, software development, hybrid methods, education},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEET '19}
}

@inproceedings{10.1145/3098954.3104059,
author1 = {Rios, Erkuden and Iturbe, Eider and Palacios, Maria Carmen},
title = {Self-healing Multi-Cloud Application Modelling},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098954.3104059},
doi = {10.1145/3098954.3104059},
abstract = {Cloud computing market forecasts and technology trends confirm that Cloud is an IT disrupting phenomena and that the number of companies with multi-cloud strategy is continuously growing. Cost optimization and increased competitiveness of companies that exploit multi-cloud will only be possible when they are able to leverage multiple cloud offerings, while mastering both the complexity of multiple cloud provider management and the protection against the higher exposure to attacks that multi-cloud brings.This paper presents the MUSA Security modelling language for multi-cloud applications which is based on the Cloud Application Modelling and Execution Language (CAMEL) to overcome the lack of expressiveness of state-of-the-art modelling languages towards easing: a) the automation of distributed deployment, b) the computation of composite Service Level Agreements (SLAs) that include security and privacy aspects, and c) the risk analysis and service match-making taking into account not only functionality and business aspects of the cloud services, but also security aspects. The paper includes the description of the MUSA Modeller as the Web tool supporting the modelling with the MUSA modelling language. The paper introduces also the MUSA SecDevOps framework in which the MUSA Modeller is integrated and with which the MUSA Modeller will be validated.},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {93},
numpages = {9},
keywords = {security, modelling, deployment, Multi-cloud, Cloud},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}

@inproceedings{10.1145/3383219.3383245,
author1 = {Behutiye, Woubshet and Sepp\"{a}nen, Pertti and Rodr\'{\i}guez, Pilar and Oivo, Markku},
title = {Documentation of Quality Requirements in Agile Software Development},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383245},
doi = {10.1145/3383219.3383245},
abstract = {Context: Quality requirements (QRs) have a significant role in the success of software projects. In agile software development (ASD), where working software is valued over comprehensive documentation, QRs are often under-specified or not documented. Consequently, they may be handled improperly and result in degraded software quality and increased maintenance costs. Investigating the documentation of QRs in ASD, would provide evidence on existing practices, tools and aspects considered in ASD that other practitioners might utilize to improve documentation and management of QRs in ASD. Although there are some studies examining documentation in ASD, those that specifically investigate the documentation of QRs in depth are lacking.Method: we conducted a multiple case study by interviewing 15 practitioners of four ASD cases, to provide empirical evidence on documentation of QRs in ASD. We also run workshops with two of the cases, to identify important aspects that ASD practitioners consider when documenting QRs in requirements management repositories.Result and conclusions: ASD companies approach documentation of QRs to fit the needs of their context. They used tools, backlogs, iterative prototypes, and artifacts such as epic, and stories to document QRs, or utilized face-face communication without documenting QRs. We observed that documentation of QRs in ASD is affected by factors such as context (e.g. product domain, and size) and the experience of practitioners. Some tools used to document QRs also enhanced customer collaboration, enabling customers report and document QRs. Aspects such as levels of abstraction, the traceability of QRs, optimal details of information of QRs and verification and validation are deemed important when documenting QRs in ASD requirements management repositories.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {250–259},
numpages = {10},
keywords = {non-functional requirements, documentation, agile software development, Quality requirement},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/3341105.3374004,
author1 = {Girardon, Gustavo and Costa, Victor and Machado, Rodrigo and Bernardino, Maicon and Legramante, Guilherme and Basso, F\'{a}bio Paulo and de Macedo Rodrigues, Elder and Neto, Anibal},
title = {Testing as a service (TaaS): a systematic literature map},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3374004},
doi = {10.1145/3341105.3374004},
abstract = {Background: The knowledge and application of tools to automate testing is essential to ensure software reliability and therefore its quality. Due to the increasing demand for quality in software projects executed in short time-scales, Testing as a Service (TaaS) appeared in the literature as contributions for cost reduction and productivity of automated tests. Aims: Once quality attributes from these contributions are not deeply discussed by the literature of the area, our goal is to investigate and identify these attributes from the TaaS platforms and providers commonly reported in the literature. Method: A protocol was formulated and executed according to the guidelines for performing systematic literature map in Software Engineering. Results: The TaaS providers and platform proposals found were classified according to the number of mentions in the literature, highlighting the most commonly mentioned and widespread. As well as the propagation and explanation of the main advantages and disadvantages reported in the literature on Testing as a Service. Conclusions: TaaS provides means for cost reduction and increase in productivity in comparison to traditional test approaches. This is a reality observed in 76 options for Test as a Service cloud platforms distributed over 52 papers. In addition, as their quality attributes, we also found eight groups of disadvantages and 21 of advantages. Thus, this systematic mapping is a valuable contribution for decision making on performance testing strategies.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1989–1996},
numpages = {8},
keywords = {testing as a service, systematic mapping, cloud testing, TaaS},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@proceedings{10.1145/3600006,
title = {SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the author1s of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!},
location = {Koblenz, Germany}
}

@article{10.1145/3186888,
author1 = {Meidan, Ayman and Garc\'{\i}a-Garc\'{\i}a, Juli\'{a}n A. and Ramos, Isabel and Escalona, Mar\'{\i}a Jos\'{e}},
title = {Measuring Software Process: A Systematic Mapping Study},
year = {2018},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3186888},
doi = {10.1145/3186888},
abstract = {Context: Measurement is essential to reach predictable performance and high capability processes. It provides support for better understanding, evaluation, management, and control of the development process and project, as well as the resulting product. It also enables organizations to improve and predict its process's performance, which places organizations in better positions to make appropriate decisions. Objective: This study aims to understand the measurement of the software development process, to identify studies, create a classification scheme based on the identified studies, and then to map such studies into the scheme to answer the research questions. Method: Systematic mapping is the selected research methodology for this study. Results: A total of 462 studies are included and classified into four topics with respect to their focus and into three groups based on the publishing date. Five abstractions and 64 attributes were identified, 25 methods/models and 17 contexts were distinguished. Conclusion: capability and performance were the most measured process attributes, while effort and performance were the most measured project attributes. Goal Question Metric and Capability Maturity Model Integration were the main methods and models used in the studies, whereas agile/lean development and small/medium-size enterprise were the most frequently identified research contexts.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {58},
numpages = {32},
keywords = {metric, measurement, mapping study, Software development process}
}

@proceedings{10.1145/3660829,
title = {Programming '24: Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming},
year = {2024},
isbn = {9798400706349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lund, Sweden}
}

@proceedings{10.1145/3571473,
title = {SBQS '22: Proceedings of the XXI Brazilian Symposium on Software Quality},
year = {2022},
isbn = {9781450399999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Curitiba, Brazil}
}

@proceedings{10.1145/3659677,
title = {NISS '24: Proceedings of the 7th International Conference on Networking, Intelligent Systems and Security},
year = {2024},
isbn = {9798400709296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Meknes, AA, Morocco}
}

@proceedings{10.1145/3647444,
title = {ICIMMI '23: Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence},
year = {2023},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@inproceedings{10.1145/3129676.3129682,
author1 = {Cerny, Tomas and Donahoo, Michael J. and Pechanec, Jiri},
title = {Disambiguation and Comparison of SOA, Microservices and Self-Contained Systems},
year = {2017},
isbn = {9781450350273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3129676.3129682},
doi = {10.1145/3129676.3129682},
abstract = {There is an industrial shift from Service-Oriented Architectures (SOA) into Microservices; however, a quick review of online resources on these topics reveals a range of different understandings of these two architectures. Individuals often mix terms, grant false advantages or expect different quality attributes and properties. The purpose of this paper is to provide readers a solid understanding of the differences between these two architectures and their features. We provide both research and industry perspectives to point out strengths and weaknesses of both architectural directions, and we point out many shortcomings in both approaches that are not addressed by the architecture. Finally, based on this we propose challenges for future research.},
booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},
pages = {228–235},
numpages = {8},
keywords = {Self-contained Systems, SOA, Microservices, Architectures},
location = {Krakow, Poland},
series = {RACS '17}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@inproceedings{10.1109/CCGrid.2015.111,
author1 = {Gupta, Smrati and Muntes-Mulero, Victor and Matthews, Peter and Dominiak, Jacek and Omerovic, Aida and Aranda, Jordi and Seycek, Stepan},
title = {Risk-driven framework for decision support in cloud service selection},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.111},
doi = {10.1109/CCGrid.2015.111},
abstract = {The growth in the number of cloud computing users has led to the availability of a variety of cloud based services provided by different vendors. This has made the task of selecting a suitable set of services quite difficult. There has been a lot of research towards the development of suitable decision support system (DSS) to assist users in making an optimal selection of cloud services. However, existing decision support systems cannot address two crucial issues: firstly, the involvement of both business and technical perspectives in decision making simultaneously and, secondly, the multiple-clouds services based selection using a single DSS. In this paper, we tackle these issues in the light of solving the problem of cloud service discovery. In particular, we present the following novel contributions: Firstly, we present a critical analysis of the state-of-the-art in decision support systems. Based on our analysis, we identify critical shortcomings in the existent tools and develop the set of requirements which should be met by a potential DSS. Secondly, we present a new holistic framework for the development of DSS which allows a pragmatic description of user requirements. Additionally, the data gathering and analysis is studied as an integral part of the proposed DSS and therefore, we present concrete algorithms to assess the data for an optimal service discovery. Thirdly, we assess our framework for applicability to cloud service selection using an industrial case study. We also demonstrate the implementation and performance of our proposed framework using a prototype which serves as a proof of concept. Overall, this paper provides a novel and holistic framework for development of a multiple cloud service discovery based decision support system.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {545–554},
numpages = {10},
keywords = {risk modeling, decision support systems, cloud computing},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@article{10.1145/3183628.3183631,
author1 = {Cerny, Tomas and Donahoo, Michael J. and Trnka, Michal},
title = {Contextual understanding of microservice architecture: current and future directions},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1559-6915},
url = {https://doi.org/10.1145/3183628.3183631},
doi = {10.1145/3183628.3183631},
abstract = {Current industry trends in enterprise architectures indicate movement from Service-Oriented Architecture (SOA) to Microservices. By understanding the key differences between these two approaches and their features, we can design a more effective Microservice architecture by avoiding SOA pitfalls. To do this, we must know why this shift is happening and how key SOA functionality is addressed by key features of the Microservice-based system. Unfortunately, Microservices do not address all SOA shortcomings. In addition, Microservices introduce new challenges. This work provides a detailed analysis of the differences between these two architectures and their features. Next, we describe both research and industry perspectives on the strengths and weaknesses of both architectural directions. Finally, we perform a systematic mapping study related to Microservice research, identifying interest and challenges in multiple categories from a range of recent research.},
journal = {SIGAPP Appl. Comput. Rev.},
month = jan,
pages = {29–45},
numpages = {17},
keywords = {systematic mapping study, survey, self-contained systems, microservices, architectures, SOA}
}

@proceedings{10.1145/3613372,
title = {SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@article{10.1145/3492762,
author1 = {Sobhy, Dalia and Minku, Leandro and Bahsoon, Rami and Kazman, Rick},
title = {Continuous and Proactive Software Architecture Evaluation: An IoT Case},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3492762},
doi = {10.1145/3492762},
abstract = {Design-time evaluation is essential to build the initial software architecture to be deployed. However, experts’ assumptions made at design-time are unlikely to remain true indefinitely in systems that are characterized by scale, hyperconnectivity, dynamism, and uncertainty in operations (e.g. IoT). Therefore, experts’ design-time decisions can be challenged at run-time. A continuous architecture evaluation that systematically assesses and intertwines design-time and run-time decisions is thus necessary. This paper proposes the first proactive approach to continuous architecture evaluation of the system leveraging the support of simulation. The approach evaluates software architectures by not only tracking their performance over time, but also forecasting their likely future performance through machine learning of simulated instances of the architecture. This enables architects to make cost-effective informed decisions on potential changes to the architecture. We perform an IoT case study to show how machine learning on simulated instances of architecture can fundamentally guide the continuous evaluation process and influence the outcome of architecture decisions. A series of experiments is conducted to demonstrate the applicability and effectiveness of the approach. We also provide the architect with recommendations on how to best benefit from the approach through choice of learners and input parameters, grounded on experimentation and evidence.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {46},
numpages = {54},
keywords = {IoT, time series forecasting, software architecture evaluation, Continuous evaluation}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2405146.2405149,
author1 = {Viswanathan, Balaji and Verma, Akshat and Krishnamurthy, Bharat and Jayachandran, Praveen and Bhattacharya, Kamal and Ananthanarayanan, Rema},
title = {Rapid adjustment and adoption to MIaaS clouds},
year = {2012},
isbn = {9781450316132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2405146.2405149},
doi = {10.1145/2405146.2405149},
abstract = {Emerging Managed Infrastructure as a Service (MIaaS) clouds allow enterprises to outsource their IT infrastructure as well as their IT management needs. One of the core tenets of a MIaaS cloud is a standardized service delivery model, allowing the cloud provider to provide infrastructure management services at a lower cost. As opposed to pure IaaS clouds where arbitrary customer virtual machines can be migrated to the cloud, migration to MIaaS clouds require the customer servers to be adapted in a way such that the cloud steady state management stack can manage these virtual machines using the standardized delivery model. In this work, we address the problem of migrating customer workloads to a standardized MIaaS cloud. We present the design and implementation of Rapid Adjustment Engine (RAE). RAE captures the adjustment process across arbitrary customer servers with high diversity in a unified rule framework. It uses rapid image adjustment to reduce the end-to-end migration time and a flexible orchestrator framework to integrate diverse functionalities and associated tools in a single migration process. Our experimental evaluation establishes the ability of RAE to enable rapid, reliable and reduced cost migration to MIaaS clouds.},
booktitle = {Proceedings of the Industrial Track of the 13th ACM/IFIP/USENIX International Middleware Conference},
articleno = {3},
numpages = {6},
keywords = {migration to cloud, Managed Infrastructure as a Service},
location = {Montreal, Quebec, Canada},
series = {MIDDLEWARE '12}
}

@proceedings{10.1145/3627050,
title = {IoT '23: Proceedings of the 13th International Conference on the Internet of Things},
year = {2023},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@article{10.1145/3511302,
author1 = {Soldani, Jacopo and Cameriero, Marco and Paparelli, Giulio and Brogi, Antonio},
title = {Modelling and Analysing Replica- and Fault-aware Management of Horizontally Scalable Applications},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/3511302},
doi = {10.1145/3511302},
abstract = {Modern enterprise applications integrate multiple interdependent software components, whose management must be suitably coordinated. This must be done by taking into account all inter-component dependencies, the faults potentially affecting them, and the fact that each component can be horizontally scaled, i.e., &nbsp;that multiple instances of each component can be spawned or destroyed, depending on application needs. In this article, we introduce a novel solution for suitably modelling and analysing the replica- and fault-aware management of multi-component applications, based on topology graphs and management protocols. More precisely, we first introduce a compositional model of the management behaviour of the (possibly multiple) instances of the components forming an application, faults included. We then show how this model enables automating various useful analyses, from checking the validity of management plans to automatically determining management plans allowing the instance of an application to reach and maintain a desired target configuration.},
journal = {ACM Trans. Internet Technol.},
month = jul,
articleno = {74},
numpages = {32},
keywords = {finite state machines, management planning, horizontal scaling, fault resilience, Application management}
}

@proceedings{10.1145/3593663,
title = {ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seeon/Bavaria, Germany}
}

@inproceedings{10.1145/2851553.2851560,
author1 = {Brebner, Paul Charles},
title = {Automatic Performance Modelling from Application Performance Management (APM) Data: An Experience Report},
year = {2016},
isbn = {9781450340809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851553.2851560},
doi = {10.1145/2851553.2851560},
abstract = {Traditional testing approaches for enterprise systems are no longer possible, agile enough, affordable, or accurate in many cases. This is due to ongoing changes, reduced time between production updates and the inability to test all system components because of third party services and the expense of maintaining a test environment. One alternative approach has been to manually build predictive performance models to mitigate performance risk. Even this has become impractical and cannot keep pace with changes in complex enterprise systems. In response to these challenges we have developed a way to automatically build and parameterize performance models for large scale enterprise systems from Application Performance Management (APM) data. This industry experience report summaries our experiences with automatically building performance models for commercial customers over the last two years. For each project we summarize the problem context, the performance risks to be addressed, the automatic modelling process, the range in complexity of the resulting models, the accuracy of the predictions, and the benefits and limitations of the models in practice.},
booktitle = {Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering},
pages = {55–61},
numpages = {7},
keywords = {scalability, performance, modelling, automatic, APM},
location = {Delft, The Netherlands},
series = {ICPE '16}
}

@article{10.1145/3054177,
author1 = {Weerasiri, Denis and Barukh, Moshe Chai and Benatallah, Boualem and Sheng, Quan Z. and Ranjan, Rajiv},
title = {A Taxonomy and Survey of Cloud Resource Orchestration Techniques},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3054177},
doi = {10.1145/3054177},
abstract = {Cloud services and applications prove indispensable amid today’s modern utility-based computing. The cloud has displayed a disruptive and growing impact on everyday computing tasks. However, facilitating the orchestration of cloud resources to build such cloud services and applications is yet to unleash its entire magnitude of power. Accordingly, it is paramount to devise a unified and comprehensive analysis framework to accelerate fundamental understanding of cloud resource orchestration in terms of concepts, paradigms, languages, models, and tools. This framework is essential to empower effective research, comprehension, comparison, and selection of cloud resource orchestration models, languages, platforms, and tools. This article provides such a comprehensive framework while analyzing the relevant state of the art in cloud resource orchestration from a novel and holistic viewpoint.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {26},
numpages = {41},
keywords = {resource orchestration, Service oriented architectures, Cloud computing}
}

@proceedings{10.1145/3643667,
title = {Q-SE 2024: Proceedings of the 5th ACM/IEEE International Workshop on Quantum Software Engineering},
year = {2024},
isbn = {9798400705700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 5th International Workshop on Quantum Software Engineering (Q-SE 2024), co-located with ICSE 2024, provides a platform for researchers and practitioners to discuss challenges in developing quantum software in high-level quantum languages, novel solutions to build correct methods for testing quantum programs, executing quantum software, developing best practices, and creating a research roadmap of quantum software engineering.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3549036,
title = {QP4SE 2022: Proceedings of the 1st International Workshop on Quantum Programming for Software Engineering},
year = {2022},
isbn = {9781450394581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the first edition of the workshop on Quantum Programming for Software Engineering (QP4SE) to be held virtually, November 18th, 2022, co-located with ESEC/FSE 2022, Singapore.},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3603166,
title = {UCC '23: Proceedings of the IEEE/ACM 16th International Conference on Utility and Cloud Computing},
year = {2023},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The IEEE/ACM International Conference on Utility and Cloud Computing (UCC) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of Cloud and Edge utility computing and applications.},
location = {Taormina (Messina), Italy}
}

@proceedings{10.1145/3629527,
title = {ICPE '24 Companion: Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the ICPE 2024 workshops program. ICPE workshops extend the main conference by providing a forum to foster discussion on hot and emerging topics from the broad field of performance engineering. They offer a highly dynamic venue to exchange ideas, establish new collaborations, and bootstrap debates on novel techniques, methodologies, and their associated early research results. Workshops feature various presentation formats, including research paper presentations, panel discussions, and keynote talks. Through these presentations and discussions with peer researchers, ICPE workshops help shape future research and identify promising research directions for performance engineering.},
location = {London, United Kingdom}
}

@proceedings{10.1145/3677995,
title = {Erlang 2024: Proceedings of the 23rd ACM SIGPLAN International Workshop on Erlang},
year = {2024},
isbn = {9798400710988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 23rd ACM SIGPLAN Erlang Workshop (Erlang’24), co-located with the annual International Conference on Functional Programming (ICFP), held in Milan, Italy. The workshop continues to be a forum for presenting research and experience reports on all aspects of theory, implementation, and applications of the Erlang language and BEAM-related technologies, covering topics in functional programming, concurrency, distribution, and reliability.},
location = {Milan, Italy}
}

@proceedings{10.1145/3616855,
title = {WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 17th ACM International Conference on Web Search and Data Mining - WSDM 2024. WSDM is one of the premier conferences in the fields of web search and data mining, with a dynamic and growing community from academia and industry. After two years of virtual conferences and in-person conferences in Singapore, the 2024 edition is an in-person conference with virtual elements. We hope you enjoy the conference at the "Centro Internacional de Congresos de Yucatan (CIC)" in Merida from March 4 to March 8, 2024.We are excited to kick off the program with a dynamic mix of Tutorials and Industry Day. Our seven tutorials will cover a broad range of search and data mining topics. Industry Day will provide valuable insights from leaders at major technology companies. The core technical program continues WSDM's tradition of a single-track format, featuring 109 thought-provoking papers from both academic and industry experts. We're honored to have inspiring keynote speakers each day: Nicolas Christin (CMU), Elizabeth Reid (Google), and Saiph Savage (Civic A.I. Lab). Additionally, 17 interactive demonstrations will showcase the latest prototypes and systems. The final day offers a stimulating Doctoral Consortium and six engaging workshops on topics including integrity in social networks, large language model for society, psychology-informed information access system, interactive and scalable information retrieval system and machine learning on graphs. WSDM 2024 proudly presents WSDM day on information retrieval and Web in the region. WSDM Cup Day highlights finalists' presentations addressing challenges in Conversational Multi-Doc QA. This diverse and stimulating program promises to be an enriching experience for all!.},
location = {Merida, Mexico}
}

@proceedings{10.1145/3624062,
title = {SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@proceedings{10.1145/2997364,
title = {SLE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.1145/3658271,
title = {SBSI '24: Proceedings of the 20th Brazilian Symposium on Information Systems},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Juiz de Fora, Brazil}
}

@proceedings{10.1145/3643796,
title = {IDE '24: Proceedings of the 1st ACM/IEEE Workshop on Integrated Development Environments},
year = {2024},
isbn = {9798400705809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Despite the research community's desire to improve the productivity of software developers, it is challenging for research to move beyond papers into the everyday practice of software development. Since IDEs are one of the most widely used tools in developers' toolkit, they remain a crucial venue for research to reach the practitioners. To close the gap between research and adoption in practice, we launched the first edition of the IDE Workshop.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3671016,
title = {Internetware '24: Proceedings of the 15th Asia-Pacific Symposium on Internetware},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3589806,
title = {ACM REP '23: Proceedings of the 2023 ACM Conference on Reproducibility and Replicability},
year = {2023},
isbn = {9798400701764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santa Cruz, CA, USA}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3579170,
title = {RAPIDO '23: Proceedings of the DroneSE and RAPIDO: System Engineering for constrained embedded systems},
year = {2023},
isbn = {9798400700453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Toulouse, France}
}

@proceedings{10.1145/3578527,
title = {ISEC '23: Proceedings of the 16th Innovations in Software Engineering Conference},
year = {2023},
isbn = {9798400700644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Allahabad, India}
}

@proceedings{10.1145/3644032,
title = {AST '24: Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AST continues to be a venue for researchers and practitioners where they can discuss high quality research contributions on methods for software test automation, and various case studies reporting practices in this field. Indeed, software test automation is a discipline that has produced noteworthy research in the last decade.The special theme of AST 2024 is "Test automation for and with Generative AI". This innovative and promising research direction deals with the application of test automation technologies to the testing of Generative AI applications, as well as the adoption of generative AI to facilitate test automation.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3555228,
title = {SBES '22: Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Brazil}
}

@proceedings{10.1145/3643916,
title = {ICPC '24: Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICPC is the premier (CORE A) venue for research on program comprehension. Research on program comprehension encompasses both human activities for comprehending the software and technologies for supporting such comprehension.},
location = {Lisbon, Portugal}
}

@proceedings{10.5555/3643142,
title = {WSC '23: Proceedings of the Winter Simulation Conference},
year = {2023},
isbn = {9798350369663},
publisher = {IEEE Press},
location = {San Antonio, Texas, USA}
}

@proceedings{10.1145/3568562,
title = {SoICT '22: Proceedings of the 11th International Symposium on Information and Communication Technology},
year = {2022},
isbn = {9781450397254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hanoi, Vietnam}
}

@book{10.1145/3664191,
author1 = {Kumar, Amruth N. and Raj, Rajendra K. and Aly, Sherif G. and Anderson, Monica D. and Becker, Brett A. and Blumenthal, Richard L. and Eaton, Eric and Epstein, Susan L. and Goldweber, Michael and Jalote, Pankaj and Lea, Douglas and Oudshoorn, Michael and Pias, Marcelo and Reiser, Susan and Servin, Christian and Simha, Rahul and Winters, Titus and Xiang, Qiao},
title = {Computer Science Curricula 2023},
year = {2024},
isbn = {9798400710339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@proceedings{10.1145/3594536,
title = {ICAIL '23: Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law},
year = {2023},
isbn = {9798400701979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is my great pleasure to present to you the proceedings of the Nineteenth International Conference on Artificial Intelligence and Law (ICAIL 2023). The conference will be held June 19-23 at the Universidade do Minho in Braga, Portugal. It has been organized by the International Association for Artificial Intelligence and Law (IAAIL) and is held in cooperation with AAAI and ACM SIGAI. IAAIL's mission is to facilitate research, collaboration, and interdisciplinary communication at the intersection of law and the technical disciplines belonging to the field of artificial intelligence. The first ICAIL conference was held in 1987 and its 2023 iteration is the first to be held in person again after the Covid-19 pandemic.},
location = {Braga, Portugal}
}

@proceedings{10.1145/3613905,
title = {CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3627703,
title = {EuroSys '24: Proceedings of the Nineteenth European Conference on Computer Systems},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@proceedings{10.5555/3571885,
title = {SC '22: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
year = {2022},
isbn = {9784665454445},
publisher = {IEEE Press},
abstract = {This volume, containing the accepted technical papers and ACM Gordon Bell prize finalists, captures the best current research in all aspects of High Performance Computing (HPC). The SC22 Archive at the conference web site sc22.supercomputing.org complements this volume by collecting other high quality, peer-reviewed material including research posters, the visualization &amp; data analytics showcase, panels, birds of a feather, workshops, and tutorials.},
location = {Dallas, Texas}
}

@proceedings{10.1145/3594441,
title = {ICIEI '23: Proceedings of the 2023 8th International Conference on Information and Education Innovations},
year = {2023},
isbn = {9798400700613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Manchester, United Kingdom}
}

@proceedings{10.1145/3579895,
title = {ICNCC '22: Proceedings of the 2022 11th International Conference on Networks, Communication and Computing},
year = {2022},
isbn = {9781450398039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3631991,
title = {WSSE '23: Proceedings of the 2023 5th World Symposium on Software Engineering},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3638584,
title = {CSAI '23: Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
year = {2023},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3575813,
title = {e-Energy '23: Proceedings of the 14th ACM International Conference on Future Energy Systems},
year = {2023},
isbn = {9798400700323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3487553,
title = {WWW '22: Companion Proceedings of the Web Conference 2022},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Lyon, France}
}

@proceedings{10.1145/3545258,
title = {Internetware '22: Proceedings of the 13th Asia-Pacific Symposium on Internetware},
year = {2022},
isbn = {9781450397803},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hohhot, China}
}

@proceedings{10.1145/3581784,
title = {SC '23: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Started in 1988, the SC Conference has become the annual nexus for researchers and practitioners from academia, industry and government to share information and foster collaborations to advance the state of the art in High Performance Computing (HPC), Networking, Storage, and Analysis.},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3597926,
title = {ISSTA 2023: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ISSTA 2023, the 32nd edition of the International Symposium on Software Testing and Analysis, to be held on July 18–20, 2023 in Seattle, USA. The symposium has become a premier scientific event in the expanding area of software testing and analysis, with a strong appeal to researchers from all continents.},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3573942,
title = {AIPR '22: Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
year = {2022},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3411763,
title = {CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3576914,
title = {CPS-IoT Week '23: Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@proceedings{10.1145/3308560,
title = {WWW '19: Companion Proceedings of The 2019 World Wide Web Conference},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to &lt;I&gt;The Web Conference 2019&lt;/I&gt;. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, USA}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

